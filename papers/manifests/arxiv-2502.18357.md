# He et al. (2025) — Perceptions of Attribution in Human-AI Co-Creation

## Bibliographic

- **Title:** Which Contributions Deserve Credit? Perceptions of Attribution in Human-AI Co-Creation
- **Authors:** Jessica He, Stephanie Houde, Justin D. Weisz
- **Date:** 25 February 2025
- **Venue:** CHI 2025 (ACM Conference on Human Factors in Computing Systems)
- **URL:** https://arxiv.org/abs/2502.18357
- **License:** CC-BY-NC-ND 4.0

## File

- **Local path:** `papers/downloads/arxiv-2502.18357.pdf`
- **SHA-256:** `4f5c9f68e465e6d721db21a52644682301d1e7312726411c8dd6d250d01e5e46`
- **Size:** 1,100,000 bytes (approx)
- **Downloaded:** 2026-02-28

## Summary

A scenario-based survey study (N=155 knowledge workers) examining how people perceive attribution credit for AI contributions in co-creative writing tasks. Participants rated authorship credit for either a human or AI partner across varying contribution types, amounts, and levels of initiative.

Finds a consistent pattern: AI partners receive less credit than human partners for equivalent contributions. Participants identified multiple factors affecting attribution judgments including quality of contributions, personal values, and technology considerations. The paper argues that binary disclosure approaches (AI involved / not involved) are insufficient and that more granular attribution frameworks are needed to capture the nuances of human-AI co-creation.

## Relevance to Our Paper

**High.** Directly relevant to the Map's attribution system. Key connections:

1. **Empirically validates the need for granular attribution:** their finding that binary AI disclosure is insufficient supports our ai_contribution scoring approach (0-100 scale) over simple yes/no disclosure.

2. **The "AI credit discount" finding** is relevant context — people systematically undervalue AI contributions, which may affect how readers perceive the Map's transparently AI-generated content.

3. **Their call for new attribution frameworks** is exactly what the Map implements: per-article contribution scoring, explicit authorship tracking, public version history, and separate human/AI commit authorship.

4. **Useful for positioning our contribution:** we can cite this as evidence that the field needs better attribution practices, then present the Map's system as a working implementation.

## Notes

- From IBM Research (Seattle, Cambridge, Yorktown Heights)
- 30 pages in ACM format including appendices
- The study focuses on writing/editing scenarios, which maps well to the Map's content production workflow
- Published at CHI — the premier HCI venue — lending credibility to the attribution problem framing
