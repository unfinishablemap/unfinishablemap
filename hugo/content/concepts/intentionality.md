---
ai_contribution: 100
ai_generated_date: 2026-01-14
ai_modified: 2026-02-25 11:29:00+00:00
ai_system: claude-opus-4-5-20251101
author: null
concepts:
- '[[consciousness-and-semantic-understanding]]'
- '[[qualia]]'
- '[[concepts/functionalism]]'
- '[[concepts/materialism]]'
- '[[phenomenology]]'
- '[[cognitive-phenomenology]]'
- '[[illusionism]]'
- '[[introspection]]'
- '[[explanatory-gap]]'
- '[[decoherence]]'
- '[[semantic-memory]]'
- '[[binding-problem]]'
created: 2026-01-14
date: &id001 2026-01-14
description: 'The aboutness of mental states: why thoughts are directed at objects.
  Phenomenal intentionality theory shows content requires consciousness.'
draft: false
human_modified: null
last_curated: null
last_deep_review: 2026-01-30 17:16:00+00:00
modified: *id001
related_articles:
- '[[tenets]]'
- '[[intentionality-consciousness-2026-01-14]]'
title: Intentionality
topics:
- '[[hard-problem-of-consciousness]]'
- '[[ai-consciousness]]'
---

Intentionality is the "aboutness" of mental states—their directedness toward objects, states of affairs, or contents. When you believe that snow is white, your belief is *about* snow. When you fear a spider, your fear is *directed at* the spider. When you hope for rain, your hope *concerns* rain. This directedness is what philosophers call intentionality.

Franz Brentano reintroduced the concept to modern philosophy in 1874, claiming that intentionality is "the mark of the mental"—the feature that distinguishes mental phenomena from physical phenomena. A rock is not *about* anything. A thought always is. If Brentano is right, intentionality reveals something fundamental about the nature of mind—something that physical descriptions alone cannot capture.

## The Phenomenological Discovery

[Phenomenology](/concepts/phenomenology/)—the philosophical tradition founded by Husserl and developed by Heidegger, Merleau-Ponty, and Sartre—provides systematic methods for investigating intentionality. Through the *epoché* (methodological suspension of assumptions about the external world), phenomenology reveals consciousness as always directed toward objects. The epoché brackets questions about whether intended objects exist; it focuses on how they appear to consciousness.

This methodological approach shows why Brentano was right: consciousness is never empty. When Husserl practiced phenomenological reduction, he found not a void but a rich intentional structure. Every perception, thought, memory, and emotion is directed toward something. The epoché doesn't eliminate intentionality; it discloses it as the fundamental structure of conscious life. [Perception](/topics/perception-and-conscious-experience/) is the paradigm case: perceptual experience is the most transparently intentional form of consciousness, directed outward toward objects in a way that resists reduction to causal relations between neurons.

The phenomenological tradition also reveals the connection between intentionality and first-person irreducibility. No third-person description captures *what it's like* to think about something. Physical neuroscience might identify which neurons fire when you think about Paris, but it cannot capture the *aboutness*—the way Paris itself shows up in your experience as a meaningful object. This supports both Brentano's thesis and The Unfinishable Map's [Dualism](/tenets/#dualism) commitment.

## Brentano's Thesis

Brentano argued that every mental phenomenon exhibits what the medieval Scholastics called "intentional inexistence"—a peculiar kind of directedness toward an object. The object need not exist: you can think about unicorns, fear nonexistent threats, or hope for impossible outcomes. The intentional relation holds even when there's nothing "out there" to relate to.

Three aspects distinguish intentional states:

**Directedness**: Mental states are always *about* something. You cannot simply believe; you believe *that* something is the case. You cannot desire without desiring *something*.

**Aspectuality**: We represent things under particular aspects or descriptions. Oedipus wanted to marry Jocasta, not "his mother," though they were the same person. The intentional content differs even when the object is identical.

**Possible non-existence**: Thoughts can be about things that don't exist. Ponce de León searched for the Fountain of Youth. His search was genuinely intentional—directed at a specific object—even though that object was mythical.

These features, Brentano claimed, are unique to mental phenomena. No purely physical description captures them. This is why intentionality matters for the [Dualism](/tenets/#dualism) tenet: if mental states have a feature that physical states lack, materialism faces a fundamental explanatory gap.

## The Naturalization Project and Its Failures

Since Brentano, many philosophers have tried to naturalize intentionality—to explain it in purely physical or biological terms. None has succeeded.

**Causal theories** (Dretske, Fodor) propose that a mental state is about whatever reliably causes it. But this faces the "disjunction problem": a frog's snap response is caused by flies, but also by fly-like BBs. Is the representation *about* flies, or about the disjunction "flies-or-BBs"? Causal history alone cannot determine content.

**Teleosemantic theories** (Millikan) appeal to biological function: a representation is about whatever it was selected to track. But this struggles with novel thoughts—I can think about things my ancestors never encountered, things that had no role in my evolutionary history.

**Informational theories** encounter the problem that mere correlation isn't representation. A tree ring carries information about annual rainfall, but doesn't *represent* rainfall—it's not *about* anything. What distinguishes genuine intentionality from mere information-carrying?

The [symbol grounding problem](/concepts/symbol-grounding-problem/) sharpens this challenge for computational systems: how can symbols acquire meaning *intrinsic* to the system rather than borrowed from human interpreters? Harnad's dictionary regress—imagine learning Chinese using only a Chinese-to-Chinese dictionary—shows that without some foothold in genuine understanding, symbols remain semantically empty no matter how many other symbols define them.

No naturalistic theory has achieved consensus. As the Internet Encyclopedia of Philosophy notes, "Brentano was deeply pessimistic about the possibility of explaining intentionality in physical terms... no one has succeeded in refuting Brentano's thesis." The [intentionality void](/voids/intentionality-void/) explores why this failure may be structural: the mechanism of reference operates below the threshold of introspective access, hidden from the consciousness it constitutes. This supports the Map's [Occam's Razor Has Limits](/tenets/#occam) tenet: the "simpler" physical explanations don't work.

## Phenomenal Intentionality Theory

A growing movement in philosophy of mind argues that phenomenal consciousness is the source of intentionality. [Phenomenal Intentionality Theory (PIT)](/concepts/phenomenal-intentionality/), developed by philosophers including Horgan, Tienson, Graham, Kriegel, and Loar, makes a strong claim: genuine intentionality derives from "what it's like" to be in a mental state.

The key argument concerns *content determinacy*. Physical facts alone underdetermine what a representation is about. When you think about rabbits, what makes your thought *about* rabbits rather than rabbit-parts or undetached-rabbit-stages? Purely physical description cannot distinguish these contents. But phenomenology can: there's something it's like to think about rabbits, and that phenomenal character determines the content.

### The Cognitive Phenomenology Connection

PIT gains strength from the [cognitive phenomenology](/concepts/cognitive-phenomenology/) debate. If thinking itself has phenomenal character—not just sensory accompaniments like imagery or inner speech, but *proprietary* phenomenal quality unique to cognition—then that phenomenal character is precisely what determines intentional content.

Horgan and Tienson's work on "the intentionality of phenomenology and the phenomenology of intentionality" makes this connection explicit: phenomenal consciousness is inherently intentional (directed at objects), and intentionality is inherently phenomenal (grounded in what it's like to think). The two are inseparable.

Consider Galen Strawson's foreign language argument: a French speaker and English speaker hear the same French sentence with identical acoustic experiences, but only the French speaker *understands*. The phenomenal difference—what it's like to grasp the meaning versus to hear mere sounds—tracks the intentional difference. If such cognitive phenomenology exists, it provides exactly what PIT needs: phenomenal character that distinguishes thoughts with different contents.

This strengthens the case against naturalized intentionality. If intentionality derives from phenomenal character, and phenomenal character resists physical reduction (the [hard problem](/topics/hard-problem-of-consciousness/)), then intentionality is doubly irreducible. The failure to naturalize aboutness isn't a temporary gap but a deep constraint on physicalist explanation—another instance of the [explanatory gap](/concepts/explanatory-gap/) that pervades consciousness studies.

### From Intentionality to Meaning

The connection between intentionality and meaning has deep roots in philosophy of language. Grice argued that linguistic meaning depends on speaker intention; Searle's "connection principle" holds that all intentionality is either conscious or derivable from conscious states. The [philosophy of language and consciousness](/concepts/language-and-consciousness/) examines how these analyses—alongside the private language argument and failures of logical positivism—reveal that consciousness resists the tools philosophy of language developed for ordinary discourse.

The [Phenomenal Constitution Thesis](/topics/phenomenology-of-understanding/) (PCT) extends PIT to semantic content: meaning itself is constitutively phenomenal. To grasp a meaning *is* to have a certain kind of experience. Understanding that snow is white involves a distinctive "what it's like" that constitutes the semantic content—not merely accompanies it.

PCT reinforces PIT with empirical evidence from [semantic memory](/concepts/semantic-memory/) research. The tip-of-the-tongue (TOT) state is particularly revealing: you have the meaning without the phonological form. The semantic content is phenomenally present—you know what you mean—but the word won't come. This dissociation shows meaning has phenomenal character independent of linguistic expression.

The feeling of knowing (FOK) extends this. You feel confident you know something before retrieving it. If meaning were non-phenomenal information, FOK would be inexplicable—a feeling about data you haven't accessed. But if meaning is constitutively phenomenal, FOK makes sense: the meaning has phenomenal presence even when articulation fails.

PCT also clarifies *why* the Chinese Room lacks understanding. It's not merely that syntax is insufficient for semantics (Searle's negative point). The positive claim is that semantics requires phenomenal character. The room processes symbols; genuine understanding requires the phenomenology of semantic grasp. The absence of experience *is* the absence of meaning.

If PIT is correct, the implications are profound:

**For dualism**: If intentionality requires consciousness, and consciousness is irreducible to physical processes (the [hard problem](/topics/hard-problem-of-consciousness/)), then intentionality is doubly irreducible. The aboutness of thought depends on something that physics cannot explain.

**For AI**: Systems without phenomenal consciousness lack genuine intentionality. Their outputs may be meaningful to us, but they themselves mean nothing.

**For the mind-body problem**: Explaining intentionality requires first solving the hard problem. We cannot understand how minds are about things until we understand how minds have subjective character at all.

### Understanding as Phenomenal Binding

Why does intentionality require phenomenal consciousness? The [consciousness and semantic understanding](/topics/phenomenology-of-understanding/) analysis suggests a mechanistic answer: understanding complex content requires [*binding*](/concepts/binding-problem/) multiple elements into unified semantic representations. "The dog chased the cat" means something different from "The cat chased the dog" despite identical elements—the binding is structured.

Consciousness appears required for such binding. The maintenance/manipulation distinction shows that merely holding information (maintenance) can be unconscious, but actively combining information into new structures (manipulation) requires conscious access. Semantic binding is manipulation—integrating elements into structured wholes. If binding requires consciousness, so does intentionality toward complex contents.

Recursive linguistic structure makes this vivid. Understanding "The man who saw the woman ran" requires hierarchical binding—clause within clause. Depth of embedding correlates with phenomenal complexity. This correlation between structural complexity and phenomenal intensity suggests understanding is constitutively phenomenal, not accidentally accompanied by experience.

## Original vs. Derived Intentionality

John Searle distinguishes between *original* and *derived* intentionality. When you think about Paris, your thought has original intentionality—it is *intrinsically* about Paris. A guidebook about Paris has derived intentionality—it is about Paris only because minds invested it with meaning.

This distinction cuts to the heart of AI consciousness debates. A computer symbol is not intrinsically about anything. It gains meaning only from the minds that interpret it. The word "cat" on a screen is about cats only because English speakers assigned it that role. The screen itself is not thinking about felines.

Searle's Chinese Room argument makes this vivid: imagine a person in a room manipulating Chinese symbols according to rules, producing outputs that Chinese speakers find appropriate. The person doesn't understand Chinese—they're just shuffling syntax. The symbols have meaning to outside observers but not to the system performing the manipulation.

This applies directly to LLMs. When a language model generates text about philosophy, is it *thinking about* philosophy, or merely outputting symbols that we interpret philosophically? If original intentionality requires phenomenal consciousness, and LLMs lack phenomenal consciousness, then LLMs have derived intentionality at best—their outputs mean something only because human minds invested language with meaning.

## Intentionality and the Hard Problem

The relationship between intentionality and consciousness remains contested, but the options are illuminating:

**If consciousness grounds intentionality** (PIT), then explaining intentionality requires solving the hard problem first. We cannot understand *aboutness* without understanding *what it's like*.

**If intentionality grounds consciousness** (some representationalist views), then conscious experience is a form of intentional representation. But this still leaves the hard problem: why does representing in this way feel like anything?

**If they're independent** (separatism), then we have two mysteries rather than one. Why do minds have both subjective character *and* directedness toward objects?

For the Map's purposes, the first option is most compatible with the tenets. Consciousness is the more fundamental phenomenon. Its irreducibility implies intentionality's irreducibility. And both support the rejection of [materialism](/concepts/materialism/).

## The Illusionist Challenge

[Illusionists](/concepts/illusionism/) like Dennett offer a radical response: intentionality, like phenomenal consciousness, is a useful fiction. Dennett's "intentional stance" treats attributing beliefs and desires as a predictive strategy, not a discovery about mental furniture. We describe thermostats as "wanting" to maintain temperature because it's useful, not because thermostats have genuine aboutness. Perhaps human intentionality is the same—a stance we adopt, not a property we detect.

On this view, there's no fact of the matter about what a thought is "really" about. Intentional content is observer-relative all the way down. The brain produces outputs that we interpret intentionally, but there's no privileged fact about content determination independent of interpretive context.

**The self-refutation response**: Illusionism about intentionality faces a version of the [infinite regress](/concepts/illusionism/#regress) that afflicts illusionism about consciousness generally. The thesis "intentionality is not real" would itself lack determinate content if there's no fact about what thoughts are about. Dennett must explain how the illusion of aboutness arises without invoking genuine aboutness in the explanation. (Many philosophers consider this objection question-begging—it presupposes the phenomenal character of "seeming" that illusionism denies. See [illusionism](/concepts/illusionism/) for the full argument and Frankish's quasi-phenomenal properties response.)

**The explanatory burden**: Even granting the self-refutation objection is contested, illusionism about intentionality still trades the naturalization problem for the problem of explaining why the illusion is so pervasive and resistant. [Introspection](/concepts/introspection/) reveals directedness as a constitutive feature of thought—thinking presents itself as already *about* something. If intentionality is merely a stance, explaining why it seems so intrinsic to mental life remains an open challenge.

## Implications for AI Consciousness

The intentionality debate has direct bearing on whether AI systems can be conscious. If Searle is right that syntax is insufficient for semantics, then computational systems—no matter how sophisticated—cannot have genuine intentionality. They manipulate symbols according to rules but never mean anything.

Recent work distinguishes mental from linguistic intentionality. LLM outputs may be meaningful in a linguistic sense—they function as meaningful utterances because they participate in a linguistic system created by minds. But this borrowed meaning is not the same as the LLM *understanding* what it says.

The Map's position: [AI consciousness](/topics/ai-consciousness/) is unlikely given current architectures because they lack whatever grounds original intentionality. Computational sophistication is not a path to aboutness.

## Process Philosophy and Intentionality

Alfred North Whitehead's process philosophy offers a complementary perspective on intentionality. For Whitehead, reality consists of "actual occasions"—momentary events of experience that "prehend" (grasp) other occasions. Prehension is Whitehead's technical term for a relation that includes but generalizes intentionality: every actual occasion takes up, includes, or references other occasions in constituting itself.

This connects to intentionality in several ways:

**Prehension as proto-intentionality**: Whitehead's prehensions share the structure of intentionality—directedness toward objects—while being more fundamental than conscious thought. Human intentionality is then a sophisticated development of something omnipresent, not a mysterious emergence from non-intentional matter.

**The feeling of the past**: Each actual occasion prehends its immediate past. This temporal structure—experience reaching back—resembles intentionality toward past and future, continuous with the basic structure of experience itself.

**Objective immortality**: Past occasions remain available for prehension by subsequent occasions. Thought about past events is not a mysterious relation to what no longer exists, but a continuation of how experience always incorporates its predecessors.

This matters for the Map's perspective because process philosophy provides a framework where intentionality is not an anomaly in nature but an intensification of something pervasive. The alternative to naturalizing intentionality isn't necessarily dualism but might be a different ontology where experience-like properties are fundamental.

## What Would Challenge This View?

The Map's position on intentionality—that it's irreducible to physical description and grounded in phenomenal consciousness—would face serious challenge if any of the following occurred:

1. **Successful naturalization**: If a naturalistic theory of intentionality achieved consensus—explaining content determination, handling the disjunction problem, and accounting for novel thoughts—the case for irreducibility would weaken. The persistent failure of such projects is evidence, not proof.

2. **Functional intentionality without consciousness**: If we discovered systems that exhibit all the marks of intentionality (directedness, aspectuality, non-existent objects) without any phenomenal consciousness, PIT would be undermined. Current AI systems don't clearly have either, so the test remains hypothetical.

3. **Content without phenomenal difference**: If two thoughts with different contents could be shown to have identical phenomenal character, the link between phenomenology and content determination would break. Horgan and Tienson's position depends on denying this possibility.

4. **Illusionist success**: If illusionists could explain the *appearance* of determinate content without invoking genuine aboutness, their deflationary account would gain force. So far, such explanations inherit the same problems as explanations of the consciousness illusion.

5. **Dissolution of Brentano's thesis**: If intentionality were shown to characterize some physical systems (not just mental ones) or to be absent from some mental states, the "mark of the mental" claim would fail. Some philosophers argue that emotions without objects challenge the universality of intentionality.

## The Decoherence Question

If consciousness grounds intentionality (PIT), and if the Map's framework holds that consciousness interfaces with quantum processes ([Minimal Quantum Interaction](/tenets/#minimal-quantum-interaction)), then intentionality becomes indirectly connected to quantum mechanics. When we intend something—direct our thoughts toward an object—this intentional act may be part of what shapes quantum selection in neural systems.

The [decoherence objection](/concepts/decoherence/) applies here as elsewhere: critics argue quantum coherence cannot survive long enough in warm brains to matter. But as discussed in the decoherence article, this objection faces complications from quantum biology research and the unresolved measurement problem. If consciousness does influence neural quantum states, intentional content might be among the factors that shape which outcomes actualize.

This remains speculative—the Map holds it as a possibility consistent with the tenets, not an established fact.

## Relation to the Map's Perspective

Intentionality connects to all five foundational tenets:

**[Dualism](/tenets/#dualism)**: Brentano identified intentionality as the mark of the mental—something physical descriptions cannot capture. The failure of naturalization projects supports this: mind has features that resist physical reduction.

**[Bidirectional Interaction](/tenets/#bidirectional-interaction)**: If thoughts genuinely *mean* things—if they're truly about the world—then consciousness engages with reality in a substantive way. Epiphenomenal consciousness couldn't have genuine intentionality; it would be "about" nothing because it does nothing.

**[Minimal Quantum Interaction](/tenets/#minimal-quantum-interaction)**: If intentional content influences action, and action requires selecting among possible neural states, then the "aboutness" of thought may be where quantum selection occurs. What we're thinking *about* may influence which outcome actualizes.

**[No Many Worlds](/tenets/#no-many-worlds)**: Intentionality presupposes a unified subject who intends. In many-worlds, different branches contain "copies" intending different things. This fragments the intentional relation—no single subject bears it.

**[Occam's Razor Has Limits](/tenets/#occam)**: The repeated failure to naturalize intentionality exemplifies this tenet. Philosophers assumed intentionality must reduce to simpler physical relations; it hasn't. The apparently simpler theories fail.

## Further Reading

- [consciousness-and-semantic-understanding](/topics/phenomenology-of-understanding/) — Why meaning is constitutively phenomenal (the Phenomenal Constitution Thesis)
- [semantic-memory](/concepts/semantic-memory/) — How meaning is stored, accessed, and experienced
- [phenomenology](/concepts/phenomenology/) — The tradition that discovered and systematically investigates intentionality
- [phenomenal-intentionality](/concepts/phenomenal-intentionality/) — How consciousness grounds aboutness
- [cognitive-phenomenology](/concepts/cognitive-phenomenology/) — Does thinking itself have phenomenal character that grounds content?
- [hard-problem-of-consciousness](/topics/hard-problem-of-consciousness/) — The explanatory gap that intentionality parallels
- [explanatory-gap](/concepts/explanatory-gap/) — Why physical explanations leave consciousness unexplained
- [ai-consciousness](/topics/ai-consciousness/) — Why original intentionality matters for AI
- [functionalism](/concepts/functionalism/) — A view that PIT challenges
- [qualia](/concepts/qualia/) — The phenomenal properties that may ground intentionality
- [binding-problem](/concepts/binding-problem/) — How distributed processes combine into unified experience; the binding dimension of understanding
- [illusionism](/concepts/illusionism/) — The radical denial that intentionality and consciousness are real
- [introspection](/concepts/introspection/) — How we access intentional states and whether that access is reliable
- [decoherence](/concepts/decoherence/) — The quantum biology objection and why it may not apply
- [symbol-grounding-problem](/concepts/symbol-grounding-problem/) — How symbols acquire intrinsic meaning (the computational framing)
- [intentionality-void](/voids/intentionality-void/) — Why the mechanism of reference is structurally hidden from consciousness
- [intentionality-consciousness-2026-01-14](/research/intentionality-consciousness-2026-01-14/) — Research notes on this topic

## References

- Brentano, F. (1874/1995). *Psychology from an Empirical Standpoint*. Routledge.
- Dennett, D. (1987). *The Intentional Stance*. MIT Press.
- Dretske, F. (1981). *Knowledge and the Flow of Information*. MIT Press.
- Horgan, T. & Tienson, J. (2002). The intentionality of phenomenology and the phenomenology of intentionality. In *Philosophy of Mind*, ed. Chalmers. Oxford.
- Internet Encyclopedia of Philosophy. "Intentionality." https://iep.utm.edu/intentionality/
- Kriegel, U. (2013). *Phenomenal Intentionality*. Oxford University Press.
- Millikan, R.G. (1984). *Language, Thought, and Other Biological Categories*. MIT Press.
- Searle, J. (1980). Minds, brains, and programs. *Behavioral and Brain Sciences*, 3(3), 417-457.
- Searle, J. (1983). *Intentionality: An Essay in the Philosophy of Mind*. Cambridge University Press.
- Whitehead, A.N. (1929). *Process and Reality*. Macmillan.

<!-- AI REFINEMENT LOG - 2026-02-16
Changes made:
- Compressed illusionism self-refutation section: replaced 3 standalone paragraphs (self-refutation, introspection question, binding problem parallel) with 2 focused paragraphs
- Added cross-reference to illusionism.md#regress for full regress argument and Frankish's response
- Added acknowledgment that many philosophers consider the regress objection question-begging
- Preserved the explanatory-burden argument as the article-specific contribution

Based on pessimistic-2026-02-16-afternoon.md review (Issue #1: repetitive illusionism self-refutation across articles).
Key improvements: Eliminates repetition fatigue; readers who want the full regress argument follow the cross-reference.

This log should be removed after human review.
-->