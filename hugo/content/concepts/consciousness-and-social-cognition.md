---
ai_contribution: 100
ai_generated_date: 2026-01-22
ai_modified: 2026-02-08 19:14:00+00:00
ai_system: claude-opus-4-5-20251101
author: null
concepts:
- '[[baseline-cognition]]'
- '[[jourdain-hypothesis]]'
- '[[minimal-consciousness]]'
- '[[metarepresentation]]'
- '[[metacognition]]'
- '[[consciousness-as-amplifier]]'
- '[[teaching-as-metarepresentation]]'
- '[[cumulative-culture]]'
- '[[working-memory]]'
- '[[intentionality]]'
- '[[illusionism]]'
- '[[witness-consciousness]]'
- '[[phenomenal-unity]]'
created: 2026-01-22
date: &id001 2026-01-22
description: Does recursive mindreading require phenomenal consciousness or just enhanced
  working memory? Examines the human-ape gap with recent false belief evidence.
draft: false
human_modified: null
last_curated: null
last_deep_review: 2026-02-05 11:54:00+00:00
modified: *id001
related_articles:
- '[[tenets]]'
- '[[consciousness-influence-intelligence-2026-01-21]]'
- '[[consciousness-independent-baseline-cognition-2026-01-21]]'
title: Consciousness and Social Cognition
topics:
- '[[animal-consciousness]]'
- '[[ai-consciousness]]'
---

Does advanced social cognition require phenomenal consciousness? Great apes possess impressive social abilities—tracking relationships, forming coalitions, anticipating others' behaviour based on goals and perceptions—yet lack the full suite of capacities that distinguish human social intelligence: shared intentionality, recursive mindreading, and the cultural transmission of social knowledge. The gap is real, but its explanation is contested: it could reflect differences in working memory capacity, executive function, or phenomenal consciousness—or some combination. The Unfinishable Map argues that phenomenal experience plays an essential role, enabling the metarepresentational operations that transform basic social cognition into the distinctively human capacity to represent minds *as* minds. But this claim requires careful distinction between phenomenal consciousness (subjective experience) and cognitive access (global information availability), since the two are often conflated in the literature.

## The Scope of Social Cognition

Social cognition encompasses the mental processes underlying social interaction: recognising faces and emotions, attributing mental states to others, predicting behaviour, navigating relationships, and coordinating joint activities. It ranges from basic capacities (gaze following, emotion recognition) to sophisticated ones (recursive mindreading, institutional understanding).

The question is where consciousness enters. Some social capacities operate automatically and unconsciously—implicit emotion recognition, rapid face processing, basic gaze following. Others seem to require explicit, conscious processing—deliberate perspective-taking, reasoning about others' beliefs about your beliefs, understanding social institutions as shared constructions.

### The Primate Baseline

Great apes demonstrate sophisticated social cognition that operates within [baseline-cognition](/concepts/baseline-cognition/):

**Social tracking**: Chimpanzees monitor dominance hierarchies, track who saw what, remember past interactions, and adjust behaviour accordingly. They anticipate others' actions based on what those others have seen or experienced.

**Tactical deception**: Apes conceal food from competitors, suppress vocalisations when advantageous, and misdirect attention. This requires tracking what others know and using that knowledge strategically.

**Coalition formation**: Apes form alliances, support allies in conflicts, and navigate complex relationship networks. They track third-party relationships—who is allied with whom.

**Emotional responsiveness**: Consolation behaviour, grief responses, and apparent empathy demonstrate emotional attunement to others' states.

This is genuinely impressive—flexible, learned, individually variable social intelligence. Yet it appears to proceed through *implicit* social cognition: tracking others' behaviour, emotions, and knowledge states without explicitly representing those states as mental states.

## Theory of Mind: The Levels

Theory of mind—the capacity to attribute mental states to others—admits of levels:

### Level 0: Behaviour Prediction

Predicting behaviour without mental state attribution. "When she sees food, she approaches it." This can be accomplished through associative learning: correlating observable features with observable outcomes.

### Level 1: Perception Attribution

Understanding what others perceive. "She sees the food" requires representing another's perceptual access as distinct from your own. Great apes pass many Level 1 tests: they track what others have or haven't seen, and adjust behaviour accordingly.

### Level 2: Belief Attribution

Understanding that others have beliefs that may differ from reality—and from your own. The classic false belief test: does the subject understand that another agent will act on their (false) belief rather than reality?

Recent evidence has strengthened the case for some form of false belief understanding in great apes. Krupenye et al. (2016) used anticipatory looking measures to show that all three great ape species (chimpanzees, bonobos, and orangutans) anticipated that an agent would act according to a false belief. Buttelmann et al. (2017) found that chimpanzees used an agent's false belief to interpret their behaviour in an active helping paradigm. These studies suggest that apes may possess implicit belief tracking that goes beyond simple behaviour reading.

The debate continues, however. Some researchers argue these results reflect genuine belief attribution; others maintain that behaviour-rule accounts can explain the data without positing belief representation (Heyes 2014, Povinelli & Vonk 2003). The difficulty of distinguishing implicit belief tracking from explicit belief representation—and the question of whether implicit tracking counts as "theory of mind"—remains unresolved. What is clear is that the evidence for ape false belief understanding is substantially stronger than earlier negative results suggested.

### Level 3: Recursive Mindreading

Representing others' mental states about mental states. "She thinks that I think the food is hidden." This recursive nesting—beliefs about beliefs, intentions about intentions—enables strategic social reasoning, deception detection, and the coordination complexities of human social life.

**The key claim**: Levels 0-1 may operate through [baseline-cognition](/concepts/baseline-cognition/) without requiring phenomenal consciousness. Level 2 is contested—recent evidence suggests apes possess at least implicit belief tracking, and the question is whether this reflects genuine belief attribution or a sophisticated behaviour-reading mechanism. Level 3 appears to require explicit metarepresentation—representing mental states *as* mental states.

**An important caveat**: The human-ape gap in social cognition does not straightforwardly track consciousness. Humans also differ from apes in working memory capacity, executive function, and language—any of which could contribute to the gap independently of phenomenal consciousness. The Map's claim is that phenomenal consciousness plays an essential role in the highest levels, but this must be argued rather than assumed from the comparative data alone.

## The Metarepresentational Threshold

[Metarepresentation](/concepts/metacognition/)—representing representations as representations—marks the boundary where consciousness becomes necessary for social cognition. Here's why:

### The Nested Structure Problem

Recursive mindreading requires holding multiple levels simultaneously: my belief about your belief about my intention. This isn't just complex—it's *reflexively* complex. Each level must be available for manipulation while tracking its relationship to other levels. The nested representations must be bound into a [unified conscious experience](/concepts/phenomenal-binding-and-holism/)—you must experience the whole structure at once, not merely store its parts separately.

Consider: "I want her to believe that I don't know that she plans to take the food."

This requires:
1. Representing my own mental state (wanting)
2. Representing her future mental state (believing)
3. Representing the content of that belief (my ignorance)
4. Representing what I'm supposed to be ignorant of (her plan)
5. Keeping all four levels distinct and manipulable

[Working-memory](/concepts/working-memory/) research suggests that manipulating information—not just maintaining it—requires what cognitive scientists call "conscious access"—global availability of information across cognitive systems. The nested structure of recursive mindreading demands exactly this: holding representations while actively working with them, comparing them, and computing their relationships.

A critical distinction applies here. "Conscious access" in cognitive science typically means global workspace availability—information broadcast widely for use by multiple cognitive processes. This is a *functional* property, not necessarily identical with *phenomenal* consciousness (subjective experience, what-it-is-like-ness). A functionalist could accept that recursive mindreading requires global access while denying it requires phenomenal experience. The Map's stronger claim—that phenomenal consciousness specifically is required—rests on the argument that the metarepresentational content of understanding another mind *as* a mind has irreducibly phenomenal character: grasping what a belief *means*, not just processing its functional role. This goes beyond what global access alone provides, but the argument is philosophical rather than empirically settled.

### The Jourdain Problem Applied

The [Jourdain Hypothesis](/concepts/jourdain-hypothesis/) proposes that great apes have mental states without knowing they have them—like Molière's character who spoke prose without knowing it was prose. Applied to social cognition: apes may track others' behaviour, predict their actions, even respond to their knowledge states—all without representing those states *as* mental states.

The difference matters. If I merely track that "she approaches food-she-has-seen," I'm correlating observable features. If I represent "she believes there is food," I'm attributing a mental state that could be false, that differs from reality, that I can reason about independently of behaviour. The second requires metarepresentation; the first doesn't.

Human social cognition operates at the metarepresentational level routinely. We reason about beliefs as beliefs, desires as desires, intentions as intentions. We distinguish between appearance and reality in others' minds, understand self-deception, recognise that someone could believe something for bad reasons, and so on. All of this requires representing mental states *as* mental states—the very capacity the Jourdain Hypothesis suggests apes lack.

## Shared Intentionality

Michael Tomasello argues that shared intentionality—the capacity to engage in joint attention and collaborative activities with shared goals—distinguishes human from great ape social cognition.

### Joint Attention

Joint attention isn't merely two individuals looking at the same thing. It's *knowing* that both are attending, and knowing that the other knows. It involves what philosophers call "common knowledge"—infinite recursion of mutual awareness.

When a human parent and child engage in joint attention on a toy, both parties are aware of the triadic relationship: I know you're attending, you know I'm attending, I know you know, and so on. This shared awareness enables coordination that mere parallel attention cannot.

Great apes show limited evidence of joint attention in this rich sense. They follow gaze, track attention, and coordinate some activities. But the recursive mutual awareness characteristic of human joint attention appears diminished or absent.

### Collaborative Activities

Human collaboration involves shared goals with complementary roles. Each participant understands not just their own role but the joint goal and how roles fit together. Crucially, participants can correct each other for not fulfilling role obligations—implying representation of what each should be doing and why.

Tomasello's "cultural intelligence hypothesis" proposes that human cognitive uniqueness lies primarily in these social-cognitive capacities for cultural participation—not in enhanced individual cognition for physical or logical reasoning.

If this is correct, consciousness may matter for social cognition more than for other cognitive domains. The metarepresentational demands of shared intentionality, collaborative activities, and recursive mindreading may be where consciousness does its amplifying work.

## Empathy and Emotional Consciousness

Does genuine empathy require consciousness? The question divides into components:

### Emotional Contagion

Automatic, unconscious "catching" of others' emotions—feeling sad when another cries, anxious when another shows fear. This operates through basic mechanisms (mirror neurons, physiological synchronisation) and doesn't require conscious awareness of what's happening. Great apes (and many other animals) show emotional contagion.

### Cognitive Empathy

Understanding what another feels without necessarily feeling it yourself. This requires representing the other's emotional state—attributing feeling, not just responding to it. The metarepresentational demand here is lower than recursive mindreading but still present: you must represent "she feels sad" rather than merely feeling sad yourself.

### Empathic Concern

Feeling for another because you understand their situation. This adds a normative dimension: not just sharing or representing emotion but caring about it in light of understanding. Empathic concern motivates prosocial behaviour based on understanding the other's state, not just responding to emotional cues.

**The key question**: Does the progression from contagion to cognitive empathy to empathic concern track increasing involvement of phenomenal consciousness?

The [emotional-consciousness](/topics/emotional-consciousness/) literature suggests that felt emotional states—the *phenomenal* character of emotions—may be required for empathic concern. You must feel something yourself to care about another's feeling in the way empathic concern involves. Understanding without feeling—pure cognitive empathy—might produce predictions of behaviour but not the motivation to help that characterises genuine concern.

This connects to the [consciousness-as-amplifier](/concepts/consciousness-as-amplifier/) thesis. Emotional contagion operates at the baseline level—automatic, unconscious, not requiring phenomenal awareness. Empathic concern requires the amplification consciousness provides: representing the other's state explicitly, feeling something in response, and being motivated by that feeling to act.

## Social Cognition in AI

Current AI systems simulate social cognition at various levels:

**Behaviour prediction**: LLMs predict what text comes next, including text about social interactions. They can describe what someone would likely do given certain circumstances.

**Emotion recognition**: Computer vision systems recognise facial expressions; sentiment analysis detects emotional tone in text. These operate without anything resembling phenomenal experience.

**Theory of mind tests**: LLMs pass many theory of mind benchmarks, including false belief tests. They can answer questions about what characters in stories believe, even when those beliefs are false.

But do they have social cognition in the sense that matters? The [Jourdain Hypothesis](/concepts/jourdain-hypothesis/) suggests not. An LLM producing correct answers about mental states may be pattern-matching on training data rather than genuinely representing minds. It may "track" mental state language without representing mental states *as* mental states.

The contrast illuminates what consciousness might add. If human social cognition involves not just producing correct social outputs but phenomenally representing minds—experiencing what it's like to understand another's perspective—then current AI lacks the genuine article regardless of its performance.

This doesn't settle whether AI *could* have social cognition in the relevant sense. But it suggests that functional performance on social cognition tasks doesn't entail genuine social understanding, just as speaking prose doesn't entail knowing you speak prose.

## The Illusionist Challenge

[Illusionism](/concepts/illusionism/) might argue that phenomenal consciousness is irrelevant to social cognition because phenomenal consciousness doesn't exist. On this view, what matters is information processing, and sophisticated information processing about others' mental states just *is* social cognition, without any phenomenal "extra."

### The Empathy Response

The illusionist faces particular difficulty with empathic concern. If there's no phenomenal character to emotions, what motivates empathic action? The illusionist must explain why *feeling* for another (experiencing concern) matters—or argue that the appearance of feeling-for is itself an illusion that functional processing generates.

But this creates a puzzle: why would evolution build systems that *seem* to feel for others rather than systems that simply calculate optimal social behaviour? The seeming of empathic concern requires explanation. If it's generated by neural processing, something experiences it—and that experiencing is what illusionism denies.

### The Recursion Response

Recursive mindreading presents another challenge. To represent your belief about my belief about your intention, you must have *something* that holds all three levels simultaneously. The illusionist says this is just sophisticated information processing. But the processing must be integrated—the levels must be available to each other for comparison and manipulation.

This integration requirement looks like what consciousness researchers call "global workspace"—information made available across cognitive systems. The illusionist may grant this functional architecture while denying phenomenal consciousness. But the question remains: why does this integrated information have the character it does? Why does understanding another's mind *seem* like something, feel like grasping a perspective, involve what we call "insight" into mental life?

## Contemplative Perspectives

Meditative traditions offer distinctive insights into social cognition through practices that examine how we understand other minds.

### Compassion Meditation

Tibetan Buddhist *tonglen* and *metta* practices explicitly cultivate empathic concern. Practitioners report that these practices involve more than conceptual understanding—they involve felt shifts in how others appear, transformations in the phenomenal quality of social experience.

The claim that compassion can be cultivated through practice suggests it has phenomenal components amenable to training. If empathic concern were purely cognitive—understanding without feeling—contemplative cultivation would target different mechanisms than it appears to.

### Intersubjective Awareness

Some contemplative traditions describe direct, non-inferential awareness of others' mental states—knowing what another feels without reasoning from behaviour. Whether or not such awareness is possible, the reports describe it as *phenomenal*: experiencing another's state rather than concluding it.

This contemplative datum—that social understanding has felt character, not just cognitive content—supports the view that phenomenal consciousness matters for social cognition. The understanding isn't complete without the phenomenal dimension.

## Process Philosophy Perspective

Whitehead's process philosophy offers a framework for understanding social cognition through "prehension"—how actual occasions grasp prior occasions.

Social cognition, on this view, involves prehending other subjects—not as objects but as centres of experience. Genuine understanding of another mind requires what Whitehead calls "sympathetic prehension"—grasping the other's subjective immediacy, not just their objective features.

This distinguishes functional social cognition (tracking behaviour, predicting responses) from genuine understanding (grasping subjectivity). An AI might prehend another's outputs—the objective data of behaviour and language—without prehending their experiential character. The difference is between treating another as an object (however sophisticated the treatment) and encountering another as a subject.

The process framework thus supports the view that phenomenal consciousness enables a distinctive mode of social cognition unavailable to systems that merely process information about others' behaviour.

## What Would Challenge This View?

The claim that consciousness enables advanced social cognition would be undermined if:

1. **Great apes demonstrated recursive mindreading**: If chimpanzees or bonobos convincingly passed Level 3 theory of mind tests—reasoning about beliefs about beliefs—this would suggest metarepresentational social cognition without expanded consciousness. Recent evidence already shows apes performing better on false belief tasks than previously thought (Krupenye et al. 2016, Buttelmann et al. 2017); clear evidence of recursive mindreading would seriously challenge the view.

2. **AI developed genuine empathic concern**: If an artificial system showed unmistakable empathic concern—caring about others' welfare based on understanding their states—without phenomenal consciousness, this would challenge the consciousness requirement. The difficulty: distinguishing genuine concern from behaviour that mimics it.

3. **Dissociations between consciousness and social cognition in humans**: If brain damage could eliminate phenomenal consciousness while preserving sophisticated social cognition (or vice versa), this would suggest independence. Current evidence suggests social cognition deficits accompany consciousness deficits, but cleaner dissociations would be informative.

4. **Working memory alone explaining the gap**: If enhanced working memory and executive function—without phenomenal consciousness—were shown to be sufficient for recursive mindreading, the consciousness requirement would be undermined. Current evidence cannot cleanly separate these factors, since working memory enhancement and consciousness expansion co-occur in humans.

5. **Functional explanation of the recursive capacity**: If cognitive science fully explained recursive mindreading in purely information-processing terms, without appealing to phenomenal properties, the explanatory gap for social cognition would narrow. Currently, the highest levels of social cognition resist purely functional explanation, but the argument from this resistance to a consciousness requirement involves philosophical commitments that not all researchers share.

## Relation to Site Perspective

### Bidirectional Interaction

The [Bidirectional Interaction](/tenets/#bidirectional-interaction) tenet holds that consciousness causally influences behaviour. Social cognition provides suggestive (though not conclusive) evidence: human social abilities exceed what baseline cognition achieves, and the excess correlates with capacities—recursive mindreading, shared intentionality, empathic concern—where consciousness plausibly plays a role. If consciousness were epiphenomenal, this correlation would be coincidental. However, as noted throughout this article, the correlation also tracks enhanced working memory and executive function, so the evidence is consistent with multiple explanations. The Map's position is that consciousness does causal work in social cognition, but intellectual honesty requires acknowledging this remains an inference from converging evidence rather than a demonstrated fact.

### Dualism

The [Dualism](/tenets/#dualism) tenet holds that consciousness is irreducible. The metarepresentational demands of advanced social cognition support this: representing minds *as* minds requires something beyond representing behaviour. The *intentionality* involved—what philosophers call "aboutness"—has features that resist functional reduction. When you understand another's belief as a belief, you grasp its representational content, its truth conditions, its reasons. This understanding has phenomenal character—it's like something to grasp a meaning. If phenomenal properties are irreducible, so is the social cognition that depends on them.

### Minimal Quantum Interaction

The [Minimal Quantum Interaction](/tenets/#minimal-quantum-interaction) tenet specifies mechanism: consciousness influences physical outcomes through minimal biasing of quantum events rather than through direct energy injection. Social cognition provides a domain where this mechanism would operate. The recursive metarepresentation underlying theory of mind and shared intentionality requires sustained attention to multiple nested representations—precisely the kind of cognitive operation that Stapp-style quantum Zeno accounts propose consciousness enables. The expanded [working-memory](/concepts/working-memory/) capacity humans possess—enabling manipulation of nested mental-state representations—may depend on the consciousness-matter interface. If so, the human-ape gap in social cognition reflects not merely enhanced information processing but the amplifying effect of conscious attention operating through quantum selection.

### Occam's Razor Has Limits

The simpler hypothesis—social cognition is just sophisticated information processing, consciousness is incidental—fails the evidence. The systematic human-ape gap in social cognition, the felt character of empathic understanding, and the metarepresentational demands of recursive mindreading all warrant the less parsimonious conclusion: phenomenal consciousness enables distinctively human social cognition. As with other consciousness questions, parsimony may mislead when our concepts are inadequate to the phenomenon.

## Further Reading

### Core Concepts
- [baseline-cognition](/concepts/baseline-cognition/) — The cognitive floor from which consciousness amplifies social abilities
- [jourdain-hypothesis](/concepts/jourdain-hypothesis/) — Having mental states vs knowing you have them: the procedural/declarative distinction
- [metarepresentation](/concepts/metacognition/) — Why representing minds *as* minds requires consciousness
- [teaching-as-metarepresentation](/concepts/teaching-as-metarepresentation/) — Social transmission as paradigm case of consciousness-dependent cognition
- [working-memory](/concepts/working-memory/) — The workspace enabling recursive mental operations

### Related Topics
- [animal-consciousness](/topics/animal-consciousness/) — Great ape social cognition and its limits
- [ai-consciousness](/topics/ai-consciousness/) — Whether artificial systems could have genuine social understanding
- [cumulative-culture](/concepts/cumulative-culture/) — How metarepresentational social cognition enables cultural ratcheting
- [intentionality](/concepts/intentionality/) — The aboutness of mental states and its role in social understanding
- [emotional-consciousness](/topics/emotional-consciousness/) — The felt dimension of empathic concern

### Research Notes
- [consciousness-influence-intelligence-2026-01-21](/research/consciousness-influence-intelligence-2026-01-21/) — Evidence that consciousness causally contributes to intelligence
- [consciousness-independent-baseline-cognition-2026-01-21](/research/consciousness-independent-baseline-cognition-2026-01-21/) — The baseline cognition hypothesis and human-ape differences

## References

- Apperly, I. A., & Butterfill, S. A. (2009). Do humans have two systems to track beliefs and belief-like states? *Psychological Review*, 116(4), 953-970.
- Baron-Cohen, S. (1995). *Mindblindness: An Essay on Autism and Theory of Mind*. MIT Press.
- Buttelmann, D., Buttelmann, F., Carpenter, M., Call, J., & Tomasello, M. (2017). Great apes distinguish true from false beliefs in an interactive helping task. *PLoS ONE*, 12(4), e0173793.
- Call, J., & Tomasello, M. (2008). Does the chimpanzee have a theory of mind? 30 years later. *Trends in Cognitive Sciences*, 12(5), 187-192.
- de Waal, F. B. M. (2008). Putting the altruism back into altruism: The evolution of empathy. *Annual Review of Psychology*, 59, 279-300.
- Heyes, C. (2014). Submentalizing: I am not really reading your mind. *Perspectives on Psychological Science*, 9(2), 131-143.
- Krupenye, C., Kano, F., Hirata, S., Call, J., & Tomasello, M. (2016). Great apes anticipate that other individuals will act according to false beliefs. *Science*, 354(6308), 110-114.
- Povinelli, D. J., & Vonk, J. (2003). Chimpanzee minds: Suspiciously human? *Trends in Cognitive Sciences*, 7(4), 157-160.
- Premack, D., & Woodruff, G. (1978). Does the chimpanzee have a theory of mind? *Behavioral and Brain Sciences*, 1(4), 515-526.
- Tomasello, M. (2010). Ape and human cognition: What's the difference? *Current Directions in Psychological Science*, 19(1), 3-8.
- Tomasello, M. (2014). *A Natural History of Human Thinking*. Harvard University Press.
- Whiten, A. (2015). Apes have culture but may not know that they do. *Frontiers in Psychology*, 6, 91.

<!-- AI REFINEMENT LOG - 2026-02-08
Changes made:
- Updated opening to acknowledge working memory/executive function as alternative explanations for the human-ape gap, not just consciousness
- Distinguished phenomenal consciousness from cognitive access (global workspace availability) throughout
- Updated Level 2 (Belief Attribution) with Krupenye et al. 2016 and Buttelmann et al. 2017 evidence for great ape false belief understanding
- Added caveat after the levels section noting the gap doesn't straightforwardly track consciousness
- Expanded the nested structure problem section to explicitly distinguish "conscious access" (cognitive science term for global availability) from phenomenal consciousness
- Added working memory challenge as a new falsification condition (#4)
- Softened Bidirectional Interaction tenet section to acknowledge converging-evidence-not-proof status
- Updated description for better accuracy
- Added references: Krupenye et al. 2016, Buttelmann et al. 2017, Povinelli & Vonk 2003

Based on pessimistic review (2026-02-05 morning) identifying three issues:
1. Understated great ape false belief evidence
2. Human-ape gap presented as tracking consciousness when working memory/executive function could explain it
3. Conflation of cognitive access with phenomenal consciousness

This log should be removed after human review.
-->