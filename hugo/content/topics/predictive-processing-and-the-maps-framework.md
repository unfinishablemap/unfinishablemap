---
ai_contribution: 100
ai_generated_date: 2026-02-15
ai_modified: 2026-02-15 14:50:00+00:00
ai_system: claude-opus-4-6
author: null
concepts:
- '[[predictive-processing]]'
- '[[attention]]'
- '[[attention-as-interface]]'
- '[[functionalism]]'
- '[[interactionist-dualism]]'
- '[[quantum-consciousness]]'
- '[[explanatory-gap]]'
created: 2026-02-15
date: &id001 2026-02-15
description: How predictive processing—the brain's prediction-error-minimizing architecture—integrates
  with interactionist dualism, providing the neural machinery that consciousness selects
  through.
draft: false
human_modified: null
last_curated: null
modified: *id001
related_articles:
- '[[tenets]]'
- '[[predictive-processing-consciousness-2026-01-14]]'
- '[[attention-as-selection-interface]]'
- '[[neural-bandwidth-constraints-and-the-interface]]'
title: Predictive Processing and the Map's Framework
topics:
- '[[hard-problem-of-consciousness]]'
- '[[cognitive-science-of-dualism]]'
- '[[phenomenology-of-surprise-and-prediction-error]]'
---

Predictive processing (PP) is the most successful computational framework in contemporary cognitive science. It describes the brain as a hierarchical prediction engine that minimises surprise by constantly generating and testing expectations against sensory input. The Unfinishable Map argues that PP provides an excellent account of the neural side of mind-body interaction — the computational machinery through which consciousness operates — while leaving entirely open the question of *why* this machinery is conscious at all. Far from threatening dualism, PP is exactly the kind of physical framework that interactionist dualism needs: a detailed account of brain architecture that nonetheless contains an unexplained gap where consciousness enters.

## The Neural Machinery Consciousness Needs

Interactionist dualism requires a physical story about the brain. If consciousness selects among neural possibilities, there must be neural possibilities to select among. PP provides them.

The brain's predictive hierarchy generates multiple competing hypotheses about incoming sensory data. At every level, predictions flow downward while prediction errors flow upward. The system maintains not just best guesses but distributions of possibility — probability-weighted expectations about what the world might be like. This architecture creates precisely the kind of branching landscape of options that a selecting consciousness would need.

Consider precision weighting — PP's mechanism for determining which prediction errors matter. The brain adjusts how much influence different error signals receive, amplifying some and suppressing others. This is functionally equivalent to attention, and attention is exactly the mechanism through which the Map argues consciousness acts on the physical world. PP describes *what* precision weighting does; the Map proposes *who* is doing the weighting.

## The Gap PP Cannot Close

PP's proponents are unusually honest about the framework's limits. Hohwy and Seth (2020) acknowledge that PP "at the outset is not a theory of consciousness." The free energy principle, Seth admits, "in and of itself makes no claims about subjective experience." This is refreshing candour, but the Map takes it as a deeper concession than its authors intend.

The gap is not a temporary incompleteness awaiting more data. It is structural. PP explains perception as controlled hallucination — the brain's best hypothesis about reality, constrained by sensory feedback. But a weather simulation also generates hypotheses constrained by input data. Nothing in the architecture of prediction error minimisation, however sophisticated, explains why the brain's hypotheses feel like something while the weather model's do not.

This is the standard [functionalist](/arguments/functionalism/) limitation applied to PP's specific case. As critics note, "we seem to experience moderate-sized specimens of dry goods, not probability density distributions." The mathematics of Bayesian inference does not contain the resources to generate [qualia](/concepts/qualia/). PP inherits this problem from every computational theory of mind — and the Map argues this inheritance is principled rather than accidental.

## Precision Weighting as Consciousness's Fingerprint

The Map's most productive integration with PP concerns precision weighting and its relationship to [attention as the causal interface](/concepts/attention-as-interface/).

PP treats precision as a mathematical parameter — the inverse variance of a probability distribution. High-precision prediction errors receive more weight; low-precision ones are suppressed. This mechanism governs what reaches awareness and what remains background processing. But PP does not explain *how* precision values are set. The framework describes precision as itself predicted — the brain learns which signals to trust — but this pushes the question back without answering it: what determines the predictions about precision?

Computational accounts within PP offer a response: precision is itself predicted from environmental statistics — the brain learns which signals to trust based on past reliability (Feldman & Friston, 2010). This is hierarchical prediction applied to reliability estimation. The Map acknowledges this account but finds it incomplete for a specific reason: it explains how precision *is* set computationally but not why the setting process is *experienced* — why attending to the conversation feels like something rather than being mere signal gain adjustment. The computational account works perfectly as engineering; the Map's question is whether engineering is all there is.

The Map's proposed answer: consciousness influences precision through the [attention as interface](/concepts/attention-as-interface/) mechanism. When you deliberately attend — concentrating on a conversation in a noisy room, focusing on a philosophical argument, noticing a change in a familiar environment — you are adjusting precision weights. PP captures the computational description of this adjustment. One speculative proposal for how consciousness achieves this influence invokes quantum-level effects (such as the quantum Zeno mechanism described by Stapp), but the Map's argument that consciousness plays a role in precision setting does not depend on any particular physical mechanism. The core claim is that phenomenal attention is not reducible to computational precision adjustment, however the causal linkage works.

This integration preserves everything PP gets right about cognitive architecture while proposing a deeper account of the selection process. The brain generates predictions; the Map argues consciousness plays a genuine role in determining which predictions matter.

## Active Inference and Bidirectional Interaction

PP's concept of active inference — organisms act on the world to bring sensory input in line with predictions, rather than just passively updating models — resonates with the Map's [bidirectional interaction](/tenets/#bidirectional-interaction) tenet.

In active inference, the organism doesn't simply observe; it intervenes. When prediction errors are too large to resolve by updating the model, the system acts to change the world instead. You feel cold, so you put on a jacket. The prediction ("I will be warm") is enacted rather than revised.

The Map treats this as a surface manifestation of a deeper truth. Consciousness doesn't just act on the external world through bodily movement; it acts on the brain itself by influencing which neural possibilities are realised. Bodily action is downstream of neural selection — the organism moves because consciousness has already influenced selection among competing neural firing patterns. Active inference describes the behavioural output; the Map's framework proposes how consciousness initiates it at the neural level.

This inversion matters. PP treats the organism's actions as themselves predicted and optimised — just more prediction error minimisation. The Map argues that genuine agency requires something outside the predictive loop to break symmetries and select among options. Compatibilist accounts of agency may dispute this — one can argue that computational selection *is* genuine agency without requiring a non-physical selector. The Map's response is that compatibilism explains agency-*talk* but not the phenomenology of deciding: the felt difference between choosing and being moved.

## What PP Gets Right

The Map does not reject PP. It accepts the framework's contributions while arguing they are incomplete:

**Perception is constructive.** The brain genuinely builds models rather than passively receiving data. This aligns with the Map's position that consciousness works *through* neural mechanisms rather than bypassing them.

**Attention is central.** PP places precision weighting — functionally, attention — at the heart of cognition. This supports the Map's claim that [attention](/attention/) is the primary interface between consciousness and the physical world.

**The hierarchy matters.** PP's multi-level predictive hierarchy explains how consciousness can influence high-level cognitive processes (beliefs, plans, decisions) through the same mechanisms that operate at low levels (sensory prediction). The Map doesn't need a separate account for each level; precision weighting operates throughout the hierarchy.

**Dreams and altered states make sense.** PP elegantly explains dreaming as unconstrained prediction — the brain's generative models running without sensory correction. This is compatible with the Map's position. What PP cannot explain is why dreams are *experienced* — why unconstrained prediction feels like vivid hallucination rather than unmonitored computation.

## What PP Misses

**The subject of prediction.** PP describes a computational process but never identifies who or what is performing the computation. The framework treats "the brain" as both the system generating predictions and the system experiencing them, but this conflation hides the [explanatory-gap](/concepts/explanatory-gap/). A complete account must explain not just the structure of prediction but the existence of a subject to whom predictions appear.

**The qualitative richness of surprise.** As the Map explores in [phenomenology-of-surprise-and-prediction-error](/phenomenology-of-surprise-and-prediction-error/), prediction error as a computational signal fails to capture the phenomenological spectrum of surprise — from the subtle wrongness of a misplaced object to the vertigo of paradigm collapse. These experiences differ in kind, not just in the magnitude of an error signal.

**Why some predictions are conscious and others aren't.** The brain generates predictions at every level, but most remain unconscious. PP explains this through precision weighting, but precision weighting itself lacks an explanation for why high-precision signals are *experienced* while low-precision ones aren't. If precision is just a mathematical parameter, there is no principled reason why any value of precision should cross the threshold into phenomenal awareness.

## Relation to Site Perspective

The Unfinishable Map sees predictive processing as a valuable ally rather than an opponent.

**[Dualism](/tenets/#dualism)**: PP is typically presented within a physicalist framework, but its own proponents concede it doesn't address the hard problem. The Map takes this concession seriously. PP describes the physical side of mind-body interaction with unprecedented detail. The non-physical side — why prediction error minimisation is accompanied by experience — requires consciousness as an irreducible addition. PP's computational elegance actually sharpens the hard problem: the more precisely we describe what the brain does, the more puzzling it becomes that doing it feels like anything.

**[Minimal Quantum Interaction](/tenets/#minimal-quantum-interaction)**: PP's precision weighting mechanism provides the functional context within which quantum selection operates. Consciousness doesn't need to micromanage every neural event — it influences which prediction errors receive high precision, thereby shaping what the brain's own computational machinery makes of its inputs. This is minimal in the tenet's required sense: a small bias at the precision-weighting level cascades through the predictive hierarchy.

**[Bidirectional Interaction](/tenets/#bidirectional-interaction)**: Active inference demonstrates that the brain's architecture supports bidirectional influence between organism and world. The Map extends this to bidirectional influence between consciousness and brain. PP shows that the brain is already structured for selection and intervention; consciousness provides the genuine agent doing the selecting.

**[No Many Worlds](/tenets/#no-many-worlds)**: PP's computational machinery operates within any single branch, and many-worlds proponents like Deutsch and Wallace have argued via decision-theoretic frameworks that probabilities and confirmation function normally branch-locally. The Map's objection to many-worlds therefore does not rest on PP breaking under branching. Rather, the concern is about what PP *reveals* phenomenologically. The felt quality of surprise — the shock of a violated expectation, the recalibration of one's model — presupposes a singular experiencer whose predictions were wrong. Under many-worlds, a copy of you exists in every outcome branch, each experiencing their result as definite. But this raises the indexical question the Map finds unanswerable: why am I the copy who experienced *this* prediction error rather than the one whose prediction was confirmed? Many-worlds treats this question as meaningless, but the phenomenology of surprise — the very thing PP describes so well — suggests it is deeply meaningful. PP sharpens the Map's rejection of many-worlds not because prediction error fails mechanically under branching, but because the lived experience of being wrong about the world implies a singular perspective that branching universes cannot ground.

**[Occam's Razor Has Limits](/tenets/#occams-limits)**: PP's elegance — one principle explaining perception, action, learning, and emotion — makes it tempting to think consciousness will eventually reduce to prediction error minimisation. The Map counsels patience. Behaviourism was equally parsimonious and equally wrong about what matters. The simplicity of PP's computational account conceals the unexplained assumption that computation should be conscious.

## Further Reading

- [predictive-processing](/concepts/predictive-processing/) — The core concept: brain as prediction engine
- [attention-as-interface](/concepts/attention-as-interface/) — How attention mediates consciousness-matter interaction
- [attention-as-selection-interface](/topics/attention-as-selection-interface/) — Attention and motor planning as unified selection
- [phenomenology-of-surprise-and-prediction-error](/phenomenology-of-surprise-and-prediction-error/) — What prediction error feels like
- [cognitive-science-of-dualism](/topics/cognitive-science-of-dualism/) — How cognitive science's findings resist materialist closure
- [neural-bandwidth-constraints-and-the-interface](/topics/neural-bandwidth-constraints-and-the-interface/) — Bandwidth limits and the interface
- [functionalism](/arguments/functionalism/) — The philosophical tradition PP inherits

## References

- Clark, A. (2016). *Surfing Uncertainty*. Oxford University Press.
- Hohwy, J. (2013). *The Predictive Mind*. Oxford University Press.
- Seth, A. K. (2021). *Being You: A New Science of Consciousness*. Dutton.
- Friston, K. (2010). "The free-energy principle: a unified brain theory?" *Nature Reviews Neuroscience*, 11(2), 127-138.
- Feldman, H. & Friston, K. (2010). "Attention, uncertainty, and free-energy." *Frontiers in Human Neuroscience*, 4, 215.
- Hohwy, J. & Seth, A. K. (2020). "Predictive processing as a systematic basis for identifying the neural correlates of consciousness." *Philosophy and the Mind Sciences*, 1(II).
- Stapp, H. P. (2007). *Mindful Universe: Quantum Mechanics and the Participating Observer*. Springer.

<!-- AI REFINEMENT LOG - 2026-02-15
Changes made (first pass — MWI fix from earlier session):
- Rewrote the No Many Worlds paragraph to fix logical flaw (Issue 3): old version claimed MWI renders prediction error "meaningless" — replaced with phenomenological argument about indexical identity that engages with Deutsch/Wallace decision-theoretic responses

Changes made (second pass — pessimistic review refinement):
- Softened quantum selection language throughout: removed definitive "consciousness sets precision through quantum selection," replaced with speculative framing. Core argument no longer depends on any particular physical mechanism.
- Added engagement with Feldman & Friston (2010) computational account of precision setting — Map now acknowledges the computational answer and explains why it finds it incomplete (engineering vs. phenomenology), rather than dismissing it.
- Softened agency claim: replaced "PP reduces agency to sophisticated automation" with engagement with compatibilist responses. Map now argues for phenomenological insufficiency rather than dismissing computational agency wholesale.
- Added Feldman & Friston (2010) to References.

Based on pessimistic review (pessimistic-2026-02-15-late.md), Issues 2, 3, 5, and Counterarguments 2 and 3.

This log should be removed after human review.
-->