---
title: "Metarepresentation and Phenomenal Consciousness"
created: 2026-01-21
modified: 2026-01-21
human_modified: null
ai_modified: 2026-01-22T14:00:00+00:00
draft: false
topics:
  - "[[hard-problem-of-consciousness]]"
  - "[[ai-consciousness]]"
concepts:
  - "[[theory-of-mind]]"
  - "[[metacognition]]"
  - "[[cognitive-phenomenology]]"
  - "[[minimal-consciousness]]"
  - "[[baseline-cognition]]"
  - "[[consciousness-as-amplifier]]"
  - "[[higher-order-theories]]"
  - "[[introspection]]"
  - "[[animal-consciousness]]"
  - "[[illusionism]]"
  - "[[decoherence]]"
  - "[[witness-consciousness]]"
  - "[[semantic-memory]]"
  - "[[phenomenology-of-choice]]"
  - "[[motor-selection]]"
  - "[[binding-problem]]"
  - "[[teaching-as-metarepresentation]]"
related_articles:
  - "[[tenets]]"
  - "[[consciousness-independent-baseline-cognition-2026-01-21]]"
ai_contribution: 100
author: null
ai_system: claude-opus-4-5-20251101
ai_generated_date: 2026-01-21
last_curated: null
last_deep_review: 2026-01-21T18:03:47+00:00
---

Knowing that you know is not the same as knowing. Metarepresentation—representing your own representations as representations—requires a distinctive cognitive operation that may depend on phenomenal consciousness. Great apes possess knowledge but may not know they possess it. Humans not only know; we know that we know, and can take our knowledge as an object of further thought. This metarepresentational capacity underpins cumulative culture, explicit reasoning, and deliberate self-improvement. If metarepresentation requires phenomenal consciousness, it provides strong evidence for the [[tenets#^bidirectional-interaction|Bidirectional Interaction]] tenet: consciousness doesn't merely accompany cognition but enables cognitive capacities that would otherwise be impossible.

The Unfinishable Map proposes that the human-great ape intelligence gap tracks consciousness-dependent capacities. Metarepresentation may be the clearest example: a cognitive operation requiring you to stand back from your own mental states, recognise them *as* mental states, and operate on them as objects. This "standing back" appears to require the kind of phenomenal distance that consciousness provides.

## What Metarepresentation Is

Metarepresentation involves three nested levels:

1. **First-order representation**: Representing the world (e.g., knowing there are nuts in the tree)
2. **Second-order representation**: Representing your first-order representations (e.g., believing that you know there are nuts in the tree)
3. **Metarepresentation proper**: Representing your representations *as* representations—knowing that your belief is a belief, that your knowledge is knowledge, that your perception might differ from reality

The third level is crucial. Many animals show evidence of second-order states: uncertainty monitoring, strategic information-seeking, adjusting confidence. But these might operate procedurally—functional states that guide behaviour without explicit representation of themselves as mental states. Metarepresentation requires treating your mental states as the kind of thing that *can* be represented, examined, and evaluated.

The [[phenomenology-of-choice|phenomenology of deliberate choice]] illustrates this structure. When you genuinely choose between options, you represent your possible actions as possible actions—not merely act on the strongest impulse but stand back from the options, recognise them as alternatives you could take, and select among them. This choosing-as-metarepresentation distinguishes human deliberation from sophisticated animal behaviour. The ape may have preferences; the human recognises having preferences and can take them as objects of further evaluation.

### Theory of Mind Levels and Metarepresentational Demands

[[theory-of-mind|Theory of mind]] admits of levels, and mapping these levels to metarepresentational demands clarifies what consciousness contributes. The framework distinguishes:

**Level 0 (Behaviour Prediction)**: Predicting action from observable regularities. No mental state attribution, no metarepresentation required. Associative learning suffices.

**Level 1 (Perception Attribution)**: Understanding what others see. Great apes pass Level 1 tests—tracking gaze, understanding barriers. But Level 1 may operate through geometric tracking (she-barrier-object relations) without representing perceptual states *as* mental states. First-order processing may suffice.

**Level 2 (Belief Attribution)**: Understanding that others have beliefs that may differ from reality. Here metarepresentation enters. To predict someone will act on a *false* belief, you must represent their belief as a belief—as a representation that could be wrong. This requires standing back from the belief itself to grasp it as a mental state subject to evaluation. First-order metarepresentation: representing beliefs AS beliefs.

**Level 3+ (Recursive Mindreading)**: "She thinks that I think the food is hidden." Nested attribution requires second-order metarepresentation—representing others' metarepresentations. You must hold your belief, their belief about your belief, and your awareness of that relationship simultaneously. The binding requirement intensifies: multiple representational levels must remain distinct yet unified.

The hierarchy maps onto working memory demands. Level 1 may require only tracking one relationship (agent-object). Level 2 requires tracking a representation of the world versus the world itself (2+ items). Level 3+ requires tracking nested representations (3+ items) while keeping each level distinct. The human-great ape working memory gap (7±2 versus 2±1 items) may explain where the metarepresentational threshold falls.

This framework predicts: where theory of mind fails in great apes should correlate with where metarepresentation fails. The evidence confirms this. Great apes show robust Level 1 (perception tracking) and contested Level 2 (belief understanding remains debated), but no clear evidence of Level 3 (recursive mindreading). The pattern suggests the metarepresentational threshold lies between Levels 1 and 2—precisely where consciousness-dependent operations begin.

### Teaching as Paradigm Case

[[teaching-as-metarepresentation|Teaching]] provides perhaps the clearest paradigm case of metarepresentation in action. To teach requires simultaneously maintaining at least five nested representational levels:

1. First-order knowledge (knowing something about the world)
2. Second-order representation (knowing that you know)
3. Theory of mind (representing the learner's knowledge state)
4. Gap representation (representing the relation between your knowledge and their ignorance)
5. Pedagogical action (adjusting behaviour specifically to bridge the gap)

This structure makes the metarepresentational demand explicit. Without knowing that you know, you cannot recognise that another doesn't know what you know. Without representing that gap as a gap, you cannot act to bridge it. Teaching requires the full metarepresentational stack operating simultaneously—a feat that loads heavily on working memory and appears to require phenomenal consciousness.

The great ape evidence is striking. Despite decades of observation and sophisticated social learning capacities, great apes rarely if ever teach in the human sense. Chimpanzee mothers tolerate their infants' proximity while cracking nuts or fishing for termites, but they do not slow their demonstrations, highlight key features, or adjust based on the learner's developing understanding. Learning happens, but through tolerated scrounging and observation rather than deliberate transmission. If teaching required only functional processing, great apes' comparable neural resources should suffice. The absence suggests metarepresentation—and therefore consciousness—is the limiting factor.

### The Jourdain Hypothesis

Andrew Whiten (2015) articulates what might be called the Jourdain Hypothesis, after Molière's character who discovered he had been speaking prose all his life without knowing it. Great apes, Whiten argues, may have culture—tool-use traditions, grooming patterns, food preferences that vary between groups—but not *know* they have culture.

The [[baseline-cognition]] framework elaborates this distinction. Great apes exemplify sophisticated baseline cognition—what neural systems achieve without substantial conscious contribution. They possess procedural metacognition (feelings that guide behaviour) without declarative metacognition (explicit knowledge of mental states). The difference between having mental states and representing oneself as having them marks the boundary between baseline and consciousness-amplified cognition.

This matters because cumulative culture requires metarepresentation. To improve a tool, you must represent the tool-making process *as a process*—as a way of doing things that could be done differently. To teach effectively, you must represent your knowledge *as knowledge* that another lacks. To innovate deliberately, you must recognise current practices *as practices* subject to modification.

Apes transmit cultural knowledge through emulation and social learning. But they don't appear to think "this is how we do it" in a way that enables questioning whether it's the best way. Without metarepresentation, cultural accumulation stalls—each generation learns what the previous generation knew, but cannot systematically improve upon it.

### Tip-of-the-Tongue Evidence

The tip-of-the-tongue (TOT) phenomenon provides direct evidence of metarepresentation in action. During TOT states, you know you know something without being able to retrieve it. More remarkably, you can assess features of the unretrieved knowledge—its length, first letter, similar-sounding words—despite lacking access to the knowledge itself.

TOT states demonstrate metarepresentational structure: you represent your own knowledge state (I know this word), represent properties of that knowledge (it starts with 'M', has three syllables), and represent the relationship between your current access and the knowledge itself (I can't retrieve it now but would recognise it). This layered structure cannot be merely procedural—it requires explicit representation of representations.

Interestingly, the phenomenology of TOT states involves a distinctive felt quality: the "tip-of-the-tongue" feeling that signals impending retrieval. This [[cognitive-phenomenology|cognitive phenomenology]]—the qualitative character of knowing-about-knowing—may be what metarepresentation requires.

## Why Metarepresentation May Require Consciousness

Several considerations suggest metarepresentation depends on phenomenal consciousness rather than merely functional processing.

### The Self-as-Object Problem

To represent your representations as representations, you must take yourself as object. But the self doing the representing is the same self being represented. This self-reflexive operation requires a kind of doubled awareness: being aware *of* your mental states while being aware *as* the subject having them.

Phenomenal consciousness provides exactly this structure. Conscious experience involves both content (what you're aware of) and the fact of awareness itself (that you're aware). When you introspect, you bring both into view—the thought and the thinking, the perception and the perceiving. Without this doubled structure, metarepresentation seems incoherent: what would represent the representations if not an aware subject?

[[higher-order-theories|Higher-Order Thought]] theories attempt to naturalise this structure: a mental state becomes conscious when targeted by a higher-order thought. But the higher-order thought must itself be about something—about the first-order state being a state. This "about-ness" is precisely what metarepresentation requires. HOT theories may inadvertently confirm that metarepresentation presupposes consciousness rather than explaining it.

### The Binding Requirement

Metarepresentation requires holding multiple representations in relation: the representation, the representation of it, and the relationship between them. This multi-level structure demands phenomenal unity—experiencing all three aspects together as a unified cognitive act.

[[working-memory|Working memory]] research supports this. Metarepresentational tasks (explicit metacognitive judgments, strategic reasoning about one's own knowledge) load heavily on working memory. If working memory depends on conscious access—as [[global-workspace-theory|Global Workspace Theory]] proposes—metarepresentation inherits this dependence.

Great apes' limited working memory (2±1 items versus human 7±2) may explain their metarepresentational limitations. Holding a representation, a representation of that representation, and their relationship simultaneously may exceed their working memory capacity. The expansion enabling human metarepresentation may be the expansion of conscious workspace.

### The Phenomenology of Knowing-That-You-Know

The experience of recognising your own knowledge has distinctive phenomenal character—what might be called *epistemic self-awareness*. Consider:

- The feeling of certainty when you know you're right
- The feeling of doubt when you recognise your uncertainty
- The aha moment when insight arrives
- The tip-of-the-tongue frustration of almost-knowing

These [[epistemic-emotions|epistemic emotions]] are metacognitive: they concern your relationship to knowledge rather than the world directly. They have phenomenal character—there is something it is like to feel certain, to doubt, to suddenly understand. This phenomenal dimension may be constitutive rather than incidental: without the felt quality, there might be no genuine metarepresentation, only functional processing that mimics it.

The conservativist position on [[cognitive-phenomenology]]—that thinking has no proprietary phenomenal character—would undermine this argument. But the evidence favours liberalism: epistemic emotions, TOT states, and insight experiences all involve phenomenology that cannot reduce to sensory accompaniments. If cognitive phenomenology exists, metarepresentation's dependence on consciousness follows naturally.

## Comparative Evidence

The metarepresentation hypothesis generates testable predictions about species differences.

### Great Ape Metacognition

Chimpanzees, bonobos, and orangutans show sophisticated metacognition:
- Uncertainty monitoring (seeking information when confidence is low)
- Strategic information-seeking (choosing informative options)
- Understanding others' knowledge states (adjusting behaviour based on what others know)
- Recognising themselves in mirrors

But this metacognition appears procedural: functional states that influence behaviour without explicit representation of themselves as mental states. The evidence:

**No teaching**: Great apes rarely if ever teach in the human sense—deliberately transmitting knowledge by representing knowledge-states in self and other. They learn socially, but the transmission is emulative rather than pedagogical.

**No cumulative culture**: Great ape traditions show remarkable stability across generations but little cumulative improvement. Without metarepresenting their practices as practices, they cannot deliberately refine them.

**Limited theory of mind**: Great apes understand others' goals, perceptions, and some knowledge states. But they may not represent these as *mental states*—as the kind of thing that involves inner experience and could be mistaken. Level 1 theory of mind (understanding what others see) may not require metarepresentation; Level 2 (understanding that others' perspectives differ from one's own) may require it.

### Human Development

Human metarepresentational capacities develop gradually:

**18-24 months**: Joint attention, pointing, recognising intentional action
**3-4 years**: False-belief understanding, pretend play with objects standing for other objects
**4-5 years**: Explicit understanding that beliefs can be false, that appearance differs from reality
**6-7 years**: Understanding that knowledge is representation, that the same thing can be represented differently

This developmental trajectory mirrors the emergence of explicit consciousness. Young children show procedural metacognition before developing metarepresentational capacities. The transition involves both cognitive maturation and expanded phenomenal consciousness—children become explicitly aware of their own minds.

### The Dissociation Pattern

The comparative and developmental evidence reveals a consistent pattern: sophisticated information processing can occur without metarepresentation, but metarepresentation requires something more—plausibly, phenomenal consciousness.

Great apes process information flexibly, monitor uncertainty, and adjust behaviour strategically. They lack the ability to represent their own knowledge as knowledge, their practices as practices, their beliefs as beliefs. This dissociation suggests metarepresentation isn't merely more complex information processing; it requires a qualitatively different capacity that consciousness provides.

## The Illusionist Challenge

[[illusionism|Illusionists]] might argue that apparent metarepresentation is merely functional processing generating the *illusion* of knowing-that-you-know. There's no genuine phenomenal dimension; cognitive systems simply represent their own states in ways that seem (but aren't) phenomenally rich.

This response faces the characteristic regress problem. For metarepresentation to *seem* phenomenally significant—for there to be an appearance of knowing-that-you-know—something must experience that seeming. The illusion of metarepresentation would itself require a subject to be fooled. That subject's experiencing of the illusion is precisely what illusionists deny exists.

More specifically, illusionism must explain:

1. **TOT phenomenology**: The distinctive feeling of almost-knowing. If this is illusory, what generates the illusion?
2. **Epistemic emotions**: The felt quality of certainty, doubt, insight. These concern metacognitive states; reducing them to functional processing still requires explaining why they feel like anything.
3. **The developmental trajectory**: Why do metarepresentational capacities emerge with expanded consciousness? If consciousness is illusory, the correlation is coincidental.

Keith Frankish's quasi-phenomenal account proposes that what seems like phenomenal consciousness is actually a representation of phenomenal-seeming properties. But this move creates a specific problem for metarepresentation.

Consider the structure of quasi-phenomenal metarepresentation. On Frankish's view, when you "know that you know," you would be:
1. Having a first-order state (representing the world)
2. Having a quasi-phenomenal representation of that state (representing it as seeming conscious)
3. Having a *further* quasi-phenomenal representation of that quasi-phenomenal state (representing your knowing-seeming as itself seeming conscious)

But what makes level (3) seem like genuine knowing-that-you-know rather than mere functional self-monitoring? The quasi-phenomenal framework must answer: it *seems* like knowing-that-you-know because the system represents it as having that quasi-phenomenal character. Yet this generates the very metarepresentational structure it was meant to explain. The seeming of knowing-that-you-know requires representing your representations-of-seeming as representations-of-seeming—precisely the metarepresentational capacity at issue.

The regress problem sharpens: either quasi-phenomenal properties are themselves phenomenally conscious (undermining illusionism), or they aren't (leaving unexplained why metarepresentation should feel like anything). The illusion of metarepresentation would require metarepresenting the illusion—using the capacity to explain it away.

## Contemplative Evidence

Contemplative traditions provide distinctive evidence for metarepresentation's dependence on phenomenal consciousness.

### Witness Consciousness

[[witness-consciousness|Witness consciousness]] practices explicitly cultivate metarepresentational capacity. The practitioner learns to observe their own mental contents—thoughts, emotions, sensations—without identification. This "witnessing" is precisely metarepresentation: representing your representations as representations, as objects within awareness rather than as the totality of awareness.

Notably, such practices require phenomenal awareness to work. The instruction is never "process your mental states differently" but "observe your mental states." Observation implies a conscious observer. The capacity develops through deliberate cultivation of conscious attention, suggesting the two are intimately linked.

### The Metacognitive Shift

Experienced meditators report a characteristic shift: thoughts come to be experienced as events within awareness rather than as the voice of the self. This shift has metarepresentational structure—thoughts are now represented as thoughts, as mental events that arise and pass, rather than as simply true or as instructions to be followed.

The shift is phenomenal: there is something it is like to experience thoughts as objects. This phenomenology cannot reduce to functional changes in processing, because the functional changes (reduced reactivity, increased flexibility) depend on the phenomenal change (experiencing thoughts as objects). Meditators who merely *process* thoughts differently without experiencing them differently do not report the same benefits.

### Buddhist Psychology

The Abhidharma tradition distinguishes consciousness (*citta*) from mental factors (*cetasika*). Metarepresentation operates through mental factors like *manasikāra* (attention), *vitakka* (applied thought), and *vicāra* (sustained thought). Crucially, these factors require consciousness as their support—they cannot operate in the absence of awareness.

This framework suggests metarepresentation is a capacity consciousness enables rather than a phenomenon independent of consciousness. The explicit phenomenological analysis of contemplative traditions, refined over millennia, consistently places metarepresentation within the domain of conscious awareness.

## Process Philosophy Perspective

Alfred North Whitehead's process philosophy illuminates why metarepresentation might require consciousness. For Whitehead, each actual occasion has a "subjective form"—a how-it-feels from the inside. Consciousness involves high-grade actual occasions capable of "intellectual feelings"—prehending abstract concepts and relationships.

Metarepresentation requires what Whitehead calls "propositional feelings": feeling the relationship between something actual and something potential. To know that you know, you must grasp the relationship between yourself (actual), your knowledge (actual), and the possibility of not knowing (potential). This triadic structure requires consciousness because it involves feeling possibilities as possibilities—something only subjects capable of intellectual feeling can achieve.

The Whiteheadian framework explains why great apes might have consciousness without metarepresentation. Their occasions may involve genuine feeling—phenomenal experience—without reaching the complexity required for propositional and intellectual feelings. Metarepresentation emerges when consciousness achieves sufficient complexity to feel relationships between actualities and potentialities, not merely to feel actualities directly.

## What Would Challenge This View?

Several findings would substantially weaken the claim that metarepresentation requires phenomenal consciousness:

1. **Great apes demonstrating explicit metarepresentation**: If experiments revealed that chimpanzees or bonobos can represent their beliefs as beliefs—not merely act on them strategically but demonstrate understanding that beliefs are representations that could be false—the species boundary would shift. The hypothesis would need modification to explain why great ape consciousness suffices for metarepresentation after all.

2. **Metarepresentation without TOT phenomenology**: If neurological patients lost the phenomenal aspects of metacognition (the feeling of knowing, tip-of-tongue phenomenology) while retaining functional metarepresentation, this would suggest the phenomenal dimension is incidental. Currently, metacognitive impairment correlates with phenomenal changes.

3. **AI achieving genuine metarepresentation**: If artificial systems demonstrated genuine metarepresentation—not merely producing outputs that describe their own states but actually representing their representations as representations—while being demonstrably non-conscious, the linkage would fail. Current AI produces metacognitive-seeming outputs without evidence of genuine metarepresentation.

4. **Illusionism explaining metarepresentational phenomenology**: If illusionists provided a compelling account of how the phenomenology of knowing-that-you-know arises from purely functional processing—explaining TOT states, epistemic emotions, the developmental trajectory—without invoking genuine phenomenal consciousness, the dependence claim would weaken.

5. **Dissociation in human subjects**: If research revealed humans with intact phenomenal consciousness but impaired metarepresentation, or intact metarepresentation but impaired phenomenal consciousness, the necessary connection would be undermined. Current evidence shows them co-varying.

## Relation to Site Perspective

### Dualism

The [[tenets#^dualism|Dualism]] tenet asserts consciousness is irreducible to physical processes. Metarepresentation's apparent dependence on phenomenal consciousness supports this: if representing representations as representations requires something over and above functional processing—requires the "standing back" that consciousness provides—then metarepresentation itself evidences consciousness's irreducibility. No purely functional account explains why metarepresentation requires phenomenal awareness; the requirement suggests consciousness contributes something functions alone cannot provide.

### Bidirectional Interaction

The [[tenets#^bidirectional-interaction|Bidirectional Interaction]] tenet claims consciousness causally influences the physical world. Metarepresentation provides a specific mechanism: consciousness enables organisms to represent their own representations, take their knowledge as objects, and deliberately improve their cognitive processes. Without metarepresentation, cumulative culture, explicit reasoning, and deliberate self-improvement are impossible. If metarepresentation requires consciousness, consciousness causally enables distinctively human capacities—exactly what bidirectional interaction predicts.

### Minimal Quantum Interaction

The [[tenets#^minimal-quantum-interaction|Minimal Quantum Interaction]] tenet proposes consciousness influences neural states through quantum selection. Metarepresentation creates a specific demand this framework addresses: the binding of multiple representational levels into unified awareness.

When you know that you know, three distinct contents must be bound simultaneously: the first-order representation, the second-order representation of it, and the awareness of their relationship. Classical binding mechanisms face the [[binding-problem|combination problem]]: how do separate neural processes produce unified experience? Metarepresentation intensifies this challenge by requiring not just binding of simultaneous contents but binding of hierarchically nested contents.

The quantum Zeno framework offers a mechanism. Through sustained attention, consciousness might maintain coherence across the neural substrates of different representational levels—preventing the decoherence that would fragment the hierarchical structure into separate, unrelated processes. The "standing back" that metarepresentation requires could be understood as attentional selection operating on quantum superpositions of representational states, collapsing them into the unified structure where I recognise my representation as mine.

This account faces the standard [[decoherence|decoherence objection]]: can quantum coherence survive at the timescales required? The metarepresentational demand is stringent—not merely binding simultaneous contents but maintaining coherence across the temporal structure of taking-one's-thoughts-as-objects. The objection doesn't show the account is false, but it identifies where empirical investigation must focus.

### No Many Worlds

The [[tenets#^no-many-worlds|No Many Worlds]] tenet rejects interpretations where consciousness fragments across branches. Metarepresentation presupposes a unified subject: *I* represent *my* representations. This unity requirement creates a specific problem for many-worlds interpretations.

Metarepresentation involves a temporal structure: at t1 you have a belief; at t2 you represent that belief as a belief. If consciousness branches at quantum events between t1 and t2, which post-branch descendant owns the t1 belief? On MWI, all branches are equally real—but metarepresentation requires identifying *this* representation as *mine*. The indexical "I" in "I know that I know" cannot coherently refer to multiple branch-descendants simultaneously.

Consider the structure of self-improvement through metarepresentation. To deliberately modify your cognitive habits, you must: (1) identify your current practice, (2) evaluate it as yours and as modifiable, (3) implement change. If branching occurs during this process, the deliberate improvement fragments across branches in ways that break the self-referential loop. The branch that evaluates is not the same subject as the branch that implements—yet metarepresentation requires continuous self-reference.

The phenomenal unity metarepresentation requires supports determinacy over branching: a singular subject whose representations remain *its own* across the temporal structure of self-reflection.

### Occam's Razor Has Limits

The [[tenets#^occams-limits|Occam's Razor Has Limits]] tenet cautions against premature parsimony. The simplest explanation of metarepresentation—that it's merely more complex information processing—fails to explain why it correlates with expanded consciousness, requires phenomenal character, and distinguishes humans from great apes despite comparable neural complexity. The evidence warrants a less parsimonious hypothesis: metarepresentation requires something consciousness provides that functional processing alone cannot replicate.

## Further Reading

- [[theory-of-mind]] — Levels 0-3+ and the metarepresentational threshold
- [[teaching-as-metarepresentation]] — Teaching as the paradigm case of metarepresentation
- [[baseline-cognition]] — What cognition achieves without metarepresentation, and why the difference matters
- [[metacognition]] — The enabling relation between consciousness and self-monitoring
- [[cognitive-phenomenology]] — The phenomenal character of thinking
- [[consciousness-as-amplifier]] — How consciousness enhances cognitive capacity
- [[minimal-consciousness]] — The baseline cognition hypothesis
- [[higher-order-theories]] — Theories that identify consciousness with metarepresentation
- [[introspection]] — Access to one's own mental states
- [[animal-consciousness]] — The great ape comparison
- [[semantic-memory]] — TOT states and the feeling of knowing
- [[epistemic-emotions]] — The phenomenology of knowing
- [[illusionism]] — The challenge and its regress problem
- [[witness-consciousness]] — Contemplative cultivation of metarepresentation
- [[phenomenology-of-choice]] — The "standing back" structure in deliberation
- [[motor-selection]] — Choosing among action patterns as metarepresentation
- [[binding-problem]] — Why unified metarepresentation requires binding
- [[consciousness-independent-baseline-cognition-2026-01-21]] — Research notes on baseline cognition

## References

- Carruthers, P. (2011). *The Opacity of Mind: An Integrative Theory of Self-Knowledge*. Oxford University Press.
- Dunlosky, J., & Metcalfe, J. (2009). *Metacognition*. Sage Publications.
- Fleming, S.M. (2024). Metacognition and confidence: A review and synthesis. *Annual Review of Psychology*, 75, 149-176.
- Koriat, A. (2000). The feeling of knowing: Some metatheoretical implications. *Consciousness and Cognition*, 9(2), 149-171.
- Perner, J. (1991). *Understanding the Representational Mind*. MIT Press.
- Rosenthal, D.M. (2005). *Consciousness and Mind*. Oxford University Press.
- Schwartz, B.L. (2002). *Tip-of-the-Tongue States: Phenomenology, Mechanism, and Lexical Retrieval*. Lawrence Erlbaum.
- Tomasello, M. (2019). *Becoming Human: A Theory of Ontogeny*. Harvard University Press.
- Wellman, H.M. (1990). *The Child's Theory of Mind*. MIT Press.
- Whitehead, A.N. (1929). *Process and Reality*. Macmillan.
- Whiten, A. (2015). Apes have culture but may not know that they do. *Frontiers in Psychology*, 6, 91.
