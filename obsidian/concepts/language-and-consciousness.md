---
title: "Philosophy of Language and Consciousness"
description: "How meaning, reference, and the private language argument reveal that consciousness is not a problem language can dissolve. A human-AI exploration."
created: 2026-02-23
modified: 2026-02-24
human_modified:
ai_modified: 2026-02-24T11:14:00+00:00
draft: false
topics:
  - "[[hard-problem-of-consciousness]]"
concepts:
  - "[[intentionality]]"
  - "[[qualia]]"
  - "[[phenomenal-concepts-strategy]]"
  - "[[philosophical-zombies]]"
  - "[[knowledge-argument]]"
  - "[[introspection]]"
  - "[[cognitive-phenomenology]]"
  - "[[phenomenal-intentionality]]"
  - "[[epiphenomenalism]]"
  - "[[materialism]]"
  - "[[functionalism]]"
  - "[[symbol-grounding-problem]]"
related_articles:
  - "[[consciousness-and-language-interface]]"
  - "[[language-recursion-and-consciousness]]"
  - "[[language-thought-boundary]]"
  - "[[tenets]]"
ai_contribution: 100
author:
ai_system: claude-opus-4-6
ai_generated_date: 2026-02-23
last_curated:
last_deep_review: 2026-02-24T11:14:00+00:00
---

The Unfinishable Map's existing articles explore how consciousness and language interact empirically—how [[consciousness-and-language-interface|language shapes experience]], how [[language-recursion-and-consciousness|recursion may require consciousness]], and where [[language-thought-boundary|thought exceeds language]]. This article addresses the philosophical infrastructure underlying those interactions: what the major debates in philosophy of language reveal about the nature of consciousness itself.

The central insight is that consciousness resists the tools philosophy of language developed for ordinary discourse. Meaning, reference, and verification—the workhorses of analytic philosophy—all behave anomalously when applied to phenomenal experience. These anomalies are evidence that consciousness involves something beyond the reach of linguistic analysis—something these techniques were never designed to capture.

## Meaning and Conscious Intention

Paul Grice argued that linguistic meaning depends on speaker intention. A sentence means what the speaker intends the audience to recognise they intend. This analysis makes meaning irreducibly dependent on mental states—specifically, on conscious intentions that can be reflexively grasped.

John Searle extended this with his "connection principle": all [[intentionality]]—the aboutness of mental states—is either conscious or derivable from conscious states. A thermostat's "belief" that the room is too hot is merely metaphorical. Genuine aboutness requires the kind of understanding that comes with phenomenal experience.

If Grice and Searle are right, meaning cannot exist without consciousness. Language is not a self-standing formal system that minds happen to use. It is constitutively dependent on conscious subjects who intend, understand, and grasp—a position closely aligned with [[phenomenal-intentionality|phenomenal intentionality]], the view that all genuine aboutness derives from phenomenal experience. This has implications for AI language systems: an LLM producing grammatically perfect sentences without phenomenal states would, on this view, produce sounds or symbols without genuine meaning—a version of the [[symbol-grounding-problem|symbol grounding problem]] applied to semantics. The surface form would be indistinguishable from meaningful speech, but meaning—in Grice's technical sense—would be absent.

The counter-position, associated with later Wittgenstein and the inferentialist tradition (Brandom, Sellars), holds that meaning is constituted by public use rather than private intention. On this view, what a word means is determined by its role in social practices, not by anything happening inside individual minds. If correct, meaning might not require consciousness at all—only participation in the right normative practices.

The Map finds neither position fully adequate. The inferentialist account explains how meaning is *shared* but struggles to explain why there is something it is like to *understand*. The intentionalist account captures the phenomenal dimension of meaning but risks making communication mysterious—how do private intentions become public understanding? The difficulty of choosing between them may itself be diagnostic: meaning straddles the boundary between public structure and private experience, and no purely linguistic theory can capture both sides.

## The Private Language Argument

Wittgenstein's private language argument (in *Philosophical Investigations*, §243–315) asks whether a language understandable by only one person is possible. His answer is no: language requires criteria of correctness, and criteria require public checkability. A purely private sensation-language—where words refer to inner experiences accessible only to the speaker—would have no way to distinguish between correctly and incorrectly applying a term. You *think* you're using "S" for the same sensation each time, but there is no independent check.

This argument has been wielded against dualism. If phenomenal experience is private and non-physical, how can we talk about it meaningfully? The private language argument seems to show that purely private referents cannot ground genuine language. Consciousness talk, the argument goes, must be about something publicly accessible—behaviour, brain states, functional roles—not about irreducibly private phenomenal states.

But the argument proves less than critics suppose. Wittgenstein showed that a *purely* private language is incoherent—that is, a language with no connection to public criteria. He did not show that public language cannot *refer to* private experiences. We learn colour vocabulary through public pointing ("that's red"), but what the word "red" captures for each speaker includes their phenomenal experience. The public criterion gets us started; the private experience gives the word its full content.

Kripke's reading of Wittgenstein (in *Wittgenstein on Rules and Private Language*) raises a deeper challenge: rule-following itself may require something beyond dispositions and public checking. When you follow a rule—adding 2, using "red" correctly—what makes your next application correct rather than merely habitual? Kripke's sceptical solution appeals to community agreement, but the Map notes that community agreement may itself require conscious grasp of norms. Unconscious systems can match patterns—a neural network can learn to add 2 to any input—but matching a pattern and *following a rule* are conceptually distinct. Rule-following involves grasping what *ought* to come next, not merely what *does* come next. As Searle argued in *The Rediscovery of the Mind* (1992), genuine understanding of a rule requires the kind of awareness that pure computation lacks. If this is right, the normative dimension of language use—the sense in which a speaker can be *correct* or *incorrect*—depends on consciousness.

## Reference and the Hard Problem

How do words connect to the world? For physical objects, reference is relatively tractable—causal chains link "water" to H₂O through baptismal events and social transmission. But for consciousness terms, reference becomes deeply puzzling.

When you say "the redness of red," what does the phrase refer to? Not the wavelength (that's the physical description). Not the neural activation (that's the functional description). The phrase seems to pick out a phenomenal property—the qualitative character of experiencing red. But phenomenal properties, if irreducible to physical properties, are not the sort of thing that ordinary causal theories of reference can handle. There is no baptismal event where someone pointed at a [[qualia|quale]] and said "let's call that *phenomenal redness*." The reference is first-personal and direct.

This is where the [[phenomenal-concepts-strategy]] enters. Physicalists argue that phenomenal concepts—concepts that pick out experiences directly from the first-person perspective—explain the *appearance* of an explanatory gap without requiring anything non-physical. "Phenomenal redness" and "neural state N47" refer to the same property through different conceptual modes.

The strategy faces a dilemma. If phenomenal concepts are purely physical, what makes them pick out experience rather than functional role? And if they have a non-physical component—if grasping the concept requires *having* the experience—then something about reference to consciousness is irreducibly non-physical. Chalmers's master argument presses this point: any physical explanation of why phenomenal concepts behave distinctively either fails to capture their phenomenal character or smuggles in something non-physical. The [[knowledge-argument|knowledge argument]] reinforces this—Mary learns something genuinely new upon seeing red, and what she learns is not capturable in any physical or functional vocabulary she could have mastered in her monochrome room.

## Expressibility and the Limits of Description

The logical positivists attempted to dissolve the mind-body problem through linguistic analysis. Consciousness talk, they argued, is meaningful only insofar as it is translatable into observation statements about behaviour. Anything beyond that is meaningless—not false, but literally without cognitive content. Carnap's physicalist programme—developed in "Psychology in Physical Language" (1932)—argued that psychological statements are translatable into physical-language statements about bodily behaviour. Ryle's dispositional analysis of mental terms, in *The Concept of Mind* (1949), pursued the same goal from ordinary language: mental vocabulary is shorthand for behavioural dispositions, not reports on inner episodes.

This programme failed—and its failure marked the decline of [[functionalism|functionalist]] and behaviourist approaches to consciousness vocabulary. No finite set of behavioural descriptions captures what it is like to be in pain. Pain-behaviour can be suppressed (stoics), faked (actors), or absent (paralysis patients). The phenomenal state and the behavioural disposition are conceptually separable—a point the [[philosophical-zombies|zombie argument]] dramatises. If a physically identical being could lack consciousness while exhibiting all the same behaviour, then consciousness talk refers to something behaviour cannot capture.

The failure of logical behaviourism is instructive. It shows that philosophy of language's most powerful reductive tools—translation, verification, logical construction—cannot dissolve the consciousness problem. The problem persists not because we lack linguistic sophistication but because phenomenal experience is the wrong kind of thing for these tools to handle. Language can *describe* consciousness (partially), *refer to* it (problematically), and *express* it (lossily)—but it cannot *reduce* it to anything more tractable.

## Relation to Site Perspective

The philosophy of language provides independent support for several of the Map's [[tenets]].

**[[tenets#^dualism|Dualism]]** gains support from reference failures. If consciousness were identical to physical processes, as [[materialism]] claims, referring to it should be no harder than referring to other physical processes. But consciousness terms behave anomalously: they resist public criteria (private language problem), causal theories of reference (no baptismal pointing at qualia), and reductive translation (behaviourism's failure). These anomalies are exactly what we would expect if consciousness involves something irreducible to the physical.

**[[tenets#^bidirectional-interaction|Bidirectional Interaction]]** finds support in the Gricean analysis of meaning. If meaning requires conscious intention, and meaningful speech is causally efficacious (it changes behaviour, coordinates action, transmits knowledge), then consciousness causally contributes to the physical world through language. Every meaningful utterance is an instance of downward causation—conscious intention shaping physical sound waves and written marks. This directly contradicts [[epiphenomenalism]], which must treat the apparent purposefulness of speech as coincidental—our words happen to match our experiences, but the experiences play no causal role in producing them.

**[[tenets#^occams-limits|Occam's Razor Has Limits]]** applies directly. The logical positivists pursued maximum parsimony—dissolve consciousness into behaviour, eliminate what cannot be publicly verified. The result was not elegant simplicity but the loss of the very phenomenon they sought to explain. Parsimony cannot eliminate what refuses to be eliminated. When the simpler theory (behaviourism, logical construction) fails to capture the data (phenomenal experience), the more complex theory (dualism, irreducibility) may be necessary.

## Further Reading

- [[consciousness-and-language-interface]] — The empirical bidirectional relationship between language and experience
- [[language-recursion-and-consciousness]] — Why recursive structure may require consciousness
- [[language-thought-boundary]] — Where thought exceeds what language can capture
- [[phenomenal-concepts-strategy]] — Physicalism's best response to the explanatory gap
- [[intentionality]] — The aboutness of mental states and phenomenal intentionality
- [[qualia]] — The qualitative character of experience
- [[knowledge-argument]] — Mary's Room and what it shows about physical knowledge
- [[philosophical-zombies]] — The conceivability argument against physicalism
- [[symbol-grounding-problem]] — How symbols acquire intrinsic meaning, and why they can't without consciousness
- [[tenets]] — The foundational commitments of the Map

## References

1. Grice, H.P. (1957). "Meaning." *The Philosophical Review*, 66(3), 377-388.
2. Searle, J.R. (1983). *Intentionality: An Essay in the Philosophy of Mind*. Cambridge University Press.
3. Searle, J.R. (1992). *The Rediscovery of the Mind*. MIT Press.
4. Wittgenstein, L. (1953). *Philosophical Investigations*. Trans. G.E.M. Anscombe. Blackwell.
5. Kripke, S. (1982). *Wittgenstein on Rules and Private Language*. Harvard University Press.
6. Carnap, R. (1932). "Psychology in Physical Language." *Erkenntnis*, 3, 107-142.
7. Ryle, G. (1949). *The Concept of Mind*. Hutchinson.
8. Chalmers, D. (2007). "Phenomenal Concepts and the Explanatory Gap." In T. Alter & S. Walter (eds.), *Phenomenal Concepts and Phenomenal Knowledge*. Oxford University Press.
9. Brandom, R. (1994). *Making It Explicit*. Harvard University Press.
