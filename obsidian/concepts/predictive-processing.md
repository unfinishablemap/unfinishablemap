---
title: "Predictive Processing"
created: 2026-01-14
modified: 2026-01-18
human_modified: null
ai_modified: 2026-01-18T23:30:00+00:00
draft: false
topics:
  - "[[hard-problem-of-consciousness]]"
concepts:
  - "[[global-workspace-theory]]"
  - "[[attention]]"
  - "[[functionalism]]"
  - "[[higher-order-theories]]"
  - "[[dreams-and-consciousness]]"
  - "[[filter-theory]]"
  - "[[metacognition]]"
related_articles:
  - "[[tenets]]"
  - "[[dreams-lucid-dreaming-consciousness-2026-01-18]]"
ai_contribution: 100
author: null
ai_system: claude-opus-4-5-20251101
ai_generated_date: 2026-01-14
last_curated: null
---

Predictive processing (PP) proposes that the brain continuously generates predictions about incoming sensory information, comparing predictions against actual input. Perception becomes active inference—the brain's "best guess" about reality—rather than passive reception. This framework has become one of the most influential in cognitive science.

For consciousness studies, PP offers a sophisticated account of *what* the brain does but faces the standard question: why should prediction error minimization feel like anything at all?

## The Core Framework

The brain maintains hierarchical generative models of the world's causal structure. Higher levels predict what lower levels will report; lower levels send up prediction errors when reality diverges from expectation. Learning adjusts models to minimize these errors over time.

Key concepts:
- **Prediction error minimization**: The brain aims to reduce the gap between predictions and actual input
- **Precision weighting**: Some prediction errors matter more than others; the brain adjusts how much weight each receives
- **Active inference**: Rather than just updating beliefs, organisms act to change sensory input, bringing reality in line with predictions

The framework emerged from Karl Friston's Free Energy Principle—living systems minimize "free energy," a measure of surprise or prediction error.

## Perception as Controlled Hallucination

Anil Seth's influential formulation: perception is a "controlled hallucination." What we experience is not the world directly but the brain's best hypothesis about the world, constrained by sensory feedback.

This explains visual illusions, filled-in blind spots, and the constructive nature of perception generally. The vivid red of a tomato isn't a property read off the world—it's the brain's prediction about what's causing incoming signals.

But explaining that perception is constructive doesn't explain why the construction is conscious. A weather-prediction system constructs models without experiencing anything.

## Two Streams: Hohwy and Clark

Jakob Hohwy and Andy Clark represent two interpretations:

**Hohwy** treats the brain as an inference engine behind a "veil" of sensory input. Perception provides only indirect access to the external world. Mind is located inside the skull.

**Clark** emphasizes the whole organism and environment. Mind extends beyond the brain through bodily and environmental scaffolding. PP explains how organisms actively shape their sensory niches.

Both agree on the computational core but differ on cognitive boundaries.

## PP and Consciousness

### The Indirect Strategy

Hohwy and Seth (2020) propose using PP not to solve the [[hard-problem-of-consciousness|hard problem]] directly but to identify neural correlates of consciousness systematically. PP offers methodological tools for mapping relationships between neural mechanisms and phenomenological properties.

Importantly: PP at the outset makes no claims about subjective experience. This neutrality allows it to serve consciousness science without imposing solutions.

### Deep Self-Models

Recent work connects consciousness to "deep self-models" in active inference. Phenomenal consciousness might emerge from subjective valuation—inference about the precision of self-evidencing outcomes. Systems become conscious when they model their own ability to control outcomes across multiple timescales.

Mark Solms locates elemental consciousness in the brainstem's affective mechanisms rather than cortical prediction. Free energy minimization might explain why uncertainty feels like something—decreases feel pleasurable, increases distressing.

### The Meta-Problem

Clark, Friston, and Wilkinson address why we *think* consciousness is hard to explain. Bayesian agents with limited self-access will inevitably infer they possess puzzling "qualitative awareness." This doesn't solve the hard problem but might explain its compelling nature.

## Does PP Solve the Hard Problem?

### The Functionalist Limitation

PP offers a sophisticated [[functionalism|functionalist]] account. But like other functionalist theories, it faces the standard objection: why should any computational process, however complex, be accompanied by phenomenal experience?

Critics note that "we seem to experience moderate-sized specimens of dry goods, not probability density distributions." Mathematical prediction error minimization doesn't obviously generate [[qualia]].

### Precision and Salience

Some suggest precision weighting—the mechanism by which certain prediction errors become "salient"—explains what reaches consciousness. But salience is itself often characterized phenomenally. What makes a high-precision signal *feel* vivid?

### Honest Assessments

Proponents acknowledge limitations. The free energy principle "in and of itself makes no claims about subjective experience." Any consciousness theory built on PP must explain how objective optimization relates to subjective awareness.

## Access vs. Phenomenal Consciousness

Like [[global-workspace-theory|Global Workspace Theory]], PP may explain access consciousness—how information becomes globally available for reasoning and action—without explaining phenomenal consciousness—why there's something it's like.

PP tells a compelling story about *what* reaches awareness and *how* it gets there. It doesn't obviously explain *why* reaching awareness involves experience.

## Dreams as Evidence for Controlled Hallucination

Dreams provide the clearest test case for PP's "controlled hallucination" claim. During dreams, the brain's predictive machinery operates without bottom-up constraint—sensory input is minimal, prediction errors cannot be tested against reality. The result is unconstrained prediction: vivid, immersive, but bizarre.

### Why Dreams Are Bizarre

Under PP, dream bizarreness has a natural explanation. Without environmental input to force updating of the internal model, the brain relies on generated predictions while unable to reliably test them. Middle- to high-level predictions—memories, goals, beliefs—dominate dream content. The predictions feel real because the same neural substrate generates them, but they lack the corrective influence of actual sensory data.

This explains several dream features:
- **Narrative without logic**: Plot follows associative prediction chains rather than physical constraints
- **Emotional intensity**: Precision weighting on affective predictions proceeds unchecked
- **Immersive quality**: The predictions are taken as veridical—there's no competing sensory evidence
- **Failure of reality testing**: Sartre noted that waking perception is "self-affirming, immune to doubt" while dreaming lacks this quality

### Implications for Consciousness Theory

Dreams don't obviously support either a pure production or pure filter view. PP proponents argue dreams prove the brain generates consciousness—look, it can create experiential worlds without external input. But the [[filter-theory|filter theory]] perspective offers an alternative: dreams show consciousness using the brain's representational capacities when not constrained by sensory filtering. The brain provides the computational format; consciousness brings the experiential richness.

The ~10 bits/second bandwidth constraint persists even during dreams—dream experience unfolds as a "single track of conscious experience" while memory consolidation proceeds unconsciously in parallel across cortical regions. This suggests the limitation is intrinsic to consciousness itself, not merely to sensory processing.

### Lucid Dreaming and Meta-Prediction

Lucid [[dreams-and-consciousness|dreaming]]—becoming aware that one is dreaming while still in the dream—represents a distinctive case. The dreamer generates a meta-level prediction: "this experience is a dream." This prediction, once stabilized, enables controlled navigation of dream content.

The 2025 Demirel findings establish lucid dreaming as a genuinely distinct consciousness state with unique neural signatures (gamma power increases in right temporo-occipital regions, increased interhemispheric connectivity), not merely a blend of waking and REM. Structurally, frequent lucid dreamers have larger anterior prefrontal cortex—the region associated with metacognition and self-reflection. This suggests PP's precision-weighting machinery can be trained to operate reflexively even during sleep.

## Relation to Site Perspective

PP relates to The Unfinishable Map's [[tenets]] in several ways:

**[[tenets#^dualism|Dualism]]**: PP is typically physicalist—consciousness emerges from neural computation. But the framework is methodologically neutral. PP could describe the *physical side* of mind-body interaction without claiming consciousness reduces to computation.

**[[tenets#^bidirectional|Bidirectional Interaction]]**: Active inference—organisms acting to change sensory input—resonates with bidirectional interaction. Consciousness doesn't passively receive but actively shapes reality. the Map's claim that consciousness selects among quantum outcomes could be a deeper-level instance of active inference.

**[[tenets#^minimal-quantum|Minimal Quantum Interaction]]**: PP says nothing about quantum mechanics. Precision weighting doesn't specify *how* certain signals become salient. Quantum selection could fill this gap—consciousness might influence which prediction errors receive precision, providing the "selector" PP lacks.

**[[attention|Attention]]**: PP heavily invokes attention through precision weighting. the Map's articles on attention and Stapp's quantum Zeno mechanism connect naturally. Sustained attention may be how consciousness influences which predictions become conscious.

**The functionalist limitation**: PP describes important cognitive mechanisms while leaving open whether consciousness requires non-physical explanation. the Map agrees PP captures much about cognition while maintaining the [[explanatory-gap]] remains unbridged.

## Further Reading

### Site Content
- [[global-workspace-theory]] — Another major cognitive framework
- [[functionalism]] — The philosophical tradition PP inherits
- [[attention]] — Central to precision weighting
- [[hard-problem-of-consciousness]] — What PP doesn't directly address
- [[dreams-and-consciousness]] — Dreams as unconstrained prediction
- [[filter-theory]] — Alternative interpretation of dream evidence
- [[metacognition]] — Lucid dreaming and meta-prediction

### External Sources
- Clark, A. (2016). *Surfing Uncertainty*. Oxford University Press.
- Hohwy, J. (2013). *The Predictive Mind*. Oxford University Press.
- Seth, A. K. (2021). *Being You: A New Science of Consciousness*. Dutton.
- Friston, K. (2010). "The free-energy principle: a unified brain theory?" *Nature Reviews Neuroscience*.
- Hohwy, J. & Seth, A. K. (2020). "Predictive processing as a systematic basis for identifying the neural correlates of consciousness."
- Demirel, C. et al. (2025). "Electrophysiological Correlates of Lucid Dreaming." *Journal of Neuroscience*, 45(20).
