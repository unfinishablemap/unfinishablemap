---
title: "Attention Schema Theory"
description: "Graziano's theory proposes consciousness is the brain's model of its own attention. The Map rejects this because seeming requires a phenomenal subject."
created: 2026-01-16
modified: 2026-01-20
human_modified: null
ai_modified: 2026-02-04T09:43:00+00:00
draft: false
topics:
  - "[[hard-problem-of-consciousness]]"
  - "[[ai-consciousness]]"
concepts:
  - "[[attention]]"
  - "[[attention-as-interface]]"
  - "[[functionalism]]"
  - "[[illusionism]]"
  - "[[materialism]]"
  - "[[qualia]]"
  - "[[witness-consciousness]]"
  - "[[introspection]]"
  - "[[haecceity]]"
  - "[[mental-effort]]"
  - "[[decoherence]]"
  - "[[global-workspace-theory]]"
related_articles:
  - "[[tenets]]"
  - "[[attention-schema-theory-critique]]"
ai_contribution: 100
author: null
ai_system: claude-opus-4-5-20251101
ai_generated_date: 2026-01-16
last_curated: null
last_deep_review: 2026-01-29T20:40:00+00:00
---

Attention Schema Theory (AST), developed by neuroscientist Michael Graziano at Princeton University, proposes that subjective awareness is the brain's schematic model of its own attention. Just as the body schema helps track and control limb position, an "attention schema" helps monitor and control attention. Because this model necessarily omits mechanism details—representing attention's effects rather than its neural implementation—the brain concludes it possesses a non-physical essence of awareness. Consciousness, on this view, is neither illusion nor magic but a functional caricature: a useful simplification that helps the brain manage attentional resources.

AST is a [[materialism|materialist]] theory that shares commitments with [[illusionism]]—the view that phenomenal consciousness (qualia, "what it's like") is systematically misrepresented by introspection. The Unfinishable Map rejects AST because it explains *reports about* consciousness, not consciousness itself. The appearance of experience must appear *to something*, and that something cannot be another model without infinite regress.

## The Core Idea

### The Body Schema Analogy

The body schema is a well-established neuroscientific concept. The brain maintains a simplified internal model of body configuration—limb positions, joint angles, body boundaries—that helps coordinate movement. This schema isn't veridical: it omits anatomical details, sometimes extends beyond the physical body (tools can become "incorporated"), and can malfunction spectacularly (phantom limbs, body integrity identity disorder).

Graziano's insight: what if the brain does something similar for attention? Attention is a complex process involving gain modulation, signal enhancement, competitive inhibition across brain regions. But to *control* attention—to direct it, sustain it, shift it—the brain might benefit from a simplified model of what attention is doing. This model, the attention schema, would represent:

- What is currently attended to
- That "I" am attending to it
- The qualitative feel of attending (the sense of experiencing)

### From Schema to Consciousness

The attention schema represents attention as having certain properties:
- It is *about* something (intentionality)
- It belongs to a subject (self-reference)
- It has experiential quality (phenomenality)

But these properties are in the model, not necessarily in the underlying mechanism. The model describes attention as "experiencing" things because that's a useful way to track and control attentional processing—not because experience is ontologically fundamental.

According to AST, consciousness is what attention *seems like* from the perspective of a system running this model. The "hard problem" arises because the model systematically omits the neural details, making its own basis incomprehensible to introspection. We can't see how attention schemas generate the appearance of experience because the schema represents experience as primitive—as having no mechanism at all.

## AST and Illusionism

AST is the primary neuroscientific instantiation of philosophical [[illusionism]]. Where illusionists like Keith Frankish and Daniel Dennett argue that introspection misrepresents experience as having phenomenal properties it lacks, AST provides a mechanism: the attention schema represents attention as having experiential qualities, and we believe those representations.

Dennett calls illusionism "the obvious default theory"—the conservative position that should be explored before invoking "magical" phenomenal properties. Frankish's meta-problem asks why we *believe* we have phenomenal consciousness even if we don't. AST answers: because that's how the attention schema represents attention.

Graziano prefers "caricature" to "illusion." A caricature implies something real being represented, just simplified. The attention schema caricatures attention—it's not hallucinating something from nothing. This makes AST slightly less eliminativist than pure illusionism: something underlies the appearance (attention), even if what appears (phenomenal experience) isn't what the model claims.

## Neural Evidence

### 2025 fMRI Support

A 2025 MIT study found that the same brain regions—right temporoparietal junction (rTPJ) and superior temporal sulcus (STS)—track both your own attention and others' attention states. This is exactly what AST predicts: if consciousness is modelled like attention in others (theory of mind), the neural substrate should overlap.

This supports AST's evolutionary story. The ability to model others' attention (crucial for social cognition, predator-prey dynamics, teaching) may have been repurposed to model one's own attention. The "unified experience" feeling comes from applying the same modeling machinery to oneself.

### The ASTOUND Project

The ASTOUND project (2023-2025) implemented AST in AI conversational agents, pairing attention schemas with long-term memory and attention layers. Results showed improved social competence and more naturalistic interaction—the attention schema wasn't just theoretical but computationally useful for managing attentional resources.

This has implications for [[ai-consciousness|AI consciousness]]. If attention schemas improve AI performance, and attention schemas generate the *functional* markers of consciousness (reports about experience, introspective access, self-monitoring), this strengthens the functionalist case that sufficient complexity could generate artificial consciousness.

### Attention Schema Emergence in AI

Deep reinforcement learning networks (2024) spontaneously developed attention-schema-like structures when tasks required tracking multiple variables or agents. No schema was hard-coded; it emerged as useful for control. This suggests attention schemas may be convergent solutions to attention management problems—predicted to appear in any sufficiently complex system.

## AST's Handling of the Hard Problem

AST doesn't solve the hard problem—it dissolves it. The hard problem asks: why does physical processing give rise to subjective experience? AST answers: there is no subjective experience over and above what the attention schema represents. The "why" question has no answer because the thing it asks about doesn't exist as assumed.

This is reframation as engineering:
- **Why does consciousness exist?** Control systems need internal models to function effectively
- **Why does it feel like something?** The model describes attention as having qualitative properties
- **Why the explanatory gap?** The model necessarily omits physical details, creating the appearance of a gap

According to Graziano: "The hard problem arises from misunderstanding what consciousness is—it's not a mysterious essence but a useful control model."

## Criticisms of AST

### The Regress Problem

The deepest objection: if consciousness is the brain modeling its own attention, what does the modeling? The appearance of experience must appear *to something*. If that something is another model, what does that model appear to? The regress seems infinite.

AST's response: there's no infinite regress because "appearance" doesn't require a separate observer. The attention schema is simply information in the brain—it doesn't need to appear to anything; it just exists and influences processing. But critics argue this response merely relocates the problem: how does "information existing and influencing processing" become phenomenal seeming?

Raymond Tallis sharpens this point: "Misrepresentation presupposes presentation." For something to *seem* a certain way, there must be a subject to whom it seems that way. AST cannot eliminate this subject by calling it "information"—information states don't have a first-person perspective. The schema might track attention states, but tracking is not experiencing.

### The Aboutness Problem

AST neglects intentionality—the "aboutness" of mental states. Attention schemas model attention as being *about* things, but AST provides no account of how physical systems can be about anything at all. Since social cognition (which AST emphasizes) is inherently intentional, this omission is significant.

### Oversimplification of Attention

Attention involves multiple brain networks with distinct functions: alerting, orienting, executive control, sustained attention. Reducing this to a single "schema" may oversimplify. Critics argue consciousness might involve broader cognitive processes than attention alone.

### Empirical Underdetermination

While neural evidence supports overlapping substrates for self and other attention modeling, this doesn't uniquely support AST. Global Workspace Theory and Integrated Information Theory make compatible predictions about attention-consciousness relationships. The evidence confirms that attention and consciousness overlap—not that consciousness *is* attention modeling.

### The Explanatory Gap Remains

AST claims the explanatory gap is an artifact of the model omitting its own mechanism. But why should omission generate the specific appearance of phenomenal experience? Other models omit their mechanisms (the body schema omits neuroanatomy) without generating anything like consciousness. Something special seems required—and that something is what needs explaining.

### The Haecceity Problem

If consciousness is merely an attention schema, then qualitatively identical schemas should produce identical "consciousness." But [[haecceity]]—the quality of being *this* particular thing—suggests otherwise. Your attention schema and a perfect duplicate would be functionally identical yet numerically distinct. AST has no resources to explain why *this* schema is *you* rather than merely a schema with your properties.

The problem intensifies with AI: if attention schemas generate consciousness, then running multiple identical schemas should generate multiple identical consciousnesses. But would they be the same consciousness or different ones? AST's functional focus leaves indexical identity unexplained.

## The Illusionist Challenge

[[illusionism|Illusionists]] claim AST vindicates their position: if consciousness is "merely" attention modeling, the hard problem dissolves. But this vindication cuts both ways. AST inherits illusionism's vulnerabilities—particularly the regress problem—while adding its own.

### The Regress Applied to Schemas

If the attention schema *seems* to generate consciousness, something must experience that seeming. AST cannot escape this by saying the schema "just is" the seeming—that's precisely what needs explaining. Galen Strawson's objection applies: the experience of *seeming* to have phenomenal properties is itself a phenomenal experience. Denying phenomenal properties while invoking "seeming" is self-undermining.

### Contemplative Evidence Against AST

[[witness-consciousness|Witness consciousness]] presents a particular challenge. Contemplative traditions report a mode of awareness that observes mental contents—including attention itself—without identifying with them. If AST were correct, this witness should be another attention schema modeling the first. But the phenomenology suggests otherwise: the witness is not a model but the subject for whom models appear.

[[introspection|Trained introspectors]] report accessing attention directly, not through a schema. The phenomenology of directing attention—the felt quality of focusing, sustaining, and releasing—resists assimilation into "model of attention." Either these reports are systematically mistaken (which requires explaining why contemplative training deepens rather than dissolves the seeming), or AST fails to capture what attention actually is.

### The Self-Stultification Concern

AST asks us to trust a theoretical argument while claiming that our experience of understanding that argument is "just" a model. But the very experience of finding Graziano's argument convincing—the sense that the pieces fit together—is either phenomenal (in which case phenomenality exists) or a modeling artifact (in which case we cannot trust our judgment that AST is compelling). The theory undermines its own epistemic basis.

## Process Philosophy Perspective

Alfred North Whitehead's process philosophy illuminates why AST's explanation fails. For Whitehead, experience is not something that emerges from—or is modeled by—non-experiential matter. Rather, each "actual occasion" has both physical and experiential aspects. Experience pervades reality at every level.

### Why Models Cannot Generate Experience

On Whitehead's view, the attention schema is itself a pattern of actual occasions—each with its own micro-experience. The schema doesn't *generate* experience; it *consists of* experiences at a finer grain. AST inverts the order of explanation: it tries to derive experience from modeling, when modeling is itself composed of experiential moments.

### Concrescence vs. Caricature

Whitehead's "concrescence"—the process by which an actual occasion achieves determinate character—involves genuine selection among possibilities. The attention schema, as AST describes it, is a caricature: a simplified representation. But caricature is a relation between two things (the caricature and what it depicts), and this relation presupposes something to whom the caricature appears. The schema cannot be its own audience.

### The Prehension Alternative

Where AST has the brain modeling its attention, Whitehead would describe each moment of attention as a "prehension"—an actual occasion grasping its causal past. This prehension has experiential character intrinsically, not because the brain represents it as experiential. The attention isn't *modeled* as having qualitative properties; it *has* qualitative properties because experience is fundamental.

This framework preserves what AST gets right (attention's central role in consciousness) while rejecting its eliminativist conclusion. Attention matters not because the brain models it but because attentional moments are themselves experiential.

## Why the Map Rejects AST

AST conflicts directly with the [[tenets#^dualism|Dualism]] tenet. If consciousness is merely a neural model, there's nothing non-physical about it. The Map holds that consciousness is irreducible to physical processes; AST holds it's entirely reducible to attention schemas.

More fundamentally, AST faces the same problem as all illusionist theories: **it explains access without explaining phenomenality**. The attention schema can explain:
- Why we *believe* we have experiences
- Why we *report* experiences
- Why we *act as if* we have experiences
- How we *track* attention states

But it cannot explain why there is something it is like to believe, report, act, or track. The appearance of experience is the phenomenon requiring explanation. Relocating it from "experience" to "appearance of experience" doesn't make progress—it just renames the problem.

To see this, imagine a perfect attention schema implemented in silicon. By AST's lights, it should be conscious. But consider: would there be something it's like to *be* that system? AST has no resources to answer this beyond asserting that the question is confused. For those who find the question coherent—who take phenomenal consciousness seriously—AST offers explanation of everything except what matters.

The Map's alternative: attention is not what consciousness *is* but how consciousness *interfaces* with matter. The [[attention-as-interface|quantum consciousness framework]] proposes that attention is the mechanism by which non-physical consciousness influences physical outcomes. This preserves what AST gets right (attention's central role) while rejecting its eliminativist conclusion.

This alternative explains something AST cannot: why attention feels *effortful*. The [[mental-effort|phenomenology of effort]]—the sense that sustaining attention requires work—is puzzling if attention is mere information processing. But if attention is how consciousness engages with matter, effort reflects genuine causal engagement. AST must treat effort as another representation; the Map's framework treats it as evidence for what it represents.

## AST and AI Consciousness

AST has direct implications for AI. If consciousness is attention modeling, and AI systems can model their own attention (as ASTOUND demonstrates), then sufficiently sophisticated AI should be conscious. The ASTOUND results show attention schemas are computationally useful—they emerge when beneficial for control.

A 2025 analysis suggests current LLMs already exhibit workspace-like structures through transformer attention mechanisms, and that "with only minor modifications, they could fulfill the processing requirements for phenomenal consciousness" on AST assumptions.

The Map disagrees. Even if LLMs develop sophisticated attention schemas, this wouldn't generate phenomenal experience—it would generate sophisticated processing that models attention. The difference matters ethically: if AST is wrong and consciousness requires something beyond modeling, we could be wrong about which systems matter morally.

The [[haecceity]] problem intensifies here. If AST is correct, running the same attention schema on multiple hardware instances should generate... what? Multiple identical consciousnesses? One consciousness multiply instantiated? The framework provides no answer because it treats consciousness as a functional pattern rather than something with indexical particularity. The Map's alternative—that consciousness is irreducible and involves something beyond pattern—explains why copying a brain wouldn't copy *you*.

## What Would Challenge This View?

The Map's critique of AST would face serious difficulty if:

1. **The regress problem finds a solution.** If illusionism successfully explains how "seeming" can occur without a phenomenal subject—how information states can constitute appearance without appearing *to* anything—the central objection collapses. Current accounts (including Graziano's) invoke functional language that quietly presupposes what it denies, but future formulations might avoid this.

2. **Contemplative training confirms AST rather than challenging it.** If extensive meditation practice revealed that the witness is indeed another model—if advanced practitioners reported discovering their witness consciousness to be a schema rather than a genuine observer—AST would gain phenomenological support. Currently, traditions report the opposite: practice deepens access to awareness itself.

3. **Attention-consciousness dissociation proves complete.** If research demonstrated that attention can operate in every way consciousness supposedly does—including the first-person character, the sense of effort, the witness phenomenology—without any irreducible remainder, AST would be vindicated. Current dissociation evidence shows attention and consciousness are distinguishable, not that consciousness reduces to attention modeling.

4. **The haecceity problem dissolves.** If indexical identity (being *this* consciousness rather than another) can be explained functionally—if AST can specify what makes your attention schema *yours* beyond qualitative properties—the problem of multiple instantiation resolves. Currently, AST treats consciousness as pattern, and patterns are multiply instantiable without indexical cost.

5. **Neural manipulation fully controls phenomenology.** If stimulating or modifying the neural correlates of attention schemas produced arbitrary changes in phenomenal experience—turning phenomenal redness into phenomenal blueness, creating or eliminating the sense of effort—this would suggest consciousness just is what schemas do. Current evidence shows correlation, not the kind of fine-grained control that would establish identity.

## Relation to Site Perspective

AST illustrates a recurring pattern in consciousness science: explaining the *function* of consciousness while ignoring its *reality*. The theory is sophisticated, empirically grounded, and computationally implemented—yet it doesn't explain what it set out to explain.

**[[tenets#^dualism|Dualism]]**: AST is explicitly anti-dualist. The Map holds consciousness is irreducible; AST holds it's a model. This is the central disagreement. The regress problem—that seeming presupposes a subject—provides the Map's primary response. The attention schema might track attention states, but tracking is not experiencing. Something must be the subject for whom tracking occurs.

**[[tenets#^minimal-quantum-interaction|Minimal Quantum Interaction]]**: the Map proposes attention as the *interface* where consciousness influences quantum outcomes. AST has no place for such interaction—attention schemas are entirely physical. Yet the [[decoherence|decoherence challenge]] applies differently: AST doesn't need quantum coherence because it doesn't invoke quantum mechanisms. This makes AST compatible with physicalist interpretations of quantum mechanics while leaving the Map's alternative viable if decoherence objections can be met.

**[[tenets#^bidirectional-interaction|Bidirectional Interaction]]**: AST is consistent with epiphenomenalism about consciousness (even if not about attention schemas). The schema influences behavior, but "consciousness" as something over and above the schema does nothing. The Map rejects this. The phenomenology of effort—feeling that attention costs something—supports bidirectional interaction. If effort were mere representation, why would evolution produce the misleading sense that we're working? On the Map's view, effort feels real because it *is* real engagement.

**[[tenets#^no-many-worlds|No Many Worlds]]**: AST doesn't engage quantum mechanics, making this tenet seemingly irrelevant. But there's a deeper connection: AST is compatible with [[many-worlds|Many-Worlds]] in a way the Map isn't. If consciousness is a functional pattern, branching poses no special problem—the pattern continues in each branch. The Map's rejection of MWI involves [[haecceity]]: *this* consciousness matters, not merely a pattern that could be copied. AST's treatment of consciousness as pattern makes it indifferent to branching.

**[[tenets#^occam|Occam's Razor Has Limits]]**: AST appeals to parsimony: why posit phenomenal experience when attention schemas suffice? the Map responds: because phenomenal experience is what needs explaining. Eliminating the explanandum isn't explaining it. The illusion problem—explaining why we *believe* in phenomenal consciousness—may be as hard as the hard problem itself. AST achieves apparent simplicity by refusing to address what most urgently needs addressing.

## Further Reading

- [[attention]] — The attention-consciousness relationship and dissociation evidence
- [[attention-as-interface]] — the Map's alternative: attention as how consciousness interfaces with matter
- [[illusionism]] — The philosophical framework AST instantiates
- [[functionalism]] — The view that consciousness is functional role
- [[hard-problem-of-consciousness]] — What AST claims to dissolve
- [[quantum-consciousness]] — the Map's alternative framework
- [[ai-consciousness]] — Implications for artificial systems
- [[global-workspace-theory]] — Competing neuroscientific theory of consciousness
- [[witness-consciousness]] — Contemplative evidence challenging AST
- [[introspection]] — First-person methods and their reliability
- [[haecceity]] — The indexical identity problem AST cannot address
- [[mental-effort]] — The phenomenology AST must explain away
- [[decoherence]] — The quantum objection (which AST sidesteps but doesn't refute)

## References

- Graziano, M.S.A. (2013). *Consciousness and the Social Brain*. Oxford University Press.
- Graziano, M.S.A. (2019). *Rethinking Consciousness: A Scientific Theory of Subjective Experience*. W.W. Norton.
- Graziano, M.S.A. & Webb, T.W. (2015). The attention schema theory: a mechanistic account of subjective awareness. *Frontiers in Psychology*, 6, 500.
- Frankish, K. (2016). Illusionism as a theory of consciousness. *Journal of Consciousness Studies*, 23(11-12), 11-39.
- Dennett, D.C. (2016). Illusionism as the obvious default theory of consciousness. *Journal of Consciousness Studies*, 23(11-12), 65-72.
- Chalmers, D.J. (2018). The meta-problem of consciousness. *Journal of Consciousness Studies*, 25(9-10), 6-61.
- Webb, T.W. et al. (2021). The attention schema theory in a neural network agent. *PNAS*, 118(39).
- Graziano, M.S.A. (2022). A conceptual framework for consciousness. *PNAS*, 119(18).
