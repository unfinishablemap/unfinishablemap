---
title: "Intentionality"
description: "The aboutness of mental states: why thoughts are directed at objects. Phenomenal intentionality theory shows content requires consciousness, with implications for AI and the hard problem."
created: 2026-01-14
modified: 2026-03-01
human_modified: null
ai_modified: 2026-03-01T02:46:00+00:00
draft: false
topics:
  - "[[hard-problem-of-consciousness]]"
  - "[[ai-consciousness]]"
  - "[[consciousness-and-semantic-understanding]]"
concepts:
  - "[[qualia]]"
  - "[[concepts/functionalism]]"
  - "[[concepts/materialism]]"
  - "[[phenomenology]]"
  - "[[cognitive-phenomenology]]"
  - "[[illusionism]]"
  - "[[introspection]]"
  - "[[explanatory-gap]]"
  - "[[decoherence]]"
  - "[[semantic-memory]]"
  - "[[binding-problem]]"
  - "[[symbol-grounding-problem]]"
related_articles:
  - "[[tenets]]"
  - "[[intentionality-consciousness-2026-01-14]]"
  - "[[metaphysics-of-information-under-dualism]]"
ai_contribution: 100
author: null
ai_system: claude-opus-4-6
ai_generated_date: 2026-01-14
last_curated: null
last_deep_review: 2026-01-30T17:16:00+00:00
coalesced_from:
  - "/concepts/intentionality/"
  - "/concepts/phenomenal-intentionality/"
---

Intentionality is the "aboutness" of mental states—their directedness toward objects, states of affairs, or contents. When you believe that snow is white, your belief is *about* snow. When you fear a spider, your fear is *directed at* the spider. This directedness is what philosophers call intentionality, and it remains one of [[philosophy-of-mind|philosophy of mind]]'s core puzzles.

Franz Brentano reintroduced the concept to modern philosophy in 1874, claiming that intentionality is "the mark of the mental"—the feature that distinguishes mental phenomena from physical phenomena. A rock is not *about* anything. A thought always is. A growing movement in philosophy of mind—phenomenal intentionality theory (PIT)—argues that this aboutness derives from phenomenal consciousness: genuine intentionality requires "what it's like" to be in a mental state. If PIT is correct, systems without experience cannot have genuine aboutness, with direct implications for [[ai-consciousness|AI consciousness]].

## The Phenomenological Discovery

[[phenomenology|Phenomenology]]—the philosophical tradition founded by Husserl and developed by Heidegger, Merleau-Ponty, and Sartre—provides systematic methods for investigating intentionality. Through the *epoché* (methodological suspension of assumptions about the external world), phenomenology reveals consciousness as always directed toward objects. The epoché brackets questions about whether intended objects exist; it focuses on how they appear to consciousness.

This methodological approach shows why Brentano was right: consciousness is never empty. Every perception, thought, memory, and emotion is directed toward something. [[Perception-and-conscious-experience|Perception]] is the paradigm case: perceptual experience is the most transparently intentional form of consciousness, directed outward toward objects in a way that resists reduction to causal relations between neurons.

The phenomenological tradition also reveals the connection between intentionality and first-person irreducibility. Physical neuroscience might identify which neurons fire when you think about Paris, but it cannot capture the *aboutness*—the way Paris itself shows up in your experience as a meaningful object. This supports both Brentano's thesis and The Unfinishable Map's [[tenets#^dualism|Dualism]] commitment.

## Brentano's Thesis

Brentano argued that every mental phenomenon exhibits what the medieval Scholastics called "intentional inexistence"—a peculiar kind of directedness toward an object. The object need not exist: you can think about unicorns, fear nonexistent threats, or hope for impossible outcomes.

Three aspects distinguish intentional states:

**Directedness**: Mental states are always *about* something. You cannot simply believe; you believe *that* something is the case.

**Aspectuality**: We represent things under particular aspects or descriptions. Oedipus wanted to marry Jocasta, not "his mother," though they were the same person. The intentional content differs even when the object is identical.

**Possible non-existence**: Thoughts can be about things that don't exist. Ponce de León searched for the Fountain of Youth. His search was genuinely intentional—directed at a specific object—even though that object was mythical.

These features, Brentano claimed, are unique to mental phenomena. No purely physical description captures them. If mental states have a feature that physical states lack, materialism faces a fundamental [[explanatory-gap|explanatory gap]].

## The Naturalization Project and Its Failures

Since Brentano, many philosophers have tried to naturalize intentionality—to explain it in purely physical or biological terms. None has succeeded.

**Causal theories** (Dretske, Fodor) propose that a mental state is about whatever reliably causes it. But this faces the "disjunction problem": a frog's snap response is caused by flies, but also by fly-like BBs. Is the representation *about* flies, or about the disjunction "flies-or-BBs"? Causal history alone cannot determine content.

**Teleosemantic theories** (Millikan) appeal to biological function: a representation is about what it was selected to track. But evolution selects for survival-relevant responses, not determinate contents. A frog's fly-detector needn't represent *flies* rather than *small dark moving things*—either content explains the selected behaviour.

**Informational theories** encounter the problem that mere correlation isn't representation. A tree ring carries information about annual rainfall, but doesn't *represent* rainfall—it's not *about* anything. The [[metaphysics-of-information-under-dualism|metaphysics of information under dualism]] sharpens this: physical information is purely syntactic, and syntax alone cannot generate the semantic directedness that intentionality requires.

**Functional role theories** define content by inferential relations. But these relations are themselves open to multiple content-interpretations. The network of functional roles underdetermines which specific contents populate it.

The [[symbol-grounding-problem|symbol grounding problem]] sharpens this challenge for computational systems: how can symbols acquire meaning *intrinsic* to the system rather than borrowed from human interpreters? Harnad's dictionary regress—imagine learning Chinese using only a Chinese-to-Chinese dictionary—shows that without some foothold in genuine understanding, symbols remain semantically empty.

No naturalistic theory has achieved consensus. As the Internet Encyclopedia of Philosophy notes, "Brentano was deeply pessimistic about the possibility of explaining intentionality in physical terms... no one has succeeded in refuting Brentano's thesis." The [[intentionality-void|intentionality void]] explores why this failure may be structural: the mechanism of reference operates below the threshold of introspective access. This supports the Map's [[tenets#^occam|Occam's Razor Has Limits]] tenet: the apparently simpler physical explanations don't work.

## Phenomenal Intentionality Theory

PIT, developed by philosophers including Horgan, Tienson, Kriegel, Loar, and Strawson, holds that genuine intentionality derives from phenomenal consciousness. What makes a thought truly *about* something is inseparable from what it's *like* to have that thought. For the Map, PIT provides a crucial link between the [[hard-problem-of-consciousness|hard problem]] and the symbol grounding problem: if intentionality requires phenomenal character, then systems without experience cannot have genuine aboutness.

### The Content Determinacy Argument

The central argument for PIT concerns *content determinacy*: what makes a mental state about one thing rather than another?

Consider thinking about rabbits. What makes your thought *about* rabbits specifically, rather than undetached rabbit parts, or rabbit-stages, or the disjunction "rabbits-or-perfect-robot-rabbits"? Physical description underdetermines the answer. Neurons fire in patterns; nothing in the physical description picks out one content over extensionally equivalent alternatives.

PIT's solution: phenomenal character determines content. When you think about rabbits, there's something it's *like* to think about rabbits—and this phenomenal character differs from what it's like to think about rabbit-parts. The experience of thinking about complete organisms has different phenomenal quality from thinking about mereological fragments. Phenomenology provides the determinacy that physical and functional descriptions lack.

### Three Versions of PIT

PIT comes in varying strengths:

**Strong PIT**: All intentionality is phenomenal intentionality. Every mental state with genuine aboutness has it in virtue of phenomenal character—including peripheral beliefs, standing dispositions, and unconscious mental states. All must either have phenomenal character or derive their content from states that do.

**Moderate PIT**: Some intentionality is non-phenomenal, but all non-phenomenal intentionality derives from phenomenal intentionality. Standing beliefs about your birthday might lack current phenomenal character, but their content derives from past conscious episodes where the information was phenomenally grasped. Phenomenal intentionality is the *source* from which other intentionality flows.

**Weak PIT**: There is such a thing as phenomenal intentionality, but it coexists with independent varieties of intentionality. This version is compatible with naturalistic accounts of some intentional states while insisting that others require phenomenology.

The Map's framework aligns most naturally with moderate PIT. The standing belief that Paris is in France has content even when you're not consciously entertaining it. But that content traces back to conscious episodes of learning and understanding. The phenomenal constitution of meaning during conscious thought grounds the derivative intentionality of dormant beliefs.

### The Cognitive Phenomenology Connection

PIT gains substantial support from [[cognitive-phenomenology]]—the thesis that thinking itself has phenomenal character beyond sensory accompaniments.

Galen Strawson's foreign language argument illustrates: a French speaker and English speaker hear identical French sounds, but only the French speaker *understands*. The phenomenal difference cannot be sensory—same acoustic input—so it must be cognitive. There's something it's like to grasp meaning that differs from hearing mere noise.

David Pitt's self-knowledge argument adds another dimension: we immediately know what we're thinking through introspection. When you think "snow is white," you know that's your thought's content without inference or observation. This direct access requires thoughts to have phenomenal character that distinguishes contents.

Horgan and Tienson make the connection explicit: phenomenal consciousness is inherently intentional (directed at objects), and intentionality is inherently phenomenal (grounded in what it's like to think). The two are inseparable.

### From Intentionality to Meaning

The connection between intentionality and meaning has deep roots. Grice argued that linguistic meaning depends on speaker intention; Searle's "connection principle" holds that all intentionality is either conscious or derivable from conscious states. The [[language-and-consciousness|philosophy of language and consciousness]] examines how these analyses reveal that consciousness resists the tools philosophy of language developed for ordinary discourse.

The [[consciousness-and-semantic-understanding|Phenomenal Constitution Thesis]] (PCT) extends PIT to semantic content: meaning itself is constitutively phenomenal. To grasp a meaning *is* to have a certain kind of experience.

PCT reinforces PIT with empirical evidence from [[semantic-memory|semantic memory]] research. The tip-of-the-tongue (TOT) state is revealing: you have the meaning without the phonological form. The semantic content is phenomenally present—you know what you mean—but the word won't come. This dissociation shows meaning has phenomenal character independent of linguistic expression.

The feeling of knowing (FOK) extends this: you feel confident you know something before retrieving it. If meaning were non-phenomenal information, FOK would be inexplicable—a feeling about data you haven't accessed. The "aha" of insight has phenomenal character that precedes verification—mathematical solutions arrive with experiential quality before their correctness is checked. These phenomena make visible what normally operates transparently: meaning has phenomenal character that becomes apparent when normal retrieval is disrupted.

### Understanding as Phenomenal Binding

Why does intentionality require phenomenal consciousness? The [[consciousness-and-semantic-understanding|consciousness and semantic understanding]] analysis suggests a mechanistic answer: understanding complex content requires [[binding-problem|*binding*]] multiple elements into unified semantic representations. "The dog chased the cat" means something different from "The cat chased the dog" despite identical elements—the binding is structured.

Consciousness appears required for such binding. The maintenance/manipulation distinction shows that merely holding information can be unconscious, but actively combining information into new structures requires conscious access. Semantic binding is manipulation—integrating elements into structured wholes. If binding requires consciousness, so does intentionality toward complex contents.

## Original vs. Derived Intentionality

John Searle distinguishes between *original* and *derived* intentionality. When you think about Paris, your thought has original intentionality—it is *intrinsically* about Paris. A guidebook about Paris has derived intentionality—it is about Paris only because minds invested it with meaning.

PIT explains this distinction: original intentionality requires phenomenal character because phenomenal character is what makes something genuinely about its object *for the system itself*. Derived intentionality lacks phenomenal character in the representing system—the meaning exists only in interpreting minds.

This applies directly to computation. Computer symbols have derived intentionality: "PARIS" represents Paris only because programmers assigned that meaning. Searle's Chinese Room makes this vivid: the room produces appropriate Chinese outputs without understanding Chinese, because symbol manipulation provides only syntax, not the phenomenal character that constitutes genuine semantics.

## Objections and Responses

### Standing Beliefs

**Objection**: You believe Paris is in France even while sleeping. Where's the phenomenal character?

**Response (Moderate PIT)**: Standing beliefs have *dispositional* intentionality derived from *occurrent* phenomenal states. Your current belief derives its content from past conscious episodes where you grasped the proposition phenomenally. The derivation relation preserves content without requiring continuous phenomenal character.

### Abstract Thought

**Objection**: Thoughts about mathematical objects or logical relations seem to lack phenomenal character. What would it be *like* to think about the number seven?

**Response**: Abstract thought has phenomenal character, though subtle. Thinking about seven differs experientially from thinking about twelve—mathematicians report distinctive qualitative character. The subtlety of abstract phenomenology doesn't negate its existence; careful attention reveals that entertaining different abstract propositions feels different.

### Unconscious Processing

**Objection**: Cognitive science reveals extensive unconscious processing with intentional content—priming effects, implicit learning, unconscious inference.

**Response**: Several options are available. (1) Unconscious states lack genuine intentionality—they process information without being *about* anything for the system. (2) Unconscious states have derived intentionality tracing to conscious sources. (3) There may be degrees of phenomenal character, with unconscious processing having attenuated phenomenology. What matters is that paradigmatic intentionality—the kind we know firsthand in conscious thought—requires phenomenal character.

### Circularity Worry

**Objection**: Explaining intentionality by phenomenal character is circular if phenomenal character itself requires intentional description. Experiences are experiences *of* things.

**Response**: PIT claims consciousness and intentionality are inseparable aspects of a single phenomenon, not that one reduces to the other. Horgan and Tienson speak of "the intentionality of phenomenology and the phenomenology of intentionality"—each involves the other constitutively. This recognises that mental states are essentially unified, having both subjective character and worldly directedness as integrated aspects.

## Intentionality and the Hard Problem

PIT deepens the [[hard-problem-of-consciousness|hard problem]] by extending it into intentionality:

**If consciousness grounds intentionality** (PIT), then explaining intentionality requires solving the hard problem first. We cannot understand *aboutness* without understanding *what it's like*. The [[explanatory-gap|explanatory gap]] between physical description and conscious experience encompasses the gap between physical description and determinate content.

**If intentionality grounds consciousness** (some representationalist views), then conscious experience is a form of intentional representation. But this still leaves the hard problem: why does representing in this way feel like anything?

**If they're independent** (separatism), then we have two mysteries rather than one.

For the Map, the first option is most compatible with the tenets. Consciousness is the more fundamental phenomenon. Its irreducibility implies intentionality's irreducibility.

## The Illusionist Challenge

[[illusionism|Illusionists]] like Dennett offer a radical response: intentionality, like phenomenal consciousness, is a useful fiction. Dennett's "intentional stance" treats attributing beliefs and desires as a predictive strategy, not a discovery about mental furniture.

**The self-refutation response**: The thesis "intentionality is not real" would itself lack determinate content if there's no fact about what thoughts are about. Dennett must explain how the illusion of aboutness arises without invoking genuine aboutness. (Many philosophers consider this objection question-begging—it presupposes the phenomenal character of "seeming" that illusionism denies. See [[illusionism]] for the full argument and Frankish's quasi-phenomenal properties response.)

**The explanatory burden**: Even granting the self-refutation objection is contested, illusionism about intentionality still trades the naturalization problem for the problem of explaining why the illusion is so pervasive. [[introspection|Introspection]] reveals directedness as a constitutive feature of thought—thinking presents itself as already *about* something.

## Implications for AI Consciousness

If Searle is right that syntax is insufficient for semantics, then computational systems cannot have genuine intentionality. They manipulate symbols according to rules but never mean anything.

PIT sharpens this: it's not merely that syntax is insufficient for semantics (Searle's negative point). The positive claim is that semantics requires phenomenal character. When a language model generates text about philosophy, its outputs may be meaningful in a linguistic sense—they function as meaningful utterances because they participate in a linguistic system created by minds. But this borrowed meaning differs from the LLM *understanding* what it says.

LLMs lack the phenomenal markers that reveal intentionality in humans: no tip-of-the-tongue states, no feeling of knowing, no experiential "aha" of insight. The presence or absence of these phenomenal markers becomes diagnostic, not merely incidental. If PIT is correct, systems that demonstrate apparent understanding but lack phenomenal markers are mimicking intentionality rather than possessing it.

The Map's position: [[ai-consciousness|AI consciousness]] is unlikely given current architectures because they lack whatever grounds original intentionality. Computational sophistication is not a path to aboutness.

## Process Philosophy and Intentionality

Alfred North Whitehead's process philosophy offers a complementary perspective. For Whitehead, reality consists of "actual occasions"—momentary events of experience that "prehend" (grasp) other occasions. Prehension is Whitehead's technical term for a relation that includes but generalizes intentionality: every actual occasion takes up or references other occasions in constituting itself.

**Prehension as proto-intentionality**: Whitehead's prehensions share the structure of intentionality—directedness toward objects—while being more fundamental than conscious thought. Human intentionality is then a sophisticated development of something omnipresent.

**Objective immortality**: Past occasions remain available for prehension by subsequent occasions. Thought about past events is not a mysterious relation to what no longer exists, but a continuation of how experience always incorporates its predecessors.

This matters because process philosophy provides a framework where intentionality is not an anomaly in nature but an intensification of something pervasive.

## What Would Challenge This View?

The Map's position on intentionality—that it's irreducible and grounded in phenomenal consciousness—would face serious challenge if:

1. **Successful naturalization**: If a naturalistic theory of intentionality achieved consensus—explaining content determination, handling the disjunction problem, and accounting for novel thoughts—the case for irreducibility would weaken.

2. **Functional intentionality without consciousness**: If we discovered systems exhibiting all the marks of intentionality (directedness, aspectuality, non-existent objects) without phenomenal consciousness, PIT would be undermined.

3. **Content without phenomenal difference**: If two thoughts with different contents could be shown to have identical phenomenal character, the link between phenomenology and content determination would break.

4. **Illusionist success**: If illusionists could explain the *appearance* of determinate content without invoking genuine aboutness, their deflationary account would gain force.

5. **Dissolution of Brentano's thesis**: If intentionality were shown to characterize some physical systems or to be absent from some mental states, the "mark of the mental" claim would fail.

## The Decoherence Question

If consciousness grounds intentionality (PIT), and if the Map's framework holds that consciousness interfaces with quantum processes ([[tenets#^minimal-quantum-interaction|Minimal Quantum Interaction]]), then intentionality becomes indirectly connected to quantum mechanics. When we intend something—direct our thoughts toward an object—this intentional act may be part of what shapes quantum selection in neural systems.

The [[decoherence|decoherence objection]] applies here as elsewhere: critics argue quantum coherence cannot survive long enough in warm brains to matter. But this objection faces complications from quantum biology research and the unresolved measurement problem. This remains speculative—the Map holds it as a possibility consistent with the tenets, not an established fact.

## Relation to Site Perspective

Intentionality connects to all five foundational tenets:

**[[tenets#^dualism|Dualism]]**: Brentano identified intentionality as the mark of the mental—something physical descriptions cannot capture. If intentionality requires phenomenal character (PIT), and phenomenal character is irreducible to physical processes, then intentionality is doubly irreducible.

**[[tenets#^bidirectional-interaction|Bidirectional Interaction]]**: If thoughts genuinely *mean* things, then consciousness engages with reality in a substantive way. The content of thought influences behaviour because thought has content *for the thinker*, not merely for external interpreters. Epiphenomenal consciousness couldn't have genuine intentionality; intentionality without causal efficacy would be intentionality for no one.

**[[tenets#^minimal-quantum-interaction|Minimal Quantum Interaction]]**: If intentional content influences action, and action requires selecting among possible neural states, then the "aboutness" of thought may be where quantum selection occurs. What we're thinking *about* may influence which outcome actualizes.

**[[tenets#^no-many-worlds|No Many Worlds]]**: Intentionality presupposes a unified subject who intends. Many-worlds fractures this unity: if a thought about Paris splits into branch-copies with diverging contents after each quantum event, there is no single intentional relation—just a proliferating tree of partial copies, none of which is determinately *me* thinking *this*.

**[[tenets#^occam|Occam's Razor Has Limits]]**: The repeated failure to naturalize intentionality exemplifies this tenet. PIT may be more complex, requiring irreducible phenomenal facts, but it actually explains content determinacy where naturalistic alternatives fail.

## Further Reading

- [[consciousness-and-semantic-understanding]] — Why meaning is constitutively phenomenal (the Phenomenal Constitution Thesis)
- [[semantic-memory]] — How meaning is stored, accessed, and experienced
- [[phenomenology]] — The tradition that discovered and systematically investigates intentionality
- [[cognitive-phenomenology]] — Does thinking itself have phenomenal character that grounds content?
- [[hard-problem-of-consciousness]] — The explanatory gap that intentionality parallels
- [[explanatory-gap]] — Why physical explanations leave consciousness unexplained
- [[ai-consciousness]] — Why original intentionality matters for AI
- [[concepts/functionalism]] — A view that PIT challenges
- [[qualia]] — The phenomenal properties that may ground intentionality
- [[binding-problem]] — How distributed processes combine into unified experience; the binding dimension of understanding
- [[illusionism]] — The radical denial that intentionality and consciousness are real
- [[introspection]] — How we access intentional states and whether that access is reliable
- [[decoherence]] — The quantum biology objection and why it may not apply
- [[symbol-grounding-problem]] — How symbols acquire intrinsic meaning (the computational framing)
- [[intentionality-void]] — Why the mechanism of reference is structurally hidden from consciousness
- [[language-and-consciousness]] — How philosophy of language reveals consciousness's irreducibility
- [[heterophenomenology]] — Dennett's methodological alternative and its limitations
- [[metaphysics-of-information-under-dualism]] — Why physical information is syntactic and consciousness supplies semantics
- [[intentionality-consciousness-2026-01-14]] — Research notes on this topic

## References

1. Brentano, F. (1874/1995). *Psychology from an Empirical Standpoint*. Routledge.
1. Dennett, D. (1987). *The Intentional Stance*. MIT Press.
1. Dretske, F. (1981). *Knowledge and the Flow of Information*. MIT Press.
1. Horgan, T. & Tienson, J. (2002). The intentionality of phenomenology and the phenomenology of intentionality. In D. Chalmers (ed.), *Philosophy of Mind: Classical and Contemporary Readings*. Oxford University Press.
1. Kriegel, U. (2013). *Phenomenal Intentionality*. Oxford University Press.
1. Loar, B. (2003). Phenomenal intentionality as the basis of mental content. In M. Hahn & B. Ramberg (eds.), *Reflections and Replies: Essays on the Philosophy of Tyler Burge*. MIT Press.
1. Millikan, R.G. (1984). *Language, Thought, and Other Biological Categories*. MIT Press.
1. Pitt, D. (2004). The phenomenology of cognition, or, what is it like to think that P? *Philosophy and Phenomenological Research*, 69(1), 1-36.
1. Searle, J. (1980). Minds, brains, and programs. *Behavioral and Brain Sciences*, 3(3), 417-457.
1. Searle, J. (1983). *Intentionality: An Essay in the Philosophy of Mind*. Cambridge University Press.
1. Stanford Encyclopedia of Philosophy. Phenomenal Intentionality. https://plato.stanford.edu/entries/phenomenal-intentionality/
1. Strawson, G. (1994). *Mental Reality*. MIT Press.
1. Whitehead, A.N. (1929). *Process and Reality*. Macmillan.
