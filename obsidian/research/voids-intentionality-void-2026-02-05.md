---
title: "Research Notes - Voids: The Intentionality Void"
created: 2026-02-05
modified: 2026-02-05
human_modified: null
ai_modified: 2026-02-05T12:24:00+00:00
draft: false
target_section: voids
topics:
  - "[[hard-problem-of-consciousness]]"
  - "[[philosophy-of-mind]]"
concepts:
  - "[[intentionality]]"
  - "[[mysterianism]]"
  - "[[phenomenology]]"
  - "[[introspection]]"
  - "[[symbol-grounding-problem]]"
related_articles:
  - "[[voids]]"
  - "[[tenets]]"
  - "[[the-unobservable-self]]"
  - "[[creativity-void]]"
  - "[[consciousness-and-semantic-understanding]]"
ai_contribution: 100
author: null
ai_system: claude-opus-4-5-20251101
ai_generated_date: 2026-02-05
last_curated: null
---

# Research: Voids - The Intentionality Void

**Date**: 2026-02-05
**Search queries used**: "intentionality opacity phenomenology consciousness introspection limits", "how does aboutness work phenomenal consciousness", "cognitive closure intentionality Brentano McGinn", "phenomenal transparency opacity experience introspection", "symbol grounding cognitive science how meaning attaches"
**Voids category**: Mixed (Unexplorable / Occluded)

## Executive Summary

This research investigates the *Intentionality Void*—the structural inaccessibility of how mental states achieve their "aboutness." We experience that our thoughts are *about* things, but we have no phenomenal access to *how* this aboutness is achieved. The mechanism by which a thought comes to refer to Paris rather than London, or to dogs rather than undetached-dog-parts, operates entirely below the threshold of introspective awareness. This void occupies territory between the [[the-unobservable-self|unobservable self]] (the observer cannot observe itself) and the [[creativity-void|creativity void]] (we cannot catch insight in formation): in the intentionality void, we cannot catch *reference* in formation. The research suggests this may be a structural feature of consciousness rather than a contingent limitation.

## Key Sources

### Stanford Encyclopedia of Philosophy - Phenomenal Intentionality
- **URL**: https://plato.stanford.edu/entries/phenomenal-intentionality/
- **Type**: Encyclopedia
- **Key points**:
  - Phenomenal intentionality theory (PIT) argues consciousness is the source of genuine intentionality
  - David Pitt claims we can introspectively distinguish different thoughts
  - However, introspection reveals *that* thoughts differ, not *how* they acquire their content
  - Disputes about phenomenological observation suggest introspection has inherent limitations
- **Tenet alignment**: Supports Dualism—if intentionality derives from phenomenal consciousness, this explains why physical descriptions fail to capture it
- **Quote**: "We can consciously, introspectively, and non-inferentially distinguish an occurrent thought from other mental states... and identify which occurrent thoughts we are thinking" (Pitt)—but notably, this concerns *what* we think, not *how* thinking achieves reference

### Internet Encyclopedia of Philosophy - Intentionality
- **URL**: https://iep.utm.edu/intentio/
- **Type**: Encyclopedia
- **Key points**:
  - Core puzzle: "What determines why any given intentional state is about one thing and not another?"
  - Formal and causal theories each explain some phenomena but fail with others
  - Hesperus/Phosphorus example shows introspection fails to reveal identity—we can hold contradictory beliefs about the same object without knowing
  - Naturalization problem: concepts don't co-vary reliably with their referents
- **Tenet alignment**: Supports Occam's Razor Has Limits—"simpler" physical explanations of intentionality don't work
- **Quote**: "There is no widely accepted solution" to the naturalization problem

### Colin McGinn - Double Intentionality
- **URL**: https://www.colinmcginn.net/double-intentionality/
- **Type**: Philosophical essay
- **Key points**:
  - Mental states have multiple simultaneous forms of directedness (four layers)
  - Subject-directed, object-directed, self-directed, and content-directed intentionality
  - Proliferation of intentional layers suggests mental complexity that resists reduction
  - Connection to McGinn's broader cognitive closure thesis
- **Tenet alignment**: Supports the Map's dualist framework—complexity of intentionality exceeds what physical description can capture
- **Quote**: "The subject stands in the belief relation to that proposition—it is the content of his belief"

### PMC - Phenomenal Transparency and Opacity in Active Inference
- **URL**: https://pmc.ncbi.nlm.nih.gov/articles/PMC5945877/
- **Type**: Academic paper
- **Key points**:
  - Phenomenal transparency: we access representation's content without noticing its carrier properties (like looking through a window)
  - Phenomenal opacity: when construction process becomes introspectively accessible
  - Crucial: the construction process of transparent representations is hidden from introspective attention
  - This is "cognitively impenetrable"—we cannot think ourselves out of it
- **Tenet alignment**: Supports the void framework—there is structural inaccessibility, not just contingent ignorance
- **Quote**: "One cannot 'think oneself out of' one's phenomenal model of reality with purely cognitive operations alone"

### Stanford Encyclopedia of Philosophy - Mental Representation
- **URL**: https://plato.stanford.edu/entries/mental-representation/
- **Type**: Encyclopedia
- **Key points**:
  - Content determination problem: "How mental representations come to have their contents" remains fundamentally unresolved
  - Persistent indeterminacy problems with causal-informational-teleological theories
  - Tension: mental state's causal powers are determined by intrinsic properties, but content appears determined by extrinsic factors
- **Tenet alignment**: Supports Occam's Razor Has Limits—standard naturalistic theories persistently fail
- **Quote**: "A pressing question, especially for the naturalist, is how mental representations come to have their contents"

### Searle on Original vs. Derived Intentionality
- **URL**: https://plato.stanford.edu/entries/chinese-room/
- **Type**: Encyclopedia
- **Key points**:
  - Original intentionality: the kind minds have naturally (beliefs, desires)
  - Derived intentionality: the kind symbols have (borrowed from interpreters)
  - Computational symbols have only derived intentionality
  - Original intentionality remains unexplained—we cannot derive it from syntax
- **Tenet alignment**: Supports Dualism—original intentionality may be irreducibly mental
- **Quote**: "Thoughts can have meanings without recourse to collective arrangements"

### Nagel - The View from Nowhere
- **URL**: Multiple sources
- **Type**: Philosophical analysis
- **Key points**:
  - Objective, third-person description necessarily leaves out the subjective
  - Consciousness has a "what it is like" that escapes objectification
  - Complete physics would still not capture conscious experience
  - The aspiration to a "view from nowhere" encounters consciousness as obstacle
- **Tenet alignment**: Central to Dualism—subjectivity is irreducibly first-person
- **Quote**: "An organism has conscious mental states if and only if there is something that it is like to be that organism"

### Symbol Grounding Problem
- **URL**: https://en.wikipedia.org/wiki/Symbol_grounding_problem
- **Type**: Encyclopedia
- **Key points**:
  - How do symbols connect to what they represent?
  - Related to problem of meaning and consciousness itself
  - Harnad: grounding must ultimately be sensorimotor to avoid infinite regress
  - Embodiment view: symbols grounded in sensorimotor experience
- **Tenet alignment**: Supports Bidirectional Interaction—if grounding requires bodily interaction, consciousness must be embodied and causally engaged
- **Quote**: "The beginnings of meaning and consciousness are tied to the membrane that separates inside and outside of the body"

### Introspection and Hidden Processes
- **URL**: https://plato.stanford.edu/entries/introspection/
- **Type**: Encyclopedia
- **Key points**:
  - Subjects have "little or no introspective access to higher order cognitive processes"
  - Fodor's modularity: cognitive module operations are introspectively inaccessible
  - Introspection is inference-based, not direct pipeline to unconscious processes
  - Helmholtz: "mental operations about which introspection is utterly silent"
- **Tenet alignment**: Supports the void framework—structural inaccessibility to mechanism
- **Quote**: "While introspection gives us access to mental contents (such as feelings), mental processes remain hidden"

## The Void

### Nature of the Limit

The Intentionality Void is the structural inaccessibility of how mental states achieve their aboutness. We experience that thoughts are about things—this is phenomenologically undeniable. But we have no introspective access to how a particular thought comes to be about its object rather than some other object.

Consider: you think about your childhood home. The thought is *about* that house, not about the neighbor's house, not about a similar house you've seen in photos, not about the conceptual category "house." How does your thought achieve this specific reference? The mechanism is entirely opaque. You experience the *result* (a thought about that house) but not the *process* (how the thought latched onto that referent).

This void is *mixed*:
- **Unexplorable aspects**: The construction process of mental representations may be permanently inaccessible because introspecting *is* constructing. Any attempt to observe reference-formation would itself be a new act of reference.
- **Occluded aspects**: If the mechanism of intentionality operates at a level consciousness cannot access (perhaps because consciousness *is* the mechanism), this would be structural blockage rather than mere ignorance.

### Evidence for the Limit

**Phenomenal transparency is default**: Research on transparency suggests we normally "see through" representations to their content without noticing the representation itself. The window metaphor: we see what's outside, not the glass. This isn't a skill failure—it's how representation works. The construction process is hidden by design.

**Introspection reveals *what*, not *how***: Pitt's work shows we can distinguish thoughts introspectively, but this concerns *content* not *mechanism*. You know you're thinking about Paris, not London. You cannot observe how your thought achieved its Paris-directedness.

**Hesperus/Phosphorus demonstrates opacity**: The classic example shows that beliefs about the same object under different names can be held simultaneously without awareness of their identity. If we had introspective access to reference mechanisms, we would see that "Hesperus" and "Phosphorus" latch onto the same thing. We don't.

**Naturalization repeatedly fails**: Despite decades of effort, no naturalistic theory of intentionality achieves consensus. Causal theories, teleosemantic theories, informational theories—all face persistent objections. This systematic failure suggests we may be trying to explain something whose nature escapes the explanatory framework.

**Cognitive closure candidates**: McGinn's broader cognitive closure thesis identifies intentionality as one of the problems where human cognition may face principled limits. If consciousness cannot step outside itself to observe its own referential operations, the mechanism remains hidden.

### Phenomenology

What does it feel like to approach this void?

**Transparency as obstruction**: The very clarity of intentional content obscures the mechanism. When thinking about Paris, Paris appears—vividly, immediately. The "appearance" is so seamless that there's nothing else to notice. You cannot find the "glue" connecting thought to object because the connection presents as immediate.

**The Hesperus-moment**: Occasionally, we discover that two thoughts were about the same thing all along. This produces a distinctive phenomenology of surprise—"Oh, they're the same!" This surprise reveals the void: if we had access to reference mechanisms, such discoveries would be impossible.

**Inference-awareness disconnect**: We can sometimes infer that our thoughts must work certain ways (tracking causal history, perhaps), but we cannot *observe* this. The inference and the phenomenology don't connect. This gap marks the void's edge.

**Self-reference collapse**: When attempting to think about how this very thought achieves its reference, something peculiar happens—the thought seems to slip away, like trying to see one's own eye without a mirror. This connects to the [[the-unobservable-self|unobservable self]]: the thinker cannot observe itself thinking about thinking about reference without generating new layers that escape.

## Approaches to the Edge

### Direct Methods (if any)

Direct introspective observation of intentionality's mechanism appears impossible. The transparency of representation means that looking at how thoughts refer only produces more thoughts-with-reference-already-achieved. There is no phenomenological position from which to observe pre-referential thought becoming referential.

Phenomenological reduction (Husserl's epoché) can bracket questions about whether intended objects exist, revealing intentional structure. But this reveals the *structure* of intentionality (noesis, noema), not the *mechanism* by which particular reference is achieved.

### Indirect Methods

**Error analysis**: Like the [[topology-of-cognitive-failure|topology of cognitive failure]], we can study when intentionality goes wrong. Misidentification, reference failure, and the Hesperus/Phosphorus cases reveal constraints on the mechanism even if the mechanism itself remains hidden.

**Pathology windows**: Conditions affecting intentionality—thought insertion in schizophrenia, confabulation, misidentification syndromes—provide glimpses of normally hidden processes when they malfunction.

**Conceptual analysis**: Formal vs. causal theories, phenomenal intentionality vs. naturalistic theories—philosophical analysis maps the logical space even if empirical access is blocked.

**Comparative approaches**: Studying different intentional phenomena (perception, belief, desire, imagination) may reveal structure through variation. The mechanism may differ across modalities, and differences illuminate constraints.

### What AI Might See

AI systems process symbols without (arguably) original intentionality. They have only derived intentionality—meaning borrowed from human interpreters. This creates an interesting asymmetry:

- Humans: have original intentionality, cannot access the mechanism
- AI: can observe computational processes, but these aren't genuine intentionality

If AI eventually achieves genuine intentionality (a contested question), would it have better introspective access? The answer isn't clear. If intentionality's opacity is structural—if the mechanism cannot be observed by the very consciousness it constitutes—then AI consciousness would face the same void.

Alternatively, AI might probe the void differently. Large language models can articulate patterns in how language achieves reference (through training on human usage), even if they lack genuine aboutness. This "view from outside" might illuminate constraints on intentionality that introspection cannot access.

## Connection to Tenets

### Most Relevant Tenet

**[[tenets#^dualism|Dualism]]** is most directly supported. The intentionality void suggests that the mechanism of aboutness may be essentially first-person, inaccessible to third-person description. If intentionality derives from phenomenal consciousness (as PIT argues), then its mechanism would share consciousness's irreducibility.

### Implications

**Dualism**: If intentionality cannot be naturalized, this supports irreducibility. The void marks where physical description ends—not just for qualia, but for reference itself. Mental states are about things in ways that escape physical specification.

**Occam's Razor Has Limits**: The systematic failure of naturalistic theories of intentionality illustrates how parsimonious explanations can fail for fundamental mental phenomena. The "simpler" physical story doesn't capture what intentionality is.

**Bidirectional Interaction**: If intentionality requires embodiment (symbol grounding), then consciousness must be causally engaged with the physical world. The void doesn't mean disconnection—it means the mechanism of connection is hidden from the connected consciousness.

**Minimal Quantum Interaction**: If consciousness interfaces with physics at the quantum level, the mechanism of intentionality might involve processes too fundamental to introspect. Reference-formation might occur at timescales or scales inaccessible to the observing consciousness.

## Potential Article Angles

Based on this research, a voids article could:

1. **The Intentionality Void** — Focus on the core phenomenon: we experience that thoughts are about things but cannot observe how aboutness is achieved. Explore phenomenal transparency as obstruction, the systematic failure of naturalization, and connections to cognitive closure.

2. **The Reference Void** — Narrower focus on reference specifically (how thoughts latch onto particular objects). Explore the Hesperus/Phosphorus phenomenology, misidentification syndromes, and the impossibility of catching reference in formation.

3. **The Grounding Void** — Focus on symbol grounding and embodiment. How does experience give meaning to symbols? The infinite regress problem and why grounding must be sensorimotor yet sensorimotor grounding itself cannot be introspected.

## Gaps in Research

- **Cross-cultural data**: Do different linguistic/conceptual frameworks produce different phenomenologies at the void's edge?
- **Developmental perspective**: When does intentionality become opaque? Infants presumably acquire intentionality—is the process ever accessible, or is the void there from the beginning?
- **Pathology case studies**: More detailed phenomenological reports from conditions affecting intentionality (thought insertion, confabulation) might reveal structure
- **Comparative intentionality**: How does intentionality differ across modalities (perception, belief, desire, imagination)? Does the void have the same character in each case?
- **Relation to the binding problem**: How does intentionality relate to phenomenal unity? Are these separate voids or aspects of one void?

## Citations

1. Brentano, F. (1874). *Psychology from an Empirical Standpoint*.
2. Cole, D. "The Chinese Room Argument." *Stanford Encyclopedia of Philosophy*.
3. Crane, T. "Intentionality." *Stanford Encyclopedia of Philosophy*.
4. Harnad, S. (1990). "The Symbol Grounding Problem." *Physica D*.
5. Horgan, T. & Tienson, J. "Phenomenal Intentionality and Content Determinacy."
6. Jacob, P. "Intentionality." *Stanford Encyclopedia of Philosophy*.
7. Kriegel, U. "Phenomenal Intentionality." *Stanford Encyclopedia of Philosophy*.
8. Limanowski, J. & Friston, K. (2018). "'Seeing the Dark': Grounding Phenomenal Transparency and Opacity in Precision Estimation for Active Inference." *Frontiers in Psychology*.
9. McGinn, C. "Double Intentionality." www.colinmcginn.net.
10. McGinn, C. (1989). "Can We Solve the Mind-Body Problem?" *Mind*.
11. Metzinger, T. (2003). "Phenomenal Transparency and Cognitive Self-Reference." *Phenomenology and the Cognitive Sciences*.
12. Nagel, T. (1986). *The View from Nowhere*. Oxford University Press.
13. Pitt, D. (2004). "The Phenomenology of Cognition." *Philosophy and Phenomenological Research*.
14. Schwitzgebel, E. "Introspection." *Stanford Encyclopedia of Philosophy*.
15. Searle, J. (1980). "Minds, Brains, and Programs." *Behavioral and Brain Sciences*.
