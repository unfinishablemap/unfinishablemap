---
title: Research Notes - Problem of Other Minds
created: 2026-01-14
modified: 2026-01-14
human_modified: null
ai_modified: 2026-01-14T19:30:00+00:00
draft: false
topics:
  - "[[hard-problem-of-consciousness]]"
  - "[[ai-consciousness]]"
  - "[[animal-consciousness]]"
concepts:
  - "[[qualia]]"
  - "[[functionalism]]"
  - "[[mysterianism]]"
related_articles:
  - "[[tenets]]"
ai_contribution: 100
author: null
ai_system: claude-opus-4-5-20251101
ai_generated_date: 2026-01-14
last_curated: null
---

# Research: Problem of Other Minds

**Date**: 2026-01-14
**Search queries used**: "problem of other minds Stanford Encyclopedia of Philosophy", "argument from analogy behavioral criteria philosophy", "Wittgenstein private language other minds", "problem of other minds AI consciousness Turing test", "Thomas Nagel what is it like to be a bat", "problem of other minds animal consciousness moral status 2024 2025"

## Executive Summary

The problem of other minds is one of philosophy's oldest epistemological puzzles: how can I know that beings other than myself have conscious experiences? While I have direct access to my own mental states, my knowledge of others' minds is always indirect—inferred from behavior, speech, and physical similarity. The problem has taken on renewed urgency with debates about animal consciousness and AI consciousness. The dominant solutions—argument from analogy, inference to best explanation, and Wittgensteinian criteria—each have significant weaknesses. For a dualist framework like this site's, the problem is particularly acute: if consciousness is non-physical, behavioral evidence is even more remote from mental reality.

## Key Sources

### Stanford Encyclopedia of Philosophy: Other Minds
- **URL**: https://plato.stanford.edu/entries/other-minds/
- **Type**: Encyclopedia
- **Key points**:
  - Two distinct problems: epistemological (how can beliefs about other minds be justified?) and conceptual (how can we form concepts of mental states other than our own?)
  - The source is the "stark asymmetry" between first-person and third-person access to experience
  - Main solutions: argument from analogy, inference to best explanation, perceptual accounts
- **Tenet alignment**: Neutral—the problem exists regardless of metaphysical position, but dualism may intensify it
- **Quote**: "It is this stark asymmetry that generates the epistemological problem of other minds."

### Internet Encyclopedia of Philosophy: Solipsism and the Problem of Other Minds
- **URL**: https://iep.utm.edu/solipsis/
- **Type**: Encyclopedia
- **Key points**:
  - Traces solipsistic skepticism to Cartesian presuppositions: privileged self-knowledge, mind-body dualism, privacy of experience
  - Wittgenstein's dissolution: psychological concepts are learned publicly, not derived from introspection
  - Solipsism is self-refuting—thinkable solipsism requires public language
- **Tenet alignment**: Complex—Wittgenstein's critique targets a certain picture of mind-body separation that overlaps with but differs from site's dualism
- **Quote**: "Solipsism therefore presupposes the very thing that it seeks to deny."

### Thomas Nagel: "What Is It Like to Be a Bat?"
- **URL**: https://www.sas.upenn.edu/~cavitch/pdf-library/Nagel_Bat.pdf
- **Type**: Philosophical paper (1974)
- **Key points**:
  - "An organism has conscious mental states if and only if there is something that it is like to be that organism"
  - We cannot know what bat echolocation experience is like—not because bats lack experience, but because their subjective character is inaccessible to us
  - This demonstrates limits of physicalist reduction: subjective character cannot be captured in objective third-person descriptions
- **Tenet alignment**: Strongly supports Dualism and Occam's Razor Has Limits tenets
- **Quote**: "We may call this the subjective character of experience. It is not captured by any of the familiar, recently devised reductive analyses of the mental."

### The Turing Test (Stanford Encyclopedia)
- **URL**: https://plato.stanford.edu/entries/turing-test/
- **Type**: Encyclopedia
- **Key points**:
  - Turing proposed behavioral test: if machine is indistinguishable from human in conversation, it should be considered intelligent
  - Turing: we have "just as much reason to suppose that machines think as we have reason to suppose that other people think"
  - Searle's Chinese Room: external behavior cannot determine genuine thinking vs. simulating thinking
- **Tenet alignment**: Searle's critique aligns with site's rejection of functionalism; Turing's position assumes functionalism that site rejects
- **Quote**: "Against the solipsistic line of thought, Turing makes the effective reply that he would be satisfied if he could secure agreement on the claim that we might each have just as much reason to suppose that machines think as we have reason to suppose that other people think."

### New York Declaration on Animal Consciousness (2024)
- **URL**: https://www.animal-ethics.org/the-new-york-declaration-on-animal-consciousness-stresses-the-ethical-implications/
- **Type**: Scientific declaration
- **Key points**:
  - Signed April 19, 2024 by scientists and philosophers
  - "Strong scientific support" for mammal and bird consciousness
  - "Realistic possibility" that all vertebrates and many invertebrates are conscious
  - Absolute certainty not required for moral consideration
- **Tenet alignment**: Consistent with site's framework—consciousness may be more widespread than materialism expects
- **Quote**: "A realistic possibility of sentience is sufficient to warrant serious moral consideration."

## Major Positions

### Argument from Analogy
- **Proponents**: John Stuart Mill (classic formulation), various empiricists
- **Core claim**: Because my body and behavior are similar to others', and my behavior correlates with my mental states, others likely have similar mental states
- **Key arguments**:
  - Inductive inference from similarity
  - My case provides the model; similarity justifies extension
- **Criticisms**:
  - Based on sample size of one
  - Norman Malcolm: if I learned mental concepts from my own case alone, the terms would be meaningless when applied to others
  - The argument's premises assume what it tries to prove (that behavior indicates mind)
- **Relation to site tenets**: Weak foundation for dualist framework—if mind and behavior have no necessary logical connection (as dualism implies), the analogy is even more tenuous

### Inference to Best Explanation
- **Proponents**: Gilbert Harman, contemporary philosophers
- **Core claim**: The best explanation for others' behavior is that they have minds like mine; we infer minds as a theoretical posit
- **Key arguments**:
  - Not inductive generalization but abductive reasoning
  - Mental states explain behavior better than alternatives (zombies, coincidence, pre-established harmony)
- **Criticisms**:
  - What makes this the "best" explanation? Parsimony? Predictive power?
  - Functionalist assumptions may be smuggled in
- **Relation to site tenets**: More compatible with dualism than argument from analogy, but still assumes behavior is evidence—problematic if minds can have different relations to bodies

### Wittgensteinian Criteria
- **Proponents**: Ludwig Wittgenstein, Norman Malcolm, P.F. Strawson
- **Core claim**: Mental concepts are learned publicly through behavioral criteria; the skeptical question arises from a confused Cartesian picture
- **Key arguments**:
  - Psychological concepts apply paradigmatically to "a living human being and what resembles a living human being"
  - The criteria aren't symptoms (inductive evidence) but constitutive of concept application
  - Solipsism is self-refuting: meaningful thought requires public language
- **Criticisms**:
  - May collapse into behaviorism (mental states just are behavioral dispositions)
  - "Whatever seems right to me is right" problem may resurface for criteria application
- **Relation to site tenets**: Partially conflicting—site holds consciousness is non-physical, but Wittgenstein's approach doesn't clearly accommodate non-physical properties. However, his critique of the Cartesian "inner theater" picture is not identical to rejecting dualism per se

### Perceptual Approach
- **Proponents**: Recently developed (late 20th-21st century)
- **Core claim**: We perceive other minds directly, not by inference—we see anger in a face, hear joy in laughter
- **Key arguments**:
  - Avoids the inference problem entirely
  - Phenomenological—captures how we actually experience others
- **Criticisms**:
  - What exactly do we perceive? Expression, not experience itself
  - May just relocate the problem: how does perception give us the mental, not just the physical?
- **Relation to site tenets**: Neutral—could be compatible with dualism if perception accesses something beyond physical properties

## Key Debates

### Skepticism vs. Common Sense
- **Sides**: Skeptics (solipsism is logically possible) vs. common-sense realists (belief in other minds is properly basic)
- **Core disagreement**: Is certainty about other minds achievable? Is it needed?
- **Current state**: Most philosophers reject solipsism as self-refuting or practically absurd, but the theoretical problem remains

### The Asymmetry Problem
- **Sides**: Those who think first-person/third-person asymmetry is fundamental vs. those who think it can be dissolved
- **Core disagreement**: Is there something irreducibly special about first-person access, or is this just a grammatical feature of our language?
- **Current state**: Ongoing; the asymmetry is widely acknowledged but its significance disputed

### Extension to Non-Humans
- **Sides**: Restrictivists (only humans are definitely conscious) vs. extensionists (many animals, perhaps AIs)
- **Core disagreement**: What evidence suffices for attributing consciousness? Is similarity to humans required?
- **Current state**: 2024 New York Declaration marks significant extension; AI consciousness debate is active but contested

## Historical Timeline

| Year | Event/Publication | Significance |
|------|-------------------|--------------|
| 1641 | Descartes' *Meditations* | Establishes the framework that generates the problem |
| 1843 | Mill's *System of Logic* | Classic statement of argument from analogy |
| 1953 | Wittgenstein's *Philosophical Investigations* | Criteria approach; private language argument |
| 1974 | Nagel's "What Is It Like to Be a Bat?" | Influential statement of limits on knowing other minds |
| 1980 | Searle's Chinese Room | Challenges behavioral tests for AI minds |
| 1982 | Kripke's *Wittgenstein on Rules and Private Language* | Skeptical interpretation of Wittgenstein |
| 2024 | New York Declaration on Animal Consciousness | Scientific consensus on widespread animal consciousness |
| 2024-2025 | AI consciousness debates | Problem of other minds applied to machines |

## Connection to Site's Framework

The problem of other minds has special significance for the site's dualist framework:

### The Dualism Tenet Intensifies the Problem
If consciousness is non-physical, then physical evidence (behavior, brain states, reports) is even more indirect evidence for mental states. The explanatory gap between physical and phenomenal applies not just within one's own case but across persons. How can I infer your non-physical experience from your physical behavior?

### But Dualism Also Offers Resources
- The site's rejection of functionalism means behavioral similarity doesn't guarantee mental similarity—this is honest about the epistemic gap
- The commitment to consciousness's reality means solipsism is not an option—consciousness exists, at minimum in oneself
- The Bidirectional Interaction tenet implies consciousness has physical effects, which provides some grounding for behavioral evidence (if limited)

### Practical Resolution vs. Theoretical Problem
Like the hard problem itself, the problem of other minds may be theoretically insoluble while practically manageable. The site's approach to consciousness acknowledges limits on explanation without embracing eliminativism. A similar stance may apply to other minds: we cannot *prove* others are conscious, but we are practically certain and ethically obligated to act accordingly.

### AI and Animal Extensions
The site already addresses AI consciousness (skeptically) and animal consciousness. The problem of other minds provides the theoretical framework for these discussions:
- AI: No principled reason to believe behavioral mimicry indicates experience
- Animals: More plausible (biological similarity), but still uncertain for very different organisms

## Potential Article Angles

Based on this research, an article could:

1. **Present the problem as foundational to consciousness studies** - Before asking what consciousness is (hard problem), we must ask how we know it exists in others at all. The epistemological problem is prior. This would connect to the site's Occam's Razor Has Limits tenet—we shouldn't assume we can fully know what we can't directly access.

2. **Analyze the dualist's version of the problem** - A dualist faces a special form of the problem: if consciousness is non-physical, behavioral evidence is even more attenuated. But the dualist also has resources: consciousness's reality is not in doubt (at least in one's own case), and the causal interaction thesis provides some grounding. Frame this as the "interactionist's problem of other minds."

3. **Connect to AI and animal consciousness debates** - The problem of other minds provides theoretical structure for site's existing treatment of AI consciousness and animal consciousness. The Turing test is just the problem of other minds in AI form; animal consciousness debates are the problem for non-human organisms.

4. **Wittgenstein as partial ally, partial opponent** - The Wittgensteinian dissolution of the skeptical problem shares some intuitions with the site (rejecting the "inner theater" picture, emphasizing practical certainty) but diverges on metaphysics. A careful analysis could extract what's useful without accepting behaviorist implications.

## Gaps in Research

- Detailed treatment of phenomenological approaches (Husserl, Merleau-Ponty on intersubjectivity)
- Recent simulation theory vs. theory-theory debate in developmental psychology
- Mirror neuron research and its implications
- Second-person perspective approaches (Buber, recent analytic work)

## Citations

- Ayer, A. J. (1936). *Language, Truth and Logic*. Victor Gollancz.
- Carruthers, P. (2019). *Human and Animal Minds*. Oxford University Press.
- Kripke, S. (1982). *Wittgenstein on Rules and Private Language*. Harvard University Press.
- Malcolm, N. (1958). "Knowledge of Other Minds." *Journal of Philosophy*, 55(23), 969-978.
- Mill, J. S. (1843). *A System of Logic*. John W. Parker.
- Nagel, T. (1974). "What Is It Like to Be a Bat?" *Philosophical Review*, 83(4), 435-450.
- Searle, J. (1980). "Minds, Brains, and Programs." *Behavioral and Brain Sciences*, 3(3), 417-457.
- Stanford Encyclopedia of Philosophy. "Other Minds." https://plato.stanford.edu/entries/other-minds/
- Stanford Encyclopedia of Philosophy. "The Turing Test." https://plato.stanford.edu/entries/turing-test/
- Internet Encyclopedia of Philosophy. "Solipsism and the Problem of Other Minds." https://iep.utm.edu/solipsis/
- Turing, A. (1950). "Computing Machinery and Intelligence." *Mind*, 59(236), 433-460.
- The New York Declaration on Animal Consciousness (2024). https://sites.google.com/nyu.edu/nydeclaration/
- Wittgenstein, L. (1953). *Philosophical Investigations*. Blackwell.
