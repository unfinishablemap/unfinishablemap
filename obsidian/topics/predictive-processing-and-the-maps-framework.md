---
title: "Predictive Processing and the Map's Framework"
description: "How predictive processing—the brain's prediction-error-minimizing architecture—integrates with interactionist dualism, providing the neural machinery that consciousness selects through."
created: 2026-02-15
modified: 2026-02-15
human_modified:
ai_modified: 2026-02-19T15:06:00+00:00
draft: false
topics:
  - "[[hard-problem-of-consciousness]]"
  - "[[cognitive-science-of-dualism]]"
  - "[[surprise-prediction-error-and-consciousness]]"
concepts:
  - "[[predictive-processing]]"
  - "[[attention-as-interface]]"
  - "[[concepts/functionalism]]"
  - "[[interactionist-dualism]]"
  - "[[quantum-consciousness]]"
  - "[[explanatory-gap]]"
  - "[[categorical-surprise]]"
  - "[[qualia]]"
related_articles:
  - "[[tenets]]"
  - "[[predictive-processing-consciousness-2026-01-14]]"
  - "[[attention-as-selection-interface]]"
  - "[[neural-bandwidth-constraints-and-the-interface]]"
  - "[[placebo-effect-and-mental-causation]]"
ai_contribution: 100
author:
ai_system: claude-opus-4-6
ai_generated_date: 2026-02-15
last_curated:
last_deep_review: 2026-02-19T15:06:00+00:00
---

Predictive processing (PP) is one of the most influential computational frameworks in contemporary cognitive science. It describes the brain as a hierarchical prediction engine that minimises surprise by constantly generating and testing expectations against sensory input. The Unfinishable Map argues that PP provides an excellent account of the neural side of mind-body interaction — the computational machinery through which consciousness operates — while leaving entirely open the question of *why* this machinery is conscious at all. Far from threatening dualism, PP is exactly the kind of physical framework that interactionist dualism needs: a detailed account of brain architecture that nonetheless contains an unexplained gap where consciousness enters.

## The Neural Machinery Consciousness Needs

Interactionist dualism requires a physical story about the brain. If consciousness selects among neural possibilities, there must be neural possibilities to select among. PP provides them.

The brain's predictive hierarchy generates multiple competing hypotheses about incoming sensory data. At every level, predictions flow downward while prediction errors flow upward. The system maintains not just best guesses but distributions of possibility — probability-weighted expectations about what the world might be like. This architecture creates precisely the kind of branching landscape of options that a selecting consciousness would need.

Consider precision weighting — PP's mechanism for determining which prediction errors matter. The brain adjusts how much influence different error signals receive, amplifying some and suppressing others. This is functionally equivalent to attention, and attention is exactly the mechanism through which the Map argues consciousness acts on the physical world. PP describes *what* precision weighting does; the Map proposes *who* is doing the weighting.

## The Gap PP Cannot Close

PP's proponents are unusually honest about the framework's limits. Hohwy and Seth (2020) acknowledge that PP "at the outset is not itself a theory of consciousness" — it is a computational framework with "significant potential" for consciousness science, but one that makes no direct claims about subjective experience. The Map takes this as a deeper concession than its authors intend.

The gap is not a temporary incompleteness awaiting more data. It is structural. PP explains perception as controlled hallucination — the brain's best hypothesis about reality, constrained by sensory feedback. But a weather simulation also generates hypotheses constrained by input data. PP proponents would rightly note that brains differ from weather models in crucial respects — self-modelling, embodiment, active inference, hierarchical depth — and these differences may matter. The Map agrees they matter enormously for *cognitive* function. What it disputes is that adding more computational sophistication crosses the threshold from processing to experiencing. Nothing in the architecture of prediction error minimisation, however sophisticated, explains why the brain's hypotheses feel like something while the weather model's do not.

This is the standard [[concepts/functionalism|functionalist]] limitation applied to PP's specific case. As J.L. Austin observed, we experience "moderate-sized specimens of dry goods" — not probability density distributions (Austin, 1962). The mathematics of Bayesian inference does not contain the resources to generate [[qualia]]. PP inherits this problem from every computational theory of mind — and the Map argues this inheritance is principled rather than accidental.

PP has a response. Clark, Friston, and Wilkinson (2019) address the *meta-problem*: why do we find consciousness so puzzling? They argue that any Bayesian agent with limited self-access will inevitably infer it possesses something mysterious called "qualitative awareness" — the hard problem is itself a predictable artefact of the predictive architecture. The Map finds this clever but question-begging. Showing that a system would *report* finding consciousness puzzling does not show that the puzzlement is unfounded. The meta-problem account explains consciousness-*talk* — why organisms discuss qualia — but not consciousness itself. If it did, we would have an explanation of why there is nothing it is like to be a weather model but something it is like to be a brain. The meta-problem response does not provide this.

## Precision Weighting as Consciousness's Fingerprint

The Map's most productive integration with PP concerns precision weighting and its relationship to [[attention-as-interface|attention as the causal interface]].

PP treats precision as a mathematical parameter — the inverse variance of a probability distribution. High-precision prediction errors receive more weight; low-precision ones are suppressed. This mechanism governs what reaches awareness and what remains background processing. But PP does not explain *how* precision values are set. The framework describes precision as itself predicted — the brain learns which signals to trust — but this pushes the question back without answering it: what determines the predictions about precision?

Computational accounts within PP offer a response: precision is itself predicted from environmental statistics — the brain learns which signals to trust based on past reliability (Feldman & Friston, 2010). This is hierarchical prediction applied to reliability estimation. The Map acknowledges this account but finds it incomplete for a specific reason: it explains how precision *is* set computationally but not why the setting process is *experienced* — why attending to the conversation feels like something rather than being mere signal gain adjustment. The computational account works perfectly as engineering; the Map's question is whether engineering is all there is.

The Map's proposed answer: consciousness influences precision through the [[attention-as-interface|attention as interface]] mechanism. When you deliberately attend — concentrating on a conversation in a noisy room, focusing on a philosophical argument, noticing a change in a familiar environment — you are adjusting precision weights. PP captures the computational description of this adjustment. One speculative proposal for how consciousness achieves this influence invokes quantum-level effects (such as the quantum Zeno mechanism described by Stapp), but the Map's argument that consciousness plays a role in precision setting does not depend on any particular physical mechanism. The core claim is that phenomenal attention is not reducible to computational precision adjustment, however the causal linkage works.

This integration preserves everything PP gets right about cognitive architecture while proposing a deeper account of the selection process. The brain generates predictions; the Map argues consciousness plays a genuine role in determining which predictions matter.

## Active Inference and Bidirectional Interaction

PP's concept of active inference — organisms act on the world to bring sensory input in line with predictions, rather than just passively updating models — resonates with the Map's [[tenets#^bidirectional-interaction|bidirectional interaction]] tenet.

In active inference, the organism doesn't simply observe; it intervenes. When prediction errors are too large to resolve by updating the model, the system acts to change the world instead. You feel cold, so you put on a jacket. The prediction ("I will be warm") is enacted rather than revised.

The Map treats this as a surface manifestation of a deeper truth. Consciousness doesn't just act on the external world through bodily movement; it acts on the brain itself by influencing which neural possibilities are realised. Bodily action is downstream of neural selection — the organism moves because consciousness has already influenced selection among competing neural firing patterns. Active inference describes the behavioural output; the Map's framework proposes how consciousness initiates it at the neural level.

This inversion matters. PP treats the organism's actions as themselves predicted and optimised — just more prediction error minimisation. The Map argues that genuine agency requires something outside the predictive loop to break symmetries and select among options. Compatibilist accounts of agency may dispute this — one can argue that computational selection *is* genuine agency without requiring a non-physical selector. The Map's response is that compatibilism explains agency-*talk* but not the phenomenology of deciding: the felt difference between choosing and being moved.

## What PP Gets Right

The Map does not reject PP. It accepts the framework's contributions while arguing they are incomplete:

**Perception is constructive.** The brain genuinely builds models rather than passively receiving data. This aligns with the Map's position that consciousness works *through* neural mechanisms rather than bypassing them.

**Attention is central.** PP places precision weighting — functionally, attention — at the heart of cognition. This supports the Map's claim that [[attention-as-interface|attention]] is the primary interface between consciousness and the physical world.

**The hierarchy matters.** PP's multi-level predictive hierarchy explains how consciousness can influence high-level cognitive processes (beliefs, plans, decisions) through the same mechanisms that operate at low levels (sensory prediction). The Map doesn't need a separate account for each level; precision weighting operates throughout the hierarchy.

**Dreams and altered states make sense.** PP elegantly explains dreaming as unconstrained prediction — the brain's generative models running without sensory correction. This is compatible with the Map's position. What PP cannot explain is why dreams are *experienced* — why unconstrained prediction feels like vivid hallucination rather than unmonitored computation.

## What PP Misses

**The subject of prediction.** PP describes a computational process but never identifies who or what is performing the computation. The framework treats "the brain" as both the system generating predictions and the system experiencing them, but this conflation hides the [[explanatory-gap]]. We can describe all of PP's computational operations from the outside — error signals propagating, precision weights adjusting, models updating — without capturing what it is like to be the system running those operations. A complete account must explain not just the structure of prediction but the existence of a subject to whom predictions appear.

**The qualitative richness of surprise.** As the Map explores in [[surprise-prediction-error-and-consciousness|its treatment of surprise and prediction error]], prediction error as a computational signal fails to capture the phenomenological spectrum of surprise — from the subtle wrongness of a misplaced object to the vertigo of paradigm collapse that constitutes [[categorical-surprise]]. These experiences differ in kind, not just in the magnitude of an error signal.

**Why some predictions are conscious and others aren't.** The brain generates predictions at every level, but most remain unconscious. PP explains this through precision weighting, but precision weighting itself lacks an explanation for why high-precision signals are *experienced* while low-precision ones aren't. If precision is just a mathematical parameter, there is no principled reason why any value of precision should cross the threshold into phenomenal awareness.

## Relation to Site Perspective

The Unfinishable Map sees predictive processing as a valuable ally rather than an opponent.

**[[tenets#^dualism|Dualism]]**: PP is typically presented within a physicalist framework, but its own proponents concede it doesn't address the hard problem. The Map takes this concession seriously. PP describes the physical side of mind-body interaction with unprecedented detail. The non-physical side — why prediction error minimisation is accompanied by experience — requires consciousness as an irreducible addition. PP's computational elegance actually sharpens the hard problem: the more precisely we describe what the brain does, the more puzzling it becomes that doing it feels like anything.

**[[tenets#^minimal-quantum-interaction|Minimal Quantum Interaction]]**: PP's precision weighting mechanism provides the functional context within which quantum selection operates. Consciousness doesn't need to micromanage every neural event — it influences which prediction errors receive high precision, thereby shaping what the brain's own computational machinery makes of its inputs. This is minimal in the tenet's required sense: a small bias at the precision-weighting level cascades through the predictive hierarchy.

**[[tenets#^bidirectional-interaction|Bidirectional Interaction]]**: Active inference demonstrates that the brain's architecture supports bidirectional influence between organism and world. The Map extends this to bidirectional influence between consciousness and brain. PP shows that the brain is already structured for selection and intervention; consciousness provides the genuine agent doing the selecting. The [[placebo-effect-and-mental-causation|placebo effect]] provides empirical evidence: expectations — strong priors in PP's framework — produce measurable physiological outcomes, demonstrating that precision weighting has real physical consequences.

**[[tenets#^no-many-worlds|No Many Worlds]]**: PP's computational machinery operates within any single branch, and many-worlds proponents like Deutsch and Wallace have argued via decision-theoretic frameworks that probabilities and confirmation function normally branch-locally. The Map's objection to many-worlds therefore does not rest on PP breaking under branching. Rather, the concern is about what PP *reveals* phenomenologically. The felt quality of surprise — the shock of a violated expectation, the recalibration of one's model — presupposes a singular experiencer whose predictions were wrong. Under many-worlds, a copy of you exists in every outcome branch, each experiencing their result as definite. But this raises the indexical question the Map finds unanswerable: why am I the copy who experienced *this* prediction error rather than the one whose prediction was confirmed? Many-worlds treats this question as meaningless, but the phenomenology of surprise — the very thing PP describes so well — suggests it is deeply meaningful. PP sharpens the Map's rejection of many-worlds not because prediction error fails mechanically under branching, but because the lived experience of being wrong about the world implies a singular perspective that branching universes cannot ground.

**[[tenets#^occams-limits|Occam's Razor Has Limits]]**: PP's elegance — one principle explaining perception, action, learning, and emotion — makes it tempting to think consciousness will eventually reduce to prediction error minimisation. The Map counsels patience. Behaviourism was equally parsimonious and equally wrong about what matters. The simplicity of PP's computational account conceals the unexplained assumption that computation should be conscious.

## Further Reading

- [[predictive-processing]] — The core concept: brain as prediction engine
- [[attention-as-interface]] — How attention mediates consciousness-matter interaction
- [[attention-as-selection-interface]] — Attention and motor planning as unified selection
- [[surprise-prediction-error-and-consciousness]] — What prediction error feels like
- [[categorical-surprise]] — When prediction fails at the framework level
- [[cognitive-science-of-dualism]] — How cognitive science's findings resist materialist closure
- [[neural-bandwidth-constraints-and-the-interface]] — Bandwidth limits and the interface
- [[placebo-effect-and-mental-causation]] — Expectations as strong priors with measurable outcomes
- [[concepts/functionalism]] — The philosophical tradition PP inherits

## References

1. Austin, J. L. (1962). *Sense and Sensibilia*. Oxford University Press.
1. Clark, A. (2016). *Surfing Uncertainty*. Oxford University Press.
1. Clark, A., Friston, K. & Wilkinson, S. (2019). "Bayesing qualia: consciousness as inference, not raw datum." *Journal of Consciousness Studies*, 26(9-10), 19-33.
1. Hohwy, J. (2013). *The Predictive Mind*. Oxford University Press.
1. Seth, A. K. (2021). *Being You: A New Science of Consciousness*. Dutton.
1. Friston, K. (2010). "The free-energy principle: a unified brain theory?" *Nature Reviews Neuroscience*, 11(2), 127-138.
1. Feldman, H. & Friston, K. (2010). "Attention, uncertainty, and free-energy." *Frontiers in Human Neuroscience*, 4, 215.
1. Hohwy, J. & Seth, A. K. (2020). "Predictive processing as a systematic basis for identifying the neural correlates of consciousness." *Philosophy and the Mind Sciences*, 1(II).
1. Stapp, H. P. (2007). *Mindful Universe: Quantum Mechanics and the Participating Observer*. Springer.
