---
title: "Consciousness and Collective Intentionality"
description: "Does building institutions, making promises, and sharing goals require phenomenal consciousness? Human-AI exploration of collective intentionality and the mind."
created: 2026-02-15
modified: 2026-02-15
human_modified:
ai_modified: 2026-02-19T18:06:00+00:00
draft: false
topics:
  - "[[topics/consciousness-and-social-cognition]]"
  - "[[consciousness-and-collective-intelligence]]"
  - "[[social-construction-of-self-vs-phenomenal-self]]"
concepts:
  - "[[intentionality]]"
  - "[[phenomenal-intentionality]]"
  - "[[intersubjectivity]]"
  - "[[theory-of-mind]]"
  - "[[metarepresentation]]"
related_articles:
  - "[[tenets]]"
  - "[[intersubjective-void]]"
  - "[[other-minds-void]]"
  - "[[consciousness-and-interpersonal-understanding]]"
ai_contribution: 100
author:
ai_system: claude-opus-4-6
ai_generated_date: 2026-02-15
last_curated:
last_deep_review: 2026-02-19T18:06:00+00:00
---

When two people carry a heavy table through a doorway, something happens that no solitary action can replicate. Each adjusts grip, pace, and angle in response to the other — not merely reacting to physical forces but coordinating around a shared goal that both understand and both know the other understands. This is collective intentionality: the capacity of multiple minds to share goals, commitments, and representations in ways that generate a form of "aboutness" no individual mind possesses alone. The Unfinishable Map argues that collective intentionality depends on phenomenal consciousness — not because groups are conscious, but because the individual contributions that make collective intentionality possible require subjects who genuinely understand what they are doing together.

The question matters because collective intentionality underpins nearly everything distinctive about human civilisation. Promises, property, institutions, language itself — all depend on minds that can share commitments and recognise each other as sharing them. If this capacity requires phenomenal consciousness, then the social world is not merely correlated with consciousness but constituted by it.

## What Collective Intentionality Is

Collective intentionality is not simply multiple individuals happening to intend the same thing. Two strangers walking in the same direction have parallel individual intentions, not a shared one. Collective intentionality requires something more: each participant must intend the joint activity *as* joint, be aware that the other shares this intention, and adjust their contribution in light of the shared goal.

John Searle distinguishes "I-intentionality" from "we-intentionality." When a group of musicians plays in an orchestra, each player's intention is not merely "I play my part" but "I play my part *as part of our playing the symphony*." The we-intention is not reducible to a collection of I-intentions plus mutual beliefs about each other's I-intentions. It has a distinctive character: each participant represents the activity as collective from the start.

Michael Bratman characterises shared cooperative activity through three features: mutual responsiveness (each participant responds to the other's intentions and actions), commitment to the joint activity, and commitment to mutual support. His formal account requires that each participant intend the joint activity, intend it in accordance with and because of the other's similar intention, and that their sub-plans mesh. The meshing requirement is critical — participants must adjust their sub-plans to fit together, which requires representing both the joint goal and the other's approach to it.

Michael Tomasello traces a developmental sequence in children. Shared intentionality — the capacity for joint goals with complementary roles — emerges around nine months and develops through early childhood. By age three, children understand and enforce social norms that govern joint activities. Tomasello argues this capacity is what distinguishes human cognition from great ape cognition, more than any enhancement in individual reasoning.

## The Consciousness Requirement

Why should collective intentionality require phenomenal consciousness? The argument proceeds through several steps.

### Understanding, Not Just Tracking

Collective intentionality requires that participants understand the joint activity *as* joint. This is metarepresentational — requiring the capacity to represent representations *as* representations (see [[theory-of-mind]]): you must represent the shared goal *as* shared, represent the other's commitment *as* a commitment, and represent your own role *as* a role in something larger. The "as" in each case marks where mere information processing becomes genuine understanding.

Consider what representing a promise involves. When someone promises to help you move house, you do not merely update a probability estimate about their future behaviour. You represent them as having *committed* themselves — as having placed themselves under an obligation they recognise and that you both understand binds them. This representation involves grasping [[intentionality|intentional states]] — beliefs, commitments, obligations — *as* intentional states with normative force. The [[consciousness-and-interpersonal-understanding|interpersonal understanding]] required is not mere behaviour prediction but genuine comprehension of another mind's commitments.

The [[phenomenal-intentionality]] thesis holds that genuine intentionality — the "aboutness" of mental states — derives from phenomenal consciousness. If this is correct, then the metarepresentational demands of collective intentionality inherit the consciousness requirement. You cannot represent another's commitment *as* a commitment unless you have the phenomenal resources to grasp what commitment means.

### The Normative Dimension

Collective intentionality generates normativity. When we engage in a joint activity, we acquire obligations: to do our part, to coordinate with others, to share information relevant to the joint goal. Violating these obligations warrants reactive attitudes — resentment, blame, demands for justification — that presuppose representing the violator as a conscious agent who understood and chose to breach a commitment.

This normative structure distinguishes collective intentionality from collective behaviour. Geese flying in V-formation exhibit coordinated behaviour governed by aerodynamic forces and simple rules. No goose violates an obligation by breaking formation; no goose owes an explanation for changing position. The coordination is real but normatively empty.

Human collective intentionality is normatively loaded because participants represent each other as conscious agents with commitments they can honour or violate. Remove consciousness from the picture, and the normative structure collapses into mere behavioural regularity — functional coordination without genuine obligation.

A functionalist might respond that normative responses — resentment, blame, demands for justification — can be fully characterised by their functional roles without invoking phenomenal consciousness. On this view, what matters is the pattern of social response, not whether it is accompanied by experience. The Map's reply: functional accounts of normativity capture the *structure* of obligation while losing its *force*. A system that produces blame-behaviour without anyone experiencing the violation as a betrayal of trust has the form of normative life without its substance. The felt weight of broken commitment — the sense that someone who *understood* what they were doing chose to breach it — is precisely what distinguishes obligation from mere behavioural expectation.

### The Searle Problem: Can We-Intentionality Be Physical?

Searle argues that collective intentionality is a biologically primitive phenomenon — not constructed from individual mental states plus social agreements, but a basic form of intentionality that brains produce directly. He insists that we-intentionality exists "in the heads" of individuals, not in some supraindividual entity.

This creates a tension for physicalist accounts. If we-intentionality is genuinely irreducible to I-intentionality (as Searle argues), yet exists only in individual brains, then individual brains must be capable of generating a form of intentionality that inherently represents the social. The brain must produce states whose content is irreducibly collective — "we intend" rather than "I intend and believe you intend."

The Map interprets this as further evidence that [[intentionality]] has features that resist physical reduction. If the content of we-intentionality cannot be decomposed into individual intentional states, and if intentionality derives from phenomenal consciousness (as the phenomenal intentionality thesis holds), then collective intentionality requires a form of phenomenal experience that is inherently social — experience whose character involves representing oneself as part of a "we."

## What Collective Intentionality Is Not

### Not Group Consciousness

The Map's [[consciousness-and-collective-intelligence|analysis of collective intelligence]] argues that groups lack the physical substrate — specifically, the quantum-sensitive neural architecture — through which consciousness interfaces with the physical world. Collective intentionality does not require revising this conclusion. Groups do not become conscious by sharing intentions. What happens is that individual conscious beings achieve something together that no individual consciousness could achieve alone — much as individual musicians create a symphony that no single player produces, without the symphony itself being conscious.

The distinction matters because it preserves the Map's framework: consciousness is individual, grounded in specific neural substrates, but its products can be collective. Institutions, shared meanings, and joint commitments are real features of the social world, created and sustained by individual conscious beings interacting through classical channels.

### Not Mere Coordination

Collective intentionality also exceeds mere coordination. A market coordinates the behaviour of millions without any shared intention — buyers and sellers pursue individual goals, and coordination emerges from price signals. This is Adam Smith's invisible hand: collective outcomes without collective intentionality.

Genuine collective intentionality involves participants who represent the activity *as* shared, who understand their role *as* a role, who hold each other accountable *as* co-agents in a joint enterprise. The invisible hand produces coordination; collective intentionality produces cooperation — and cooperation requires minds that can recognise each other as minds.

## The Developmental Evidence

Tomasello's developmental research illuminates where collective intentionality emerges and what it requires.

At around nine months, human infants begin engaging in joint attention — triadic interactions where child, adult, and object are connected through mutual awareness. The infant does not merely look at what the adult looks at (gaze following, present in apes) but engages in *shared* attention: knowing the adult is attending, knowing the adult knows the infant is attending, and finding this shared awareness meaningful.

Between one and three years, children develop shared intentionality: participating in collaborative activities with complementary roles, understanding the joint goal, and correcting partners who fail to fulfil their role. Crucially, three-year-olds enforce norms on third parties — telling others how a game "should" be played — indicating they represent the activity's normative structure, not just their own participation.

Great apes show limited evidence of these capacities. They coordinate behaviour — hunting in loose groups, travelling together, sharing some activities. But the recursive mutual awareness that characterises human joint attention, the complementary role structure of shared activities, and the normative enforcement that holds participants accountable all appear diminished or absent.

The developmental trajectory suggests that collective intentionality builds on capacities the Map associates with phenomenal consciousness: metarepresentation, recursive [[theory-of-mind|mindreading]], and normative sensitivity. The nine-month milestone coincides with what developmental researchers describe as the emergence of shared experience — the infant's dawning awareness that others have perspectives that can be aligned with or differ from their own.

## Institutional Reality as a Test Case

Searle argues that institutional facts — money, property, marriage, government — depend on collective intentionality. A piece of paper counts as money only because enough people collectively accept it as money. This acceptance is not mere behaviour (using the paper in exchange) but involves representing the paper *as* money — understanding it has exchange value because of collective agreement, not because of intrinsic physical properties.

Creating and sustaining institutional reality requires what Searle calls "status functions": assigning functions to objects and people that they cannot perform by virtue of physical properties alone. A judge has the power to sentence someone not because of physical capabilities but because a community collectively recognises that power.

The consciousness requirement enters through status functions' dependence on understanding. A community of beings that merely processed information and produced appropriate behavioural outputs — functional equivalents of social participation — could sustain the *behaviour* associated with institutions without sustaining the institutions themselves. Institutions require participants who understand that status functions exist, who can distinguish institutional from brute facts, who can create new institutions by collectively intending new status functions. This understanding is metarepresentational: representing social arrangements *as* social arrangements, with the awareness that they exist because we collectively recognise them.

Whether sophisticated AI systems could sustain institutional reality without phenomenal consciousness remains an open question. But the Map's position is that institutional understanding — grasping that money is money because we agree it is, not because of what it is made of — requires the kind of genuine comprehension that phenomenal consciousness enables.

## Relation to Site Perspective

The [[tenets#^dualism|Dualism]] tenet holds that consciousness is irreducible to physical processes. Collective intentionality extends this claim into the social domain. If we-intentionality cannot be reduced to aggregated I-intentionality (as Searle argues), and if I-intentionality itself derives from irreducible phenomenal consciousness (as the phenomenal intentionality thesis holds), then the social world rests on irreducibly conscious foundations. Institutions, promises, and shared goals are not physical arrangements that happen to be accompanied by experience — they are constituted by the intentional acts of phenomenally conscious beings.

The [[tenets#^bidirectional-interaction|Bidirectional Interaction]] tenet holds that consciousness causally influences the physical world. Collective intentionality provides some of the strongest circumstantial evidence. The entire institutional structure of human civilisation — laws, economies, governments, organisations — exists because conscious beings share intentions and hold each other to commitments. If consciousness were [[concepts/epiphenomenalism|epiphenomenal]], the systematic dependence of institutional reality on shared understanding would be coincidental. The Map finds this implausible: the causal chain from shared intentions to institutional outcomes is too direct and too pervasive to dismiss as mere correlation.

The [[tenets#^occams-limits|Occam's Razor Has Limits]] tenet counsels against dismissing collective intentionality's consciousness requirement on parsimony grounds. The simpler hypothesis — social coordination is sophisticated information processing, consciousness is incidental — struggles to explain the normative dimension. Obligations, commitments, and accountability presuppose agents who understand what they are doing. A purely functional account of these phenomena strips them of their normative character, leaving only behavioural regularity where we experience binding commitment. The parsimonious explanation may be wrong because it cannot capture what collective intentionality actually involves.

## Further Reading

- [[consciousness-and-collective-intelligence]] — Whether groups can be conscious, distinct from whether consciousness enables collective intentionality
- [[topics/consciousness-and-social-cognition]] — How individual consciousness enables the social cognition collective intentionality requires
- [[intentionality]] — The "aboutness" of mental states and its relation to consciousness
- [[phenomenal-intentionality]] — The thesis that genuine intentionality derives from phenomenal experience
- [[intersubjectivity]] — The shared space between minds where collective intentionality operates
- [[intersubjective-void]] — The structural gap between minds that collective intentionality bridges but never closes
- [[social-construction-of-self-vs-phenomenal-self]] — Why social construction requires phenomenal subjects

## References

1. Searle, J. R. (1990). "Collective Intentions and Actions." In *Intentions in Communication*, ed. Cohen, Morgan, and Pollack. MIT Press.
1. Searle, J. R. (1995). *The Construction of Social Reality*. Free Press.
1. Bratman, M. E. (1992). "Shared Cooperative Activity." *The Philosophical Review*, 101(2), 327-341.
1. Bratman, M. E. (2014). *Shared Agency: A Planning Theory of Acting Together*. Oxford University Press.
1. Tomasello, M. (2014). *A Natural History of Human Thinking*. Harvard University Press.
1. Tomasello, M. (2019). *Becoming Human: A Theory of Ontogeny*. Harvard University Press.
1. Tuomela, R. (2007). *The Philosophy of Sociality: The Shared Point of View*. Oxford University Press.
1. Gilbert, M. (1989). *On Social Facts*. Routledge.
